<!-- Google Tag Manager -->
<script>
  (function (w, d, s, l, i) {
    w[l] = w[l] || [];
    w[l].push({ "gtm.start": new Date().getTime(), event: "gtm.js" });
    var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s),
      dl = l != "dataLayer" ? "&l=" + l : "";
    j.async = true;
    j.src = "https://www.googletagmanager.com/gtm.js?id=" + i + dl;
    f.parentNode.insertBefore(j, f);
  })(window, document, "script", "dataLayer", "GTM-KV83JWN");
</script>
<!-- End Google Tag Manager -->


<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Easier Configuration">
      
      
        <meta name="author" content="DanLing Contributors">
      
      
        <link rel="canonical" href="https://danling.org/package/">
      
      
        
          <link rel="alternate" href="../" hreflang="en">
        
          <link rel="alternate" href="../zh/" hreflang="zh">
        
      
      
        <link rel="alternate" type="application/rss+xml" title="RSS feed" href="../feed_rss_created.xml">
        <link rel="alternate" type="application/rss+xml" title="RSS feed of updated content" href="../feed_rss_updated.xml">
      
      <link rel="icon" href="../assets/images/logo.ico">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-8.5.11+insiders-4.26.6">
    
    
      
        <title>package - DanLing</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.9b35cbb9.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.2505c338.min.css">
        
      
      

    
    
    
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../assets/css/fonts.css">
    
      <link rel="stylesheet" href="../assets/css/extra.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  


  <script id="__analytics">function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config","G-GBDSEJ5FND"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","G-GBDSEJ5FND",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-GBDSEJ5FND",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script>

  
    <script>var consent;"undefined"==typeof __md_analytics||(consent=__md_get("__consent"))&&consent.analytics&&__md_analytics()</script>
  

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="blue-grey" data-md-color-accent="teal">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#danling_1" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href=".." title="DanLing" class="md-header__button md-logo" aria-label="DanLing" data-md-component="logo">
      
  <img src="../assets/images/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            DanLing
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              package
            
          </span>
        </div>
      </div>
    </div>
    
      <form class="md-header__option" data-md-component="palette">
        
          
          
          
          <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="blue-grey" data-md-color-accent="teal"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
          
            <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
            </label>
          
        
          
          
          
          <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="blue-grey" data-md-color-accent="teal"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
          
            <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_0" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
            </label>
          
        
      </form>
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
      <div class="md-header__option">
        <div class="md-select">
          
          <button class="md-header__button md-icon" aria-label="选择当前语言">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m12.87 15.07-2.54-2.51.03-.03A17.52 17.52 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04M18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12m-2.62 7 1.62-4.33L19.12 17h-3.24Z"/></svg>
          </button>
          <div class="md-select__inner">
            <ul class="md-select__list">
              
                <li class="md-select__item">
                  <a href="../" hreflang="en" class="md-select__link">
                    English
                  </a>
                </li>
              
                <li class="md-select__item">
                  <a href="../zh/" hreflang="zh" class="md-select__link">
                    汉语
                  </a>
                </li>
              
            </ul>
          </div>
        </div>
      </div>
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="分享" aria-label="分享" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/ZhiyuanChen/DanLing" title="åå¾ä»åº" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    DanLing
  </div>
</a>
      </div>
    
  </nav>
  
    
      <nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        




  
    <li class="md-tabs__item">
      <a href=".." class="md-tabs__link">
        
  
  DanLing

      </a>
    </li>
  

      
        




  
    
    
    
      <li class="md-tabs__item">
        <a href="../runner/" class="md-tabs__link">
          
  
    
  
  Runner

        </a>
      </li>
    
  

      
        




  
    
    
    
      <li class="md-tabs__item">
        <a href="../tensors/nested_tensor/" class="md-tabs__link">
          
  
  Tensors

        </a>
      </li>
    
  

      
        




  
    <li class="md-tabs__item">
      <a href="../registry/" class="md-tabs__link">
        
  
  Registry

      </a>
    </li>
  

      
        




  
    
    
    
      <li class="md-tabs__item">
        <a href="../metrics/average_meter/" class="md-tabs__link">
          
  
  Metrics

        </a>
      </li>
    
  

      
        




  
    
    
    
      <li class="md-tabs__item">
        <a href="../utils/decorator/" class="md-tabs__link">
          
  
  Utils

        </a>
      </li>
    
  

      
        

  




  
    <li class="md-tabs__item">
      <a href="./" class="md-tabs__link md-tabs__link--active">
        
  
  package

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="DanLing" class="md-nav__button md-logo" aria-label="DanLing" data-md-component="logo">
      
  <img src="../assets/images/logo.png" alt="logo">

    </a>
    DanLing
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/ZhiyuanChen/DanLing" title="åå¾ä»åº" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    DanLing
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DanLing
    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../runner/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Runner
    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
    
    
      
        
      
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../tensors/nested_tensor/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Tensors
    
  </span>
  
  

      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../registry/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Registry
    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
    
    
      
        
      
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../metrics/average_meter/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Metrics
    
  </span>
  
  

      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../utils/decorator/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Utils
    
  </span>
  
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    package
    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    package
    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#danling" class="md-nav__link">
    <span class="md-ellipsis">
      danling
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#danling.AverageMeter" class="md-nav__link">
    <span class="md-ellipsis">
      AverageMeter
    </span>
  </a>
  
    <nav class="md-nav" aria-label="AverageMeter">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#danling.metrics.average_meter.AverageMeter.reset" class="md-nav__link">
    <span class="md-ellipsis">
      reset()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#danling.metrics.average_meter.AverageMeter.update" class="md-nav__link">
    <span class="md-ellipsis">
      update()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#danling.MultiHeadAttention" class="md-nav__link">
    <span class="md-ellipsis">
      MultiHeadAttention
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MultiHeadAttention">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#danling.models.transformer.attention.multihead_attention.MultiHeadAttention.attention" class="md-nav__link">
    <span class="md-ellipsis">
      attention()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#danling.models.transformer.attention.multihead_attention.MultiHeadAttention.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#danling.models.transformer.attention.multihead_attention.MultiHeadAttention.in_projection" class="md-nav__link">
    <span class="md-ellipsis">
      in_projection()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#danling.NestedTensor" class="md-nav__link">
    <span class="md-ellipsis">
      NestedTensor
    </span>
  </a>
  
    <nav class="md-nav" aria-label="NestedTensor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#danling.NestedTensor--notes" class="md-nav__link">
    <span class="md-ellipsis">
      Notes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#danling.tensors.nested_tensor.NestedTensor.device" class="md-nav__link">
    <span class="md-ellipsis">
      device()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#danling.tensors.nested_tensor.NestedTensor.mask" class="md-nav__link">
    <span class="md-ellipsis">
      mask()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#danling.tensors.nested_tensor.NestedTensor.shape" class="md-nav__link">
    <span class="md-ellipsis">
      shape()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#danling.tensors.nested_tensor.NestedTensor.size" class="md-nav__link">
    <span class="md-ellipsis">
      size()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#danling.tensors.nested_tensor.NestedTensor.tensor" class="md-nav__link">
    <span class="md-ellipsis">
      tensor()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#danling.Registry" class="md-nav__link">
    <span class="md-ellipsis">
      Registry
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Registry">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#danling.Registry--notes" class="md-nav__link">
    <span class="md-ellipsis">
      Notes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#danling.registry.registry.Registry.build" class="md-nav__link">
    <span class="md-ellipsis">
      build()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#danling.registry.registry.Registry.lookup" class="md-nav__link">
    <span class="md-ellipsis">
      lookup()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#danling.registry.registry.Registry.register" class="md-nav__link">
    <span class="md-ellipsis">
      register()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#danling.SelfAttention" class="md-nav__link">
    <span class="md-ellipsis">
      SelfAttention
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SelfAttention">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#danling.models.transformer.attention.self_attention.SelfAttention.attention" class="md-nav__link">
    <span class="md-ellipsis">
      attention()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#danling.models.transformer.attention.self_attention.SelfAttention.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#danling.models.transformer.attention.self_attention.SelfAttention.in_projection" class="md-nav__link">
    <span class="md-ellipsis">
      in_projection()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#danling.TorchRunner" class="md-nav__link">
    <span class="md-ellipsis">
      TorchRunner
    </span>
  </a>
  
    <nav class="md-nav" aria-label="TorchRunner">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#danling.runner.torch_runner.TorchRunner.init_distributed" class="md-nav__link">
    <span class="md-ellipsis">
      init_distributed()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#danling.runner.torch_runner.TorchRunner.init_tensorboard" class="md-nav__link">
    <span class="md-ellipsis">
      init_tensorboard()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#danling.runner.torch_runner.TorchRunner.load" class="md-nav__link">
    <span class="md-ellipsis">
      load()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#danling.runner.torch_runner.TorchRunner.local_rank" class="md-nav__link">
    <span class="md-ellipsis">
      local_rank()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#danling.runner.torch_runner.TorchRunner.rank" class="md-nav__link">
    <span class="md-ellipsis">
      rank()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#danling.runner.torch_runner.TorchRunner.save" class="md-nav__link">
    <span class="md-ellipsis">
      save()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#danling.runner.torch_runner.TorchRunner.set_deterministic" class="md-nav__link">
    <span class="md-ellipsis">
      set_deterministic()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#danling.runner.torch_runner.TorchRunner.set_seed" class="md-nav__link">
    <span class="md-ellipsis">
      set_seed()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#danling.runner.torch_runner.TorchRunner.world_size" class="md-nav__link">
    <span class="md-ellipsis">
      world_size()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#danling.TransformerDecoder" class="md-nav__link">
    <span class="md-ellipsis">
      TransformerDecoder
    </span>
  </a>
  
    <nav class="md-nav" aria-label="TransformerDecoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#danling.models.transformer.decoder.TransformerDecoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#danling.TransformerDecoderLayer" class="md-nav__link">
    <span class="md-ellipsis">
      TransformerDecoderLayer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="TransformerDecoderLayer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#danling.models.transformer.decoder.TransformerDecoderLayer.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#danling.TransformerEncoder" class="md-nav__link">
    <span class="md-ellipsis">
      TransformerEncoder
    </span>
  </a>
  
    <nav class="md-nav" aria-label="TransformerEncoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#danling.models.transformer.encoder.TransformerEncoder.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#danling.TransformerEncoderLayer" class="md-nav__link">
    <span class="md-ellipsis">
      TransformerEncoderLayer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="TransformerEncoderLayer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#danling.models.transformer.encoder.TransformerEncoderLayer.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#danling.UnitedPositionEmbedding" class="md-nav__link">
    <span class="md-ellipsis">
      UnitedPositionEmbedding
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#danling.catch" class="md-nav__link">
    <span class="md-ellipsis">
      catch()
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#danling.load" class="md-nav__link">
    <span class="md-ellipsis">
      load()
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                 
                  
  



  <a href="https://github.com/ZhiyuanChen/DanLing/edit/master/docs/package.md" title="ç¼è¾æ­¤é¡µ" class="md-content__button md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
  </a>


<h1 id="danling_1">DanLing<a class="headerlink" href="#danling_1" title="Permanent link">&para;</a></h1>


<div class="doc doc-object doc-module">


<a id="danling"></a>
  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="danling.AverageMeter" class="doc doc-heading">
        <code>AverageMeter</code>


<a href="#danling.AverageMeter" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">

  
      <p>Computes and stores the average and current value.</p>

  <p><strong>Attributes:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>val</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Current value.</p></td>
        </tr>
        <tr>
          <td><code>avg</code></td>
          <td>
                <code>float</code>
          </td>
          <td><p>Average value.</p></td>
        </tr>
        <tr>
          <td><code>sum</code></td>
          <td>
                <code>float</code>
          </td>
          <td><p>Sum of values.</p></td>
        </tr>
        <tr>
          <td><code>count</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Number of values.</p></td>
        </tr>
    </tbody>
  </table>

<p><strong>Examples:</strong></p>
    <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-0-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-0-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-0-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-0-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-0-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-0-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-0-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-0-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-0-10">10</a></span>
<span class="normal"><a href="#__codelineno-0-11">11</a></span>
<span class="normal"><a href="#__codelineno-0-12">12</a></span>
<span class="normal"><a href="#__codelineno-0-13">13</a></span>
<span class="normal"><a href="#__codelineno-0-14">14</a></span>
<span class="normal"><a href="#__codelineno-0-15">15</a></span>
<span class="normal"><a href="#__codelineno-0-16">16</a></span>
<span class="normal"><a href="#__codelineno-0-17">17</a></span>
<span class="normal"><a href="#__codelineno-0-18">18</a></span>
<span class="normal"><a href="#__codelineno-0-19">19</a></span>
<span class="normal"><a href="#__codelineno-0-20">20</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">meter</span> <span class="o">=</span> <span class="n">AverageMeter</span><span class="p">()</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">meter</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mf">0.7</span><span class="p">)</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">meter</span><span class="o">.</span><span class="n">val</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="mf">0.7</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">meter</span><span class="o">.</span><span class="n">avg</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="mf">0.7</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">meter</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mf">0.9</span><span class="p">)</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">meter</span><span class="o">.</span><span class="n">val</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="mf">0.9</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">meter</span><span class="o">.</span><span class="n">avg</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="mf">0.8</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">meter</span><span class="o">.</span><span class="n">sum</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a><span class="mf">1.6</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">meter</span><span class="o">.</span><span class="n">count</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a><span class="mi">2</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">meter</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">meter</span><span class="o">.</span><span class="n">val</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a><span class="mi">0</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">meter</span><span class="o">.</span><span class="n">avg</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a><span class="mi">0</span>
</code></pre></div></td></tr></table></div>


        <details class="quote">
          <summary>Source code in <code>danling/metrics/average_meter.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1">  1</a></span>
<span class="normal"><a href="#__codelineno-0-2">  2</a></span>
<span class="normal"><a href="#__codelineno-0-3">  3</a></span>
<span class="normal"><a href="#__codelineno-0-4">  4</a></span>
<span class="normal"><a href="#__codelineno-0-5">  5</a></span>
<span class="normal"><a href="#__codelineno-0-6">  6</a></span>
<span class="normal"><a href="#__codelineno-0-7">  7</a></span>
<span class="normal"><a href="#__codelineno-0-8">  8</a></span>
<span class="normal"><a href="#__codelineno-0-9">  9</a></span>
<span class="normal"><a href="#__codelineno-0-10"> 10</a></span>
<span class="normal"><a href="#__codelineno-0-11"> 11</a></span>
<span class="normal"><a href="#__codelineno-0-12"> 12</a></span>
<span class="normal"><a href="#__codelineno-0-13"> 13</a></span>
<span class="normal"><a href="#__codelineno-0-14"> 14</a></span>
<span class="normal"><a href="#__codelineno-0-15"> 15</a></span>
<span class="normal"><a href="#__codelineno-0-16"> 16</a></span>
<span class="normal"><a href="#__codelineno-0-17"> 17</a></span>
<span class="normal"><a href="#__codelineno-0-18"> 18</a></span>
<span class="normal"><a href="#__codelineno-0-19"> 19</a></span>
<span class="normal"><a href="#__codelineno-0-20"> 20</a></span>
<span class="normal"><a href="#__codelineno-0-21"> 21</a></span>
<span class="normal"><a href="#__codelineno-0-22"> 22</a></span>
<span class="normal"><a href="#__codelineno-0-23"> 23</a></span>
<span class="normal"><a href="#__codelineno-0-24"> 24</a></span>
<span class="normal"><a href="#__codelineno-0-25"> 25</a></span>
<span class="normal"><a href="#__codelineno-0-26"> 26</a></span>
<span class="normal"><a href="#__codelineno-0-27"> 27</a></span>
<span class="normal"><a href="#__codelineno-0-28"> 28</a></span>
<span class="normal"><a href="#__codelineno-0-29"> 29</a></span>
<span class="normal"><a href="#__codelineno-0-30"> 30</a></span>
<span class="normal"><a href="#__codelineno-0-31"> 31</a></span>
<span class="normal"><a href="#__codelineno-0-32"> 32</a></span>
<span class="normal"><a href="#__codelineno-0-33"> 33</a></span>
<span class="normal"><a href="#__codelineno-0-34"> 34</a></span>
<span class="normal"><a href="#__codelineno-0-35"> 35</a></span>
<span class="normal"><a href="#__codelineno-0-36"> 36</a></span>
<span class="normal"><a href="#__codelineno-0-37"> 37</a></span>
<span class="normal"><a href="#__codelineno-0-38"> 38</a></span>
<span class="normal"><a href="#__codelineno-0-39"> 39</a></span>
<span class="normal"><a href="#__codelineno-0-40"> 40</a></span>
<span class="normal"><a href="#__codelineno-0-41"> 41</a></span>
<span class="normal"><a href="#__codelineno-0-42"> 42</a></span>
<span class="normal"><a href="#__codelineno-0-43"> 43</a></span>
<span class="normal"><a href="#__codelineno-0-44"> 44</a></span>
<span class="normal"><a href="#__codelineno-0-45"> 45</a></span>
<span class="normal"><a href="#__codelineno-0-46"> 46</a></span>
<span class="normal"><a href="#__codelineno-0-47"> 47</a></span>
<span class="normal"><a href="#__codelineno-0-48"> 48</a></span>
<span class="normal"><a href="#__codelineno-0-49"> 49</a></span>
<span class="normal"><a href="#__codelineno-0-50"> 50</a></span>
<span class="normal"><a href="#__codelineno-0-51"> 51</a></span>
<span class="normal"><a href="#__codelineno-0-52"> 52</a></span>
<span class="normal"><a href="#__codelineno-0-53"> 53</a></span>
<span class="normal"><a href="#__codelineno-0-54"> 54</a></span>
<span class="normal"><a href="#__codelineno-0-55"> 55</a></span>
<span class="normal"><a href="#__codelineno-0-56"> 56</a></span>
<span class="normal"><a href="#__codelineno-0-57"> 57</a></span>
<span class="normal"><a href="#__codelineno-0-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-0-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-0-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-0-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-0-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-0-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-0-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-0-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-0-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-0-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-0-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-0-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-0-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-0-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="k">class</span> <span class="nc">AverageMeter</span><span class="p">:</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="sd">    Computes and stores the average and current value.</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="sd">    Attributes</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">    val: int</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="sd">        Current value.</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="sd">    avg: float</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="sd">        Average value.</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">    sum: float</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="sd">        Sum of values.</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a><span class="sd">    count: int</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a><span class="sd">        Number of values.</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a><span class="sd">    Examples</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a><span class="sd">    --------</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a><span class="sd">    &gt;&gt;&gt; meter = AverageMeter()</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a><span class="sd">    &gt;&gt;&gt; meter.update(0.7)</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a><span class="sd">    &gt;&gt;&gt; meter.val</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a><span class="sd">    0.7</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a><span class="sd">    &gt;&gt;&gt; meter.avg</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a><span class="sd">    0.7</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a><span class="sd">    &gt;&gt;&gt; meter.update(0.9)</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a><span class="sd">    &gt;&gt;&gt; meter.val</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a><span class="sd">    0.9</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a><span class="sd">    &gt;&gt;&gt; meter.avg</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a><span class="sd">    0.8</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a><span class="sd">    &gt;&gt;&gt; meter.sum</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="sd">    1.6</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a><span class="sd">    &gt;&gt;&gt; meter.count</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a><span class="sd">    2</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a><span class="sd">    &gt;&gt;&gt; meter.reset()</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a><span class="sd">    &gt;&gt;&gt; meter.val</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a><span class="sd">    0</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a><span class="sd">    &gt;&gt;&gt; meter.avg</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a><span class="sd">    0</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a><span class="sd">    ```</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a>    <span class="n">val</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>    <span class="n">avg</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a>    <span class="nb">sum</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>    <span class="n">count</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a><span class="sd">        Resets the meter.</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a><span class="sd">        Examples</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="sd">        --------</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a><span class="sd">        ```python</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a><span class="sd">        &gt;&gt;&gt; meter = AverageMeter()</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a><span class="sd">        &gt;&gt;&gt; meter.update(0.7)</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="sd">        &gt;&gt;&gt; meter.val</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a><span class="sd">        0.7</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">        &gt;&gt;&gt; meter.avg</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a><span class="sd">        0.7</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a><span class="sd">        &gt;&gt;&gt; meter.reset()</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a><span class="sd">        &gt;&gt;&gt; meter.val</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a><span class="sd">        0</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a><span class="sd">        &gt;&gt;&gt; meter.avg</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a><span class="sd">        0</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a><span class="sd">        ```</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">val</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">avg</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">sum</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a><span class="sd">        Updates the average and current value in the meter.</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a><span class="sd">        Parameters</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a><span class="sd">        ----------</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a><span class="sd">        val: int</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a><span class="sd">            Value to be added to the average.</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a><span class="sd">        n: int = 1</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a><span class="sd">            Number of values to be added.</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a><span class="sd">        Examples</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a><span class="sd">        --------</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a><span class="sd">        ```python</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a><span class="sd">        &gt;&gt;&gt; meter = AverageMeter()</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a><span class="sd">        &gt;&gt;&gt; meter.update(0.7)</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a><span class="sd">        &gt;&gt;&gt; meter.val</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a><span class="sd">        0.7</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a><span class="sd">        &gt;&gt;&gt; meter.avg</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a><span class="sd">        0.7</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a><span class="sd">        &gt;&gt;&gt; meter.update(0.9)</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a><span class="sd">        &gt;&gt;&gt; meter.val</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a><span class="sd">        0.9</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a><span class="sd">        &gt;&gt;&gt; meter.avg</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a><span class="sd">        0.8</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a><span class="sd">        &gt;&gt;&gt; meter.sum</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a><span class="sd">        1.6</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a><span class="sd">        &gt;&gt;&gt; meter.count</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a><span class="sd">        2</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a><span class="sd">        ```</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>        <span class="c1"># pylint: disable=C0103</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">val</span> <span class="o">=</span> <span class="n">val</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">sum</span> <span class="o">+=</span> <span class="n">val</span> <span class="o">*</span> <span class="n">n</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">+=</span> <span class="n">n</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">avg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sum</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">count</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h3 id="danling.metrics.average_meter.AverageMeter.reset" class="doc doc-heading">
<code class="highlight language-python"><span class="n">reset</span><span class="p">()</span></code>

<a href="#danling.metrics.average_meter.AverageMeter.reset" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Resets the meter.</p>

<p><strong>Examples:</strong></p>
    <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-0-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-0-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-0-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-0-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-0-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-0-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-0-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-0-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-0-10">10</a></span>
<span class="normal"><a href="#__codelineno-0-11">11</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">meter</span> <span class="o">=</span> <span class="n">AverageMeter</span><span class="p">()</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">meter</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mf">0.7</span><span class="p">)</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">meter</span><span class="o">.</span><span class="n">val</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="mf">0.7</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">meter</span><span class="o">.</span><span class="n">avg</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="mf">0.7</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">meter</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">meter</span><span class="o">.</span><span class="n">val</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="mi">0</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">meter</span><span class="o">.</span><span class="n">avg</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="mi">0</span>
</code></pre></div></td></tr></table></div>

      <details class="quote">
        <summary>Source code in <code>danling/metrics/average_meter.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-51">51</a></span>
<span class="normal"><a href="#__codelineno-0-52">52</a></span>
<span class="normal"><a href="#__codelineno-0-53">53</a></span>
<span class="normal"><a href="#__codelineno-0-54">54</a></span>
<span class="normal"><a href="#__codelineno-0-55">55</a></span>
<span class="normal"><a href="#__codelineno-0-56">56</a></span>
<span class="normal"><a href="#__codelineno-0-57">57</a></span>
<span class="normal"><a href="#__codelineno-0-58">58</a></span>
<span class="normal"><a href="#__codelineno-0-59">59</a></span>
<span class="normal"><a href="#__codelineno-0-60">60</a></span>
<span class="normal"><a href="#__codelineno-0-61">61</a></span>
<span class="normal"><a href="#__codelineno-0-62">62</a></span>
<span class="normal"><a href="#__codelineno-0-63">63</a></span>
<span class="normal"><a href="#__codelineno-0-64">64</a></span>
<span class="normal"><a href="#__codelineno-0-65">65</a></span>
<span class="normal"><a href="#__codelineno-0-66">66</a></span>
<span class="normal"><a href="#__codelineno-0-67">67</a></span>
<span class="normal"><a href="#__codelineno-0-68">68</a></span>
<span class="normal"><a href="#__codelineno-0-69">69</a></span>
<span class="normal"><a href="#__codelineno-0-70">70</a></span>
<span class="normal"><a href="#__codelineno-0-71">71</a></span>
<span class="normal"><a href="#__codelineno-0-72">72</a></span>
<span class="normal"><a href="#__codelineno-0-73">73</a></span>
<span class="normal"><a href="#__codelineno-0-74">74</a></span>
<span class="normal"><a href="#__codelineno-0-75">75</a></span>
<span class="normal"><a href="#__codelineno-0-76">76</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a><span class="sd">    Resets the meter.</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a><span class="sd">    Examples</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="sd">    --------</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a><span class="sd">    &gt;&gt;&gt; meter = AverageMeter()</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a><span class="sd">    &gt;&gt;&gt; meter.update(0.7)</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="sd">    &gt;&gt;&gt; meter.val</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a><span class="sd">    0.7</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">    &gt;&gt;&gt; meter.avg</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a><span class="sd">    0.7</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a><span class="sd">    &gt;&gt;&gt; meter.reset()</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a><span class="sd">    &gt;&gt;&gt; meter.val</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a><span class="sd">    0</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a><span class="sd">    &gt;&gt;&gt; meter.avg</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a><span class="sd">    0</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a><span class="sd">    ```</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">val</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">avg</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">sum</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="danling.metrics.average_meter.AverageMeter.update" class="doc doc-heading">
<code class="highlight language-python"><span class="n">update</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code>

<a href="#danling.metrics.average_meter.AverageMeter.update" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Updates the average and current value in the meter.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>val</code></td>
          <td>
          </td>
          <td><p>Value to be added to the average.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>n</code></td>
          <td>
                <code>int</code>
          </td>
          <td><p>Number of values to be added.</p></td>
          <td>
                <code>1</code>
          </td>
        </tr>
    </tbody>
  </table>

<p><strong>Examples:</strong></p>
    <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-0-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-0-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-0-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-0-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-0-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-0-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-0-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-0-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-0-10">10</a></span>
<span class="normal"><a href="#__codelineno-0-11">11</a></span>
<span class="normal"><a href="#__codelineno-0-12">12</a></span>
<span class="normal"><a href="#__codelineno-0-13">13</a></span>
<span class="normal"><a href="#__codelineno-0-14">14</a></span>
<span class="normal"><a href="#__codelineno-0-15">15</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">meter</span> <span class="o">=</span> <span class="n">AverageMeter</span><span class="p">()</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">meter</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mf">0.7</span><span class="p">)</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">meter</span><span class="o">.</span><span class="n">val</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="mf">0.7</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">meter</span><span class="o">.</span><span class="n">avg</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="mf">0.7</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">meter</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mf">0.9</span><span class="p">)</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">meter</span><span class="o">.</span><span class="n">val</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="mf">0.9</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">meter</span><span class="o">.</span><span class="n">avg</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="mf">0.8</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">meter</span><span class="o">.</span><span class="n">sum</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a><span class="mf">1.6</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">meter</span><span class="o">.</span><span class="n">count</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a><span class="mi">2</span>
</code></pre></div></td></tr></table></div>

      <details class="quote">
        <summary>Source code in <code>danling/metrics/average_meter.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-78" name="__codelineno-0-78"></a><span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a><span class="sd">    Updates the average and current value in the meter.</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a><span class="sd">    val: int</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a><span class="sd">        Value to be added to the average.</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a><span class="sd">    n: int = 1</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a><span class="sd">        Number of values to be added.</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a><span class="sd">    Examples</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a><span class="sd">    --------</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a><span class="sd">    &gt;&gt;&gt; meter = AverageMeter()</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a><span class="sd">    &gt;&gt;&gt; meter.update(0.7)</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a><span class="sd">    &gt;&gt;&gt; meter.val</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a><span class="sd">    0.7</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a><span class="sd">    &gt;&gt;&gt; meter.avg</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a><span class="sd">    0.7</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a><span class="sd">    &gt;&gt;&gt; meter.update(0.9)</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a><span class="sd">    &gt;&gt;&gt; meter.val</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a><span class="sd">    0.9</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a><span class="sd">    &gt;&gt;&gt; meter.avg</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a><span class="sd">    0.8</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a><span class="sd">    &gt;&gt;&gt; meter.sum</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a><span class="sd">    1.6</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a><span class="sd">    &gt;&gt;&gt; meter.count</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a><span class="sd">    2</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a><span class="sd">    ```</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>    <span class="c1"># pylint: disable=C0103</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">val</span> <span class="o">=</span> <span class="n">val</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">sum</span> <span class="o">+=</span> <span class="n">val</span> <span class="o">*</span> <span class="n">n</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">+=</span> <span class="n">n</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">avg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sum</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">count</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="danling.MultiHeadAttention" class="doc doc-heading">
        <code>MultiHeadAttention</code>


<a href="#danling.MultiHeadAttention" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
      <p class="doc doc-class-bases">
        Bases: <code><span title="torch.nn">nn</span>.<span title="torch.nn.Module">Module</span></code></p>

  
      <p>Allows the model to jointly attend to information
from different representation subspaces.
See <code>Attention Is All You Need &lt;https://arxiv.org/abs/1706.03762&gt;</code>_
.. math::
    \text{MultiHead}(Q, K, V) = \text{Concat}(head_1,\dots,head_h)W^O
where :math:<code>head_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)</code>.
Args:
    embed_dim: total dimension of the model.
    num_heads: parallel attention heads.
    dropout: a Dropout layer on attn_output_weights. Default: 0.0.
    bias: add bias as module parameter. Default: True.
    add_bias_kv: add bias to the key and value sequences at dim=0.
    add_zero_attn: add a new batch of zeros to the key and
                   value sequences at dim=1.
    k_dim: total number of features in key. Default: None.
    v_dim: total number of features in value. Default: None.
    batch_first: If <code>True</code>, then the input and output tensors are provided
        as (batch, seq, feature). Default: <code>False</code> (seq, batch, feature).
Note that if :attr:<code>k_dim</code> and :attr:<code>v_dim</code> are None, they will be set
to :attr:<code>embed_dim</code> such that query, key, and value have the same
number of features.
Examples::
    &gt;&gt;&gt; multihead_attn = dl.model.MultiHeadAttention(embed_dim, num_heads)
    &gt;&gt;&gt; attn_output, attn_output_weights = multihead_attn(query, key, value)</p>


        <details class="quote">
          <summary>Source code in <code>danling/models/transformer/attention/multihead_attention.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-9">  9</a></span>
<span class="normal"><a href="#__codelineno-0-10"> 10</a></span>
<span class="normal"><a href="#__codelineno-0-11"> 11</a></span>
<span class="normal"><a href="#__codelineno-0-12"> 12</a></span>
<span class="normal"><a href="#__codelineno-0-13"> 13</a></span>
<span class="normal"><a href="#__codelineno-0-14"> 14</a></span>
<span class="normal"><a href="#__codelineno-0-15"> 15</a></span>
<span class="normal"><a href="#__codelineno-0-16"> 16</a></span>
<span class="normal"><a href="#__codelineno-0-17"> 17</a></span>
<span class="normal"><a href="#__codelineno-0-18"> 18</a></span>
<span class="normal"><a href="#__codelineno-0-19"> 19</a></span>
<span class="normal"><a href="#__codelineno-0-20"> 20</a></span>
<span class="normal"><a href="#__codelineno-0-21"> 21</a></span>
<span class="normal"><a href="#__codelineno-0-22"> 22</a></span>
<span class="normal"><a href="#__codelineno-0-23"> 23</a></span>
<span class="normal"><a href="#__codelineno-0-24"> 24</a></span>
<span class="normal"><a href="#__codelineno-0-25"> 25</a></span>
<span class="normal"><a href="#__codelineno-0-26"> 26</a></span>
<span class="normal"><a href="#__codelineno-0-27"> 27</a></span>
<span class="normal"><a href="#__codelineno-0-28"> 28</a></span>
<span class="normal"><a href="#__codelineno-0-29"> 29</a></span>
<span class="normal"><a href="#__codelineno-0-30"> 30</a></span>
<span class="normal"><a href="#__codelineno-0-31"> 31</a></span>
<span class="normal"><a href="#__codelineno-0-32"> 32</a></span>
<span class="normal"><a href="#__codelineno-0-33"> 33</a></span>
<span class="normal"><a href="#__codelineno-0-34"> 34</a></span>
<span class="normal"><a href="#__codelineno-0-35"> 35</a></span>
<span class="normal"><a href="#__codelineno-0-36"> 36</a></span>
<span class="normal"><a href="#__codelineno-0-37"> 37</a></span>
<span class="normal"><a href="#__codelineno-0-38"> 38</a></span>
<span class="normal"><a href="#__codelineno-0-39"> 39</a></span>
<span class="normal"><a href="#__codelineno-0-40"> 40</a></span>
<span class="normal"><a href="#__codelineno-0-41"> 41</a></span>
<span class="normal"><a href="#__codelineno-0-42"> 42</a></span>
<span class="normal"><a href="#__codelineno-0-43"> 43</a></span>
<span class="normal"><a href="#__codelineno-0-44"> 44</a></span>
<span class="normal"><a href="#__codelineno-0-45"> 45</a></span>
<span class="normal"><a href="#__codelineno-0-46"> 46</a></span>
<span class="normal"><a href="#__codelineno-0-47"> 47</a></span>
<span class="normal"><a href="#__codelineno-0-48"> 48</a></span>
<span class="normal"><a href="#__codelineno-0-49"> 49</a></span>
<span class="normal"><a href="#__codelineno-0-50"> 50</a></span>
<span class="normal"><a href="#__codelineno-0-51"> 51</a></span>
<span class="normal"><a href="#__codelineno-0-52"> 52</a></span>
<span class="normal"><a href="#__codelineno-0-53"> 53</a></span>
<span class="normal"><a href="#__codelineno-0-54"> 54</a></span>
<span class="normal"><a href="#__codelineno-0-55"> 55</a></span>
<span class="normal"><a href="#__codelineno-0-56"> 56</a></span>
<span class="normal"><a href="#__codelineno-0-57"> 57</a></span>
<span class="normal"><a href="#__codelineno-0-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-0-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-0-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-0-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-0-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-0-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-0-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-0-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-0-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-0-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-0-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-0-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-0-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-0-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span>
<span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span>
<span class="normal"><a href="#__codelineno-0-203">203</a></span>
<span class="normal"><a href="#__codelineno-0-204">204</a></span>
<span class="normal"><a href="#__codelineno-0-205">205</a></span>
<span class="normal"><a href="#__codelineno-0-206">206</a></span>
<span class="normal"><a href="#__codelineno-0-207">207</a></span>
<span class="normal"><a href="#__codelineno-0-208">208</a></span>
<span class="normal"><a href="#__codelineno-0-209">209</a></span>
<span class="normal"><a href="#__codelineno-0-210">210</a></span>
<span class="normal"><a href="#__codelineno-0-211">211</a></span>
<span class="normal"><a href="#__codelineno-0-212">212</a></span>
<span class="normal"><a href="#__codelineno-0-213">213</a></span>
<span class="normal"><a href="#__codelineno-0-214">214</a></span>
<span class="normal"><a href="#__codelineno-0-215">215</a></span>
<span class="normal"><a href="#__codelineno-0-216">216</a></span>
<span class="normal"><a href="#__codelineno-0-217">217</a></span>
<span class="normal"><a href="#__codelineno-0-218">218</a></span>
<span class="normal"><a href="#__codelineno-0-219">219</a></span>
<span class="normal"><a href="#__codelineno-0-220">220</a></span>
<span class="normal"><a href="#__codelineno-0-221">221</a></span>
<span class="normal"><a href="#__codelineno-0-222">222</a></span>
<span class="normal"><a href="#__codelineno-0-223">223</a></span>
<span class="normal"><a href="#__codelineno-0-224">224</a></span>
<span class="normal"><a href="#__codelineno-0-225">225</a></span>
<span class="normal"><a href="#__codelineno-0-226">226</a></span>
<span class="normal"><a href="#__codelineno-0-227">227</a></span>
<span class="normal"><a href="#__codelineno-0-228">228</a></span>
<span class="normal"><a href="#__codelineno-0-229">229</a></span>
<span class="normal"><a href="#__codelineno-0-230">230</a></span>
<span class="normal"><a href="#__codelineno-0-231">231</a></span>
<span class="normal"><a href="#__codelineno-0-232">232</a></span>
<span class="normal"><a href="#__codelineno-0-233">233</a></span>
<span class="normal"><a href="#__codelineno-0-234">234</a></span>
<span class="normal"><a href="#__codelineno-0-235">235</a></span>
<span class="normal"><a href="#__codelineno-0-236">236</a></span>
<span class="normal"><a href="#__codelineno-0-237">237</a></span>
<span class="normal"><a href="#__codelineno-0-238">238</a></span>
<span class="normal"><a href="#__codelineno-0-239">239</a></span>
<span class="normal"><a href="#__codelineno-0-240">240</a></span>
<span class="normal"><a href="#__codelineno-0-241">241</a></span>
<span class="normal"><a href="#__codelineno-0-242">242</a></span>
<span class="normal"><a href="#__codelineno-0-243">243</a></span>
<span class="normal"><a href="#__codelineno-0-244">244</a></span>
<span class="normal"><a href="#__codelineno-0-245">245</a></span>
<span class="normal"><a href="#__codelineno-0-246">246</a></span>
<span class="normal"><a href="#__codelineno-0-247">247</a></span>
<span class="normal"><a href="#__codelineno-0-248">248</a></span>
<span class="normal"><a href="#__codelineno-0-249">249</a></span>
<span class="normal"><a href="#__codelineno-0-250">250</a></span>
<span class="normal"><a href="#__codelineno-0-251">251</a></span>
<span class="normal"><a href="#__codelineno-0-252">252</a></span>
<span class="normal"><a href="#__codelineno-0-253">253</a></span>
<span class="normal"><a href="#__codelineno-0-254">254</a></span>
<span class="normal"><a href="#__codelineno-0-255">255</a></span>
<span class="normal"><a href="#__codelineno-0-256">256</a></span>
<span class="normal"><a href="#__codelineno-0-257">257</a></span>
<span class="normal"><a href="#__codelineno-0-258">258</a></span>
<span class="normal"><a href="#__codelineno-0-259">259</a></span>
<span class="normal"><a href="#__codelineno-0-260">260</a></span>
<span class="normal"><a href="#__codelineno-0-261">261</a></span>
<span class="normal"><a href="#__codelineno-0-262">262</a></span>
<span class="normal"><a href="#__codelineno-0-263">263</a></span>
<span class="normal"><a href="#__codelineno-0-264">264</a></span>
<span class="normal"><a href="#__codelineno-0-265">265</a></span>
<span class="normal"><a href="#__codelineno-0-266">266</a></span>
<span class="normal"><a href="#__codelineno-0-267">267</a></span>
<span class="normal"><a href="#__codelineno-0-268">268</a></span>
<span class="normal"><a href="#__codelineno-0-269">269</a></span>
<span class="normal"><a href="#__codelineno-0-270">270</a></span>
<span class="normal"><a href="#__codelineno-0-271">271</a></span>
<span class="normal"><a href="#__codelineno-0-272">272</a></span>
<span class="normal"><a href="#__codelineno-0-273">273</a></span>
<span class="normal"><a href="#__codelineno-0-274">274</a></span>
<span class="normal"><a href="#__codelineno-0-275">275</a></span>
<span class="normal"><a href="#__codelineno-0-276">276</a></span>
<span class="normal"><a href="#__codelineno-0-277">277</a></span>
<span class="normal"><a href="#__codelineno-0-278">278</a></span>
<span class="normal"><a href="#__codelineno-0-279">279</a></span>
<span class="normal"><a href="#__codelineno-0-280">280</a></span>
<span class="normal"><a href="#__codelineno-0-281">281</a></span>
<span class="normal"><a href="#__codelineno-0-282">282</a></span>
<span class="normal"><a href="#__codelineno-0-283">283</a></span>
<span class="normal"><a href="#__codelineno-0-284">284</a></span>
<span class="normal"><a href="#__codelineno-0-285">285</a></span>
<span class="normal"><a href="#__codelineno-0-286">286</a></span>
<span class="normal"><a href="#__codelineno-0-287">287</a></span>
<span class="normal"><a href="#__codelineno-0-288">288</a></span>
<span class="normal"><a href="#__codelineno-0-289">289</a></span>
<span class="normal"><a href="#__codelineno-0-290">290</a></span>
<span class="normal"><a href="#__codelineno-0-291">291</a></span>
<span class="normal"><a href="#__codelineno-0-292">292</a></span>
<span class="normal"><a href="#__codelineno-0-293">293</a></span>
<span class="normal"><a href="#__codelineno-0-294">294</a></span>
<span class="normal"><a href="#__codelineno-0-295">295</a></span>
<span class="normal"><a href="#__codelineno-0-296">296</a></span>
<span class="normal"><a href="#__codelineno-0-297">297</a></span>
<span class="normal"><a href="#__codelineno-0-298">298</a></span>
<span class="normal"><a href="#__codelineno-0-299">299</a></span>
<span class="normal"><a href="#__codelineno-0-300">300</a></span>
<span class="normal"><a href="#__codelineno-0-301">301</a></span>
<span class="normal"><a href="#__codelineno-0-302">302</a></span>
<span class="normal"><a href="#__codelineno-0-303">303</a></span>
<span class="normal"><a href="#__codelineno-0-304">304</a></span>
<span class="normal"><a href="#__codelineno-0-305">305</a></span>
<span class="normal"><a href="#__codelineno-0-306">306</a></span>
<span class="normal"><a href="#__codelineno-0-307">307</a></span>
<span class="normal"><a href="#__codelineno-0-308">308</a></span>
<span class="normal"><a href="#__codelineno-0-309">309</a></span>
<span class="normal"><a href="#__codelineno-0-310">310</a></span>
<span class="normal"><a href="#__codelineno-0-311">311</a></span>
<span class="normal"><a href="#__codelineno-0-312">312</a></span>
<span class="normal"><a href="#__codelineno-0-313">313</a></span>
<span class="normal"><a href="#__codelineno-0-314">314</a></span>
<span class="normal"><a href="#__codelineno-0-315">315</a></span>
<span class="normal"><a href="#__codelineno-0-316">316</a></span>
<span class="normal"><a href="#__codelineno-0-317">317</a></span>
<span class="normal"><a href="#__codelineno-0-318">318</a></span>
<span class="normal"><a href="#__codelineno-0-319">319</a></span>
<span class="normal"><a href="#__codelineno-0-320">320</a></span>
<span class="normal"><a href="#__codelineno-0-321">321</a></span>
<span class="normal"><a href="#__codelineno-0-322">322</a></span>
<span class="normal"><a href="#__codelineno-0-323">323</a></span>
<span class="normal"><a href="#__codelineno-0-324">324</a></span>
<span class="normal"><a href="#__codelineno-0-325">325</a></span>
<span class="normal"><a href="#__codelineno-0-326">326</a></span>
<span class="normal"><a href="#__codelineno-0-327">327</a></span>
<span class="normal"><a href="#__codelineno-0-328">328</a></span>
<span class="normal"><a href="#__codelineno-0-329">329</a></span>
<span class="normal"><a href="#__codelineno-0-330">330</a></span>
<span class="normal"><a href="#__codelineno-0-331">331</a></span>
<span class="normal"><a href="#__codelineno-0-332">332</a></span>
<span class="normal"><a href="#__codelineno-0-333">333</a></span>
<span class="normal"><a href="#__codelineno-0-334">334</a></span>
<span class="normal"><a href="#__codelineno-0-335">335</a></span>
<span class="normal"><a href="#__codelineno-0-336">336</a></span>
<span class="normal"><a href="#__codelineno-0-337">337</a></span>
<span class="normal"><a href="#__codelineno-0-338">338</a></span>
<span class="normal"><a href="#__codelineno-0-339">339</a></span>
<span class="normal"><a href="#__codelineno-0-340">340</a></span>
<span class="normal"><a href="#__codelineno-0-341">341</a></span>
<span class="normal"><a href="#__codelineno-0-342">342</a></span>
<span class="normal"><a href="#__codelineno-0-343">343</a></span>
<span class="normal"><a href="#__codelineno-0-344">344</a></span>
<span class="normal"><a href="#__codelineno-0-345">345</a></span>
<span class="normal"><a href="#__codelineno-0-346">346</a></span>
<span class="normal"><a href="#__codelineno-0-347">347</a></span>
<span class="normal"><a href="#__codelineno-0-348">348</a></span>
<span class="normal"><a href="#__codelineno-0-349">349</a></span>
<span class="normal"><a href="#__codelineno-0-350">350</a></span>
<span class="normal"><a href="#__codelineno-0-351">351</a></span>
<span class="normal"><a href="#__codelineno-0-352">352</a></span>
<span class="normal"><a href="#__codelineno-0-353">353</a></span>
<span class="normal"><a href="#__codelineno-0-354">354</a></span>
<span class="normal"><a href="#__codelineno-0-355">355</a></span>
<span class="normal"><a href="#__codelineno-0-356">356</a></span>
<span class="normal"><a href="#__codelineno-0-357">357</a></span>
<span class="normal"><a href="#__codelineno-0-358">358</a></span>
<span class="normal"><a href="#__codelineno-0-359">359</a></span>
<span class="normal"><a href="#__codelineno-0-360">360</a></span>
<span class="normal"><a href="#__codelineno-0-361">361</a></span>
<span class="normal"><a href="#__codelineno-0-362">362</a></span>
<span class="normal"><a href="#__codelineno-0-363">363</a></span>
<span class="normal"><a href="#__codelineno-0-364">364</a></span>
<span class="normal"><a href="#__codelineno-0-365">365</a></span>
<span class="normal"><a href="#__codelineno-0-366">366</a></span>
<span class="normal"><a href="#__codelineno-0-367">367</a></span>
<span class="normal"><a href="#__codelineno-0-368">368</a></span>
<span class="normal"><a href="#__codelineno-0-369">369</a></span>
<span class="normal"><a href="#__codelineno-0-370">370</a></span>
<span class="normal"><a href="#__codelineno-0-371">371</a></span>
<span class="normal"><a href="#__codelineno-0-372">372</a></span>
<span class="normal"><a href="#__codelineno-0-373">373</a></span>
<span class="normal"><a href="#__codelineno-0-374">374</a></span>
<span class="normal"><a href="#__codelineno-0-375">375</a></span>
<span class="normal"><a href="#__codelineno-0-376">376</a></span>
<span class="normal"><a href="#__codelineno-0-377">377</a></span>
<span class="normal"><a href="#__codelineno-0-378">378</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="k">class</span> <span class="nc">MultiHeadAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Allows the model to jointly attend to information</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">    from different representation subspaces.</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="sd">    See `Attention Is All You Need &lt;https://arxiv.org/abs/1706.03762&gt;`_</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a><span class="sd">    .. math::</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a><span class="sd">        \text{MultiHead}(Q, K, V) = \text{Concat}(head_1,\dots,head_h)W^O</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a><span class="sd">    where :math:`head_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)`.</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a><span class="sd">        embed_dim: total dimension of the model.</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a><span class="sd">        num_heads: parallel attention heads.</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a><span class="sd">        dropout: a Dropout layer on attn_output_weights. Default: 0.0.</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a><span class="sd">        bias: add bias as module parameter. Default: True.</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a><span class="sd">        add_bias_kv: add bias to the key and value sequences at dim=0.</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a><span class="sd">        add_zero_attn: add a new batch of zeros to the key and</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a><span class="sd">                       value sequences at dim=1.</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a><span class="sd">        k_dim: total number of features in key. Default: None.</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a><span class="sd">        v_dim: total number of features in value. Default: None.</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a><span class="sd">        batch_first: If ``True``, then the input and output tensors are provided</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a><span class="sd">            as (batch, seq, feature). Default: ``False`` (seq, batch, feature).</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a><span class="sd">    Note that if :attr:`k_dim` and :attr:`v_dim` are None, they will be set</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a><span class="sd">    to :attr:`embed_dim` such that query, key, and value have the same</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a><span class="sd">    number of features.</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="sd">    Examples::</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a><span class="sd">        &gt;&gt;&gt; multihead_attn = dl.model.MultiHeadAttention(embed_dim, num_heads)</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a><span class="sd">        &gt;&gt;&gt; attn_output, attn_output_weights = multihead_attn(query, key, value)</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a>    <span class="n">__constants__</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;batch_first&quot;</span><span class="p">]</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a>    <span class="n">bias_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a>    <span class="n">bias_v</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>        <span class="n">embed_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a>        <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a>        <span class="n">attn_dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>        <span class="n">scale_factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a>        <span class="n">bias</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>        <span class="n">add_bias_kv</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>        <span class="n">add_zero_attn</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>        <span class="n">k_dim</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a>        <span class="n">v_dim</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a>        <span class="n">batch_first</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a>        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span> <span class="o">=</span> <span class="n">embed_dim</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">k_dim</span> <span class="o">=</span> <span class="n">k_dim</span> <span class="k">if</span> <span class="n">k_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">v_dim</span> <span class="o">=</span> <span class="n">v_dim</span> <span class="k">if</span> <span class="n">v_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_qkv_same_embed_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_dim</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_dim</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">scale_factor</span> <span class="o">=</span> <span class="n">scale_factor</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">batch_first</span> <span class="o">=</span> <span class="n">batch_first</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">scaling</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_factor</span><span class="p">)</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">:</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;embed_dim </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="si">}</span><span class="s2"> not divisible by num_heads </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_dim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">attn_dropout</span><span class="p">)</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>        <span class="k">if</span> <span class="n">add_bias_kv</span><span class="p">:</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">bias_k</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">)))</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">bias_v</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">)))</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">bias_k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_v</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">add_zero_attn</span> <span class="o">=</span> <span class="n">add_zero_attn</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_reset_parameters</span><span class="p">()</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>    <span class="k">def</span> <span class="nf">_reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_k</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_normal_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bias_k</span><span class="p">)</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_normal_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bias_v</span><span class="p">)</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a>    <span class="k">def</span> <span class="nf">__setstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a>        <span class="c1"># Support loading old MultiHeadAttention checkpoints generated by v1.1.0</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a>        <span class="k">if</span> <span class="s2">&quot;_qkv_same_embed_dim&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">state</span><span class="p">:</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a>            <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_qkv_same_embed_dim&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a>        <span class="nb">super</span><span class="p">(</span><span class="n">MultiHeadAttention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__setstate__</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>        <span class="n">query</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>        <span class="n">key</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>        <span class="n">value</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>        <span class="n">attn_bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>        <span class="n">attn_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>        <span class="n">key_padding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>        <span class="n">need_weights</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>        <span class="n">static_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>        <span class="n">static_v</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]]:</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a><span class="sd">            query, key, value: map a query and a set of key-value pairs to an output.</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a><span class="sd">                See &quot;Attention Is All You Need&quot; for more details.</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a><span class="sd">            attn_bias: 2D or 3D mask that add bias to attention output weights. Used for relative positional embedding.</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a><span class="sd">                A 2D bias will be broadcasted for all the batches while a 3D mask allows to specify a different mask for</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a><span class="sd">                the entries of each batch.</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a><span class="sd">            attn_mask: 2D or 3D mask that prevents attention to certain positions. A 2D mask will be broadcasted for all</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a><span class="sd">                the batches while a 3D mask allows to specify a different mask for the entries of each batch.</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a><span class="sd">            key_padding_mask: if provided, specified padding elements in the key will</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a><span class="sd">                be ignored by the attention. When given a binary mask and a value is True,</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a><span class="sd">                the corresponding value on the attention layer will be ignored. When given</span>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a><span class="sd">                a byte mask and a value is non-zero, the corresponding value on the attention</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a><span class="sd">                layer will be ignored</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a><span class="sd">            need_weights: output attn_output_weights.</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a><span class="sd">            static_k, static_v: static key and value used for attention operators.</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a><span class="sd">        Shapes for inputs:</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a><span class="sd">            - query: :math:`(L, N, E)` where L is the target sequence length, N is the batch size, E is</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a><span class="sd">                the embedding dimension. :math:`(N, L, E)` if ``batch_first`` is ``True``.</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a><span class="sd">            - key: :math:`(S, N, E)`, where S is the source sequence length, N is the batch size, E is</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a><span class="sd">                the embedding dimension. :math:`(N, S, E)` if ``batch_first`` is ``True``.</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a><span class="sd">            - value: :math:`(S, N, E)` where S is the source sequence length, N is the batch size, E is</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a><span class="sd">                the embedding dimension. :math:`(N, S, E)` if ``batch_first`` is ``True``.</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a><span class="sd">            - attn_bias: if a 2D mask: :math:`(L, S)` where L is the target sequence length, S is the</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a><span class="sd">                source sequence length.</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a><span class="sd">                If a 3D mask: :math:`(N\cdot\text{num\_heads}, L, S)` where N is the batch size, L is the target sequence</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a><span class="sd">                length, S is the source sequence length. ``attn_bias`` allows to pass pos embed directly into attention</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a><span class="sd">                If a ByteTensor is provided, the non-zero positions are not allowed to attend while the zero positions will</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a><span class="sd">                be unchanged. If a BoolTensor is provided, positions with ``True`` is not allowed to attend while ``False``</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a><span class="sd">                values will be unchanged. If a FloatTensor is provided, it will be added to the attention weight.</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a><span class="sd">            - attn_mask: if a 2D mask: :math:`(L, S)` where L is the target sequence length, S is the</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a><span class="sd">                source sequence length.</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a><span class="sd">                If a 3D mask: :math:`(N\cdot\text{num\_heads}, L, S)` where N is the batch size, L is the target sequence</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a><span class="sd">                length, S is the source sequence length. ``attn_mask`` ensure that position i is allowed to attend</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a><span class="sd">                the unmasked positions. If a ByteTensor is provided, the non-zero positions are not allowed to attend</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a><span class="sd">                while the zero positions will be unchanged. If a BoolTensor is provided, positions with ``True``</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a><span class="sd">                is not allowed to attend while ``False`` values will be unchanged. If a FloatTensor</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a><span class="sd">                is provided, it will be added to the attention weight.</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a><span class="sd">            - key_padding_mask: :math:`(N, S)` where N is the batch size, S is the source sequence length.</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a><span class="sd">                If a ByteTensor is provided, the non-zero positions will be ignored while the position</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a><span class="sd">                with the zero positions will be unchanged. If a BoolTensor is provided, the positions with the</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a><span class="sd">                value of ``True`` will be ignored while the position with the value of ``False`` will be unchanged.</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a><span class="sd">            - static_k: :math:`(N*num_heads, S, E/num_heads)`, where S is the source sequence length,</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a><span class="sd">                N is the batch size, E is the embedding dimension. E/num_heads is the head dimension.</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a><span class="sd">            - static_v: :math:`(N*num_heads, S, E/num_heads)`, where S is the source sequence length,</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a><span class="sd">                N is the batch size, E is the embedding dimension. E/num_heads is the head dimension.</span>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a><span class="sd">        Outputs:</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a><span class="sd">            - attn_output: :math:`(L, N, E)` where L is the target sequence length, N is the batch size,</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a><span class="sd">                E is the embedding dimension. :math:`(N, L, E)` if ``batch_first`` is ``True``.</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a><span class="sd">            - attn_output_weights: :math:`(N, L, S)` where N is the batch size,</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a><span class="sd">                L is the target sequence length, S is the source sequence length.</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_first</span><span class="p">:</span>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a>            <span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)]</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a>        <span class="c1"># set up shape vars</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a>        <span class="n">target_len</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">embed_dim</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a>        <span class="n">source_len</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">key</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]:</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;key&#39;s sequence and batch dims </span><span class="si">{</span><span class="n">key</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="s2"> do not match value&#39;s </span><span class="si">{</span><span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a>        <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_projection</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a>        <span class="c1"># prep attention mask</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a>        <span class="k">if</span> <span class="n">attn_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a>            <span class="k">if</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">:</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a>                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a>                    <span class="s2">&quot;attn_mask is of type uint8. This type is deprecated. Please use bool or float tensors instead.&quot;</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a>                <span class="p">)</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a>                <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a>            <span class="k">elif</span> <span class="ow">not</span> <span class="p">(</span><span class="n">attn_mask</span><span class="o">.</span><span class="n">is_floating_point</span><span class="p">()</span> <span class="ow">or</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">):</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;attn_mask should have type float or bool, but got </span><span class="si">{</span><span class="n">attn_mask</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a>            <span class="c1"># ensure attn_mask&#39;s dim is 3</span>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a>            <span class="k">if</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a>                <span class="n">correct_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">target_len</span><span class="p">,</span> <span class="n">source_len</span><span class="p">)</span>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a>                <span class="k">if</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">correct_shape</span><span class="p">:</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a>                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;attn_mask should have shape </span><span class="si">{</span><span class="n">correct_shape</span><span class="si">}</span><span class="s2">, but got </span><span class="si">{</span><span class="n">attn_mask</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a>                <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a>            <span class="k">elif</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a>                <span class="n">correct_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">target_len</span><span class="p">,</span> <span class="n">source_len</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>                <span class="k">if</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">correct_shape</span><span class="p">:</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a>                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;attn_mask should have shape </span><span class="si">{</span><span class="n">correct_shape</span><span class="si">}</span><span class="s2">, but got </span><span class="si">{</span><span class="n">attn_mask</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a>                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;attn_mask should have dimension 2 or 3, bug got </span><span class="si">{</span><span class="n">attn_mask</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a>        <span class="c1"># prep key padding mask</span>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a>        <span class="k">if</span> <span class="n">key_padding_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">key_padding_mask</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">:</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a>            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a>                <span class="s2">&quot;key_padding_mask is of type uint8. This type is deprecated. Please use bool or float tensors instead.&quot;</span>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a>            <span class="p">)</span>
<a id="__codelineno-0-199" name="__codelineno-0-199"></a>            <span class="n">key_padding_mask</span> <span class="o">=</span> <span class="n">key_padding_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a>
<a id="__codelineno-0-201" name="__codelineno-0-201"></a>        <span class="c1"># add bias along batch dimension (currently second)</span>
<a id="__codelineno-0-202" name="__codelineno-0-202"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_k</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-203" name="__codelineno-0-203"></a>            <span class="k">assert</span> <span class="n">static_k</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;bias cannot be added to static key.&quot;</span>
<a id="__codelineno-0-204" name="__codelineno-0-204"></a>            <span class="k">assert</span> <span class="n">static_v</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;bias cannot be added to static value.&quot;</span>
<a id="__codelineno-0-205" name="__codelineno-0-205"></a>            <span class="n">k</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">k</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_k</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)])</span>
<a id="__codelineno-0-206" name="__codelineno-0-206"></a>            <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">v</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_v</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)])</span>
<a id="__codelineno-0-207" name="__codelineno-0-207"></a>            <span class="k">if</span> <span class="n">attn_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-208" name="__codelineno-0-208"></a>                <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">attn_mask</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<a id="__codelineno-0-209" name="__codelineno-0-209"></a>            <span class="k">if</span> <span class="n">key_padding_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-210" name="__codelineno-0-210"></a>                <span class="n">key_padding_mask</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">key_padding_mask</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<a id="__codelineno-0-211" name="__codelineno-0-211"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-212" name="__codelineno-0-212"></a>            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_k</span> <span class="ow">is</span> <span class="kc">None</span>
<a id="__codelineno-0-213" name="__codelineno-0-213"></a>            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_v</span> <span class="ow">is</span> <span class="kc">None</span>
<a id="__codelineno-0-214" name="__codelineno-0-214"></a>
<a id="__codelineno-0-215" name="__codelineno-0-215"></a>        <span class="c1"># reshape q, k, v for multihead attention and make em batch first</span>
<a id="__codelineno-0-216" name="__codelineno-0-216"></a>        <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">target_len</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-217" name="__codelineno-0-217"></a>        <span class="n">k</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">static_k</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">static_k</span>
<a id="__codelineno-0-218" name="__codelineno-0-218"></a>        <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">static_v</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">static_v</span>
<a id="__codelineno-0-219" name="__codelineno-0-219"></a>
<a id="__codelineno-0-220" name="__codelineno-0-220"></a>        <span class="k">if</span> <span class="n">static_k</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-221" name="__codelineno-0-221"></a>            <span class="n">correct_shape</span> <span class="o">=</span> <span class="p">(</span>  <span class="c1"># type: ignore</span>
<a id="__codelineno-0-222" name="__codelineno-0-222"></a>                <span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span>
<a id="__codelineno-0-223" name="__codelineno-0-223"></a>                <span class="n">static_k</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
<a id="__codelineno-0-224" name="__codelineno-0-224"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">,</span>
<a id="__codelineno-0-225" name="__codelineno-0-225"></a>            <span class="p">)</span>
<a id="__codelineno-0-226" name="__codelineno-0-226"></a>            <span class="k">if</span> <span class="n">static_k</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">correct_shape</span><span class="p">:</span>
<a id="__codelineno-0-227" name="__codelineno-0-227"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;static_k should have shape </span><span class="si">{</span><span class="n">correct_shape</span><span class="si">}</span><span class="s2">, but got </span><span class="si">{</span><span class="n">static_k</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-228" name="__codelineno-0-228"></a>        <span class="k">if</span> <span class="n">static_v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-229" name="__codelineno-0-229"></a>            <span class="n">correct_shape</span> <span class="o">=</span> <span class="p">(</span>  <span class="c1"># type: ignore</span>
<a id="__codelineno-0-230" name="__codelineno-0-230"></a>                <span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span>
<a id="__codelineno-0-231" name="__codelineno-0-231"></a>                <span class="n">static_v</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
<a id="__codelineno-0-232" name="__codelineno-0-232"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">,</span>
<a id="__codelineno-0-233" name="__codelineno-0-233"></a>            <span class="p">)</span>
<a id="__codelineno-0-234" name="__codelineno-0-234"></a>            <span class="k">if</span> <span class="n">static_v</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">correct_shape</span><span class="p">:</span>
<a id="__codelineno-0-235" name="__codelineno-0-235"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;static_v should have shape </span><span class="si">{</span><span class="n">correct_shape</span><span class="si">}</span><span class="s2">, but got </span><span class="si">{</span><span class="n">static_v</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-236" name="__codelineno-0-236"></a>
<a id="__codelineno-0-237" name="__codelineno-0-237"></a>        <span class="c1"># add zero attention along batch dimension (now first)</span>
<a id="__codelineno-0-238" name="__codelineno-0-238"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_zero_attn</span><span class="p">:</span>
<a id="__codelineno-0-239" name="__codelineno-0-239"></a>            <span class="n">zero_attn_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">)</span>
<a id="__codelineno-0-240" name="__codelineno-0-240"></a>            <span class="n">k</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">k</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">zero_attn_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">k</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">k</span><span class="o">.</span><span class="n">device</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-241" name="__codelineno-0-241"></a>            <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">v</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">zero_attn_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">v</span><span class="o">.</span><span class="n">device</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-242" name="__codelineno-0-242"></a>            <span class="k">if</span> <span class="n">attn_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-243" name="__codelineno-0-243"></a>                <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">attn_mask</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<a id="__codelineno-0-244" name="__codelineno-0-244"></a>            <span class="k">if</span> <span class="n">key_padding_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-245" name="__codelineno-0-245"></a>                <span class="n">key_padding_mask</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">key_padding_mask</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<a id="__codelineno-0-246" name="__codelineno-0-246"></a>
<a id="__codelineno-0-247" name="__codelineno-0-247"></a>        <span class="c1"># update source sequence length after adjustments</span>
<a id="__codelineno-0-248" name="__codelineno-0-248"></a>        <span class="n">source_len</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-249" name="__codelineno-0-249"></a>
<a id="__codelineno-0-250" name="__codelineno-0-250"></a>        <span class="c1"># merge key padding and attention masks</span>
<a id="__codelineno-0-251" name="__codelineno-0-251"></a>        <span class="k">if</span> <span class="n">key_padding_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-252" name="__codelineno-0-252"></a>            <span class="k">if</span> <span class="n">key_padding_mask</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">source_len</span><span class="p">):</span>
<a id="__codelineno-0-253" name="__codelineno-0-253"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-254" name="__codelineno-0-254"></a>                    <span class="sa">f</span><span class="s2">&quot;key_padding_mask should have shape </span><span class="si">{</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">source_len</span><span class="p">)</span><span class="si">}</span><span class="s2">, but got </span><span class="si">{</span><span class="n">key_padding_mask</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
<a id="__codelineno-0-255" name="__codelineno-0-255"></a>                <span class="p">)</span>
<a id="__codelineno-0-256" name="__codelineno-0-256"></a>            <span class="n">key_padding_mask</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-257" name="__codelineno-0-257"></a>                <span class="n">key_padding_mask</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">source_len</span><span class="p">)</span>
<a id="__codelineno-0-258" name="__codelineno-0-258"></a>                <span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-259" name="__codelineno-0-259"></a>                <span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">source_len</span><span class="p">)</span>
<a id="__codelineno-0-260" name="__codelineno-0-260"></a>            <span class="p">)</span>
<a id="__codelineno-0-261" name="__codelineno-0-261"></a>            <span class="k">if</span> <span class="n">attn_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-262" name="__codelineno-0-262"></a>                <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">key_padding_mask</span>
<a id="__codelineno-0-263" name="__codelineno-0-263"></a>            <span class="k">elif</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">:</span>
<a id="__codelineno-0-264" name="__codelineno-0-264"></a>                <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">logical_or</span><span class="p">(</span><span class="n">key_padding_mask</span><span class="p">)</span>
<a id="__codelineno-0-265" name="__codelineno-0-265"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-266" name="__codelineno-0-266"></a>                <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">key_padding_mask</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;-inf&quot;</span><span class="p">))</span>
<a id="__codelineno-0-267" name="__codelineno-0-267"></a>
<a id="__codelineno-0-268" name="__codelineno-0-268"></a>        <span class="c1"># convert mask to float</span>
<a id="__codelineno-0-269" name="__codelineno-0-269"></a>        <span class="k">if</span> <span class="n">attn_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">:</span>
<a id="__codelineno-0-270" name="__codelineno-0-270"></a>            <span class="n">new_attn_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">attn_mask</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
<a id="__codelineno-0-271" name="__codelineno-0-271"></a>            <span class="n">new_attn_mask</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">attn_mask</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;-inf&quot;</span><span class="p">))</span>
<a id="__codelineno-0-272" name="__codelineno-0-272"></a>            <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">new_attn_mask</span>
<a id="__codelineno-0-273" name="__codelineno-0-273"></a>
<a id="__codelineno-0-274" name="__codelineno-0-274"></a>        <span class="c1"># (deep breath) calculate attention and out projection</span>
<a id="__codelineno-0-275" name="__codelineno-0-275"></a>        <span class="n">attn_output</span><span class="p">,</span> <span class="n">attn_output_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">attn_bias</span><span class="p">,</span> <span class="n">attn_mask</span><span class="p">)</span>
<a id="__codelineno-0-276" name="__codelineno-0-276"></a>        <span class="n">attn_output</span> <span class="o">=</span> <span class="n">attn_output</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">target_len</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">)</span>
<a id="__codelineno-0-277" name="__codelineno-0-277"></a>        <span class="n">attn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_projection</span><span class="p">(</span><span class="n">attn_output</span><span class="p">)</span>
<a id="__codelineno-0-278" name="__codelineno-0-278"></a>
<a id="__codelineno-0-279" name="__codelineno-0-279"></a>        <span class="c1"># attn_output_weights is set to torch.empty(0, requires_grad=False) to avoid errors in DDP</span>
<a id="__codelineno-0-280" name="__codelineno-0-280"></a>        <span class="n">attn_output_weights</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-281" name="__codelineno-0-281"></a>            <span class="n">attn_output_weights</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">target_len</span><span class="p">,</span> <span class="n">source_len</span><span class="p">)</span>
<a id="__codelineno-0-282" name="__codelineno-0-282"></a>            <span class="k">if</span> <span class="n">need_weights</span>
<a id="__codelineno-0-283" name="__codelineno-0-283"></a>            <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-0-284" name="__codelineno-0-284"></a>        <span class="p">)</span>
<a id="__codelineno-0-285" name="__codelineno-0-285"></a>
<a id="__codelineno-0-286" name="__codelineno-0-286"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_first</span><span class="p">:</span>
<a id="__codelineno-0-287" name="__codelineno-0-287"></a>            <span class="k">return</span> <span class="n">attn_output</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">attn_output_weights</span>
<a id="__codelineno-0-288" name="__codelineno-0-288"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-289" name="__codelineno-0-289"></a>            <span class="k">return</span> <span class="n">attn_output</span><span class="p">,</span> <span class="n">attn_output_weights</span>
<a id="__codelineno-0-290" name="__codelineno-0-290"></a>
<a id="__codelineno-0-291" name="__codelineno-0-291"></a>    <span class="k">def</span> <span class="nf">in_projection</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">v</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-292" name="__codelineno-0-292"></a>        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-293" name="__codelineno-0-293"></a><span class="sd">        Performs the in-projection step of the attention operation, using packed weights.</span>
<a id="__codelineno-0-294" name="__codelineno-0-294"></a><span class="sd">        Output is a triple containing projection tensors for query, key and value.</span>
<a id="__codelineno-0-295" name="__codelineno-0-295"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-296" name="__codelineno-0-296"></a><span class="sd">            q, k, v: query, key and value tensors to be projected. For self-attention,</span>
<a id="__codelineno-0-297" name="__codelineno-0-297"></a><span class="sd">                these are typically the same tensor; for encoder-decoder attention,</span>
<a id="__codelineno-0-298" name="__codelineno-0-298"></a><span class="sd">                k and v are typically the same tensor. (We take advantage of these</span>
<a id="__codelineno-0-299" name="__codelineno-0-299"></a><span class="sd">                identities for performance if they are present.) Regardless, q, k and v</span>
<a id="__codelineno-0-300" name="__codelineno-0-300"></a><span class="sd">                must share a common embedding dimension; otherwise their shapes may vary.</span>
<a id="__codelineno-0-301" name="__codelineno-0-301"></a><span class="sd">        Shape:</span>
<a id="__codelineno-0-302" name="__codelineno-0-302"></a><span class="sd">            Inputs:</span>
<a id="__codelineno-0-303" name="__codelineno-0-303"></a><span class="sd">            - q: :math:`(..., E)` where E is the embedding dimension</span>
<a id="__codelineno-0-304" name="__codelineno-0-304"></a><span class="sd">            - k: :math:`(..., E)` where E is the embedding dimension</span>
<a id="__codelineno-0-305" name="__codelineno-0-305"></a><span class="sd">            - v: :math:`(..., E)` where E is the embedding dimension</span>
<a id="__codelineno-0-306" name="__codelineno-0-306"></a><span class="sd">            Output:</span>
<a id="__codelineno-0-307" name="__codelineno-0-307"></a><span class="sd">            - in output list :math:`[q&#39;, k&#39;, v&#39;]`, each output tensor will have the</span>
<a id="__codelineno-0-308" name="__codelineno-0-308"></a><span class="sd">                same shape as the corresponding input tensor.</span>
<a id="__codelineno-0-309" name="__codelineno-0-309"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-310" name="__codelineno-0-310"></a>        <span class="k">if</span> <span class="n">k</span> <span class="ow">is</span> <span class="n">v</span><span class="p">:</span>
<a id="__codelineno-0-311" name="__codelineno-0-311"></a>            <span class="c1"># self-attention</span>
<a id="__codelineno-0-312" name="__codelineno-0-312"></a>            <span class="k">if</span> <span class="n">q</span> <span class="ow">is</span> <span class="n">k</span><span class="p">:</span>
<a id="__codelineno-0-313" name="__codelineno-0-313"></a>                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="p">(</span><span class="n">q</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_dim</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-314" name="__codelineno-0-314"></a>            <span class="c1"># encoder-decoder attention</span>
<a id="__codelineno-0-315" name="__codelineno-0-315"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-316" name="__codelineno-0-316"></a>                <span class="n">w_q</span><span class="p">,</span> <span class="n">w_kv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">split</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_dim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_dim</span><span class="p">])</span>
<a id="__codelineno-0-317" name="__codelineno-0-317"></a>                <span class="n">b_q</span><span class="p">,</span> <span class="n">b_kv</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-318" name="__codelineno-0-318"></a>                    <span class="kc">None</span>
<a id="__codelineno-0-319" name="__codelineno-0-319"></a>                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="kc">None</span>
<a id="__codelineno-0-320" name="__codelineno-0-320"></a>                    <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">split</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_dim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_dim</span><span class="p">])</span>
<a id="__codelineno-0-321" name="__codelineno-0-321"></a>                <span class="p">)</span>
<a id="__codelineno-0-322" name="__codelineno-0-322"></a>                <span class="k">return</span> <span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">w_q</span><span class="p">,</span> <span class="n">b_q</span><span class="p">),)</span> <span class="o">+</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">w_kv</span><span class="p">,</span> <span class="n">b_kv</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">k_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_dim</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-323" name="__codelineno-0-323"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-324" name="__codelineno-0-324"></a>            <span class="n">w_q</span><span class="p">,</span> <span class="n">w_k</span><span class="p">,</span> <span class="n">w_v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">split</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_dim</span><span class="p">])</span>
<a id="__codelineno-0-325" name="__codelineno-0-325"></a>            <span class="n">b_q</span><span class="p">,</span> <span class="n">b_k</span><span class="p">,</span> <span class="n">b_v</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-326" name="__codelineno-0-326"></a>                <span class="kc">None</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">split</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_dim</span><span class="p">])</span>
<a id="__codelineno-0-327" name="__codelineno-0-327"></a>            <span class="p">)</span>
<a id="__codelineno-0-328" name="__codelineno-0-328"></a>            <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">w_q</span><span class="p">,</span> <span class="n">b_q</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">w_k</span><span class="p">,</span> <span class="n">b_k</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">w_v</span><span class="p">,</span> <span class="n">b_v</span><span class="p">)</span>
<a id="__codelineno-0-329" name="__codelineno-0-329"></a>
<a id="__codelineno-0-330" name="__codelineno-0-330"></a>    <span class="k">def</span> <span class="nf">attention</span><span class="p">(</span>
<a id="__codelineno-0-331" name="__codelineno-0-331"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-332" name="__codelineno-0-332"></a>        <span class="n">q</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-333" name="__codelineno-0-333"></a>        <span class="n">k</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-334" name="__codelineno-0-334"></a>        <span class="n">v</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-335" name="__codelineno-0-335"></a>        <span class="n">attn_bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-336" name="__codelineno-0-336"></a>        <span class="n">attn_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-337" name="__codelineno-0-337"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-338" name="__codelineno-0-338"></a>        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-339" name="__codelineno-0-339"></a><span class="sd">        Computes scaled dot product attention on query, key and value tensors, using</span>
<a id="__codelineno-0-340" name="__codelineno-0-340"></a><span class="sd">        an optional attention mask if passed, and applying dropout if a probability</span>
<a id="__codelineno-0-341" name="__codelineno-0-341"></a><span class="sd">        greater than 0.0 is specified.</span>
<a id="__codelineno-0-342" name="__codelineno-0-342"></a><span class="sd">        Returns a tensor pair containing attended values and attention weights.</span>
<a id="__codelineno-0-343" name="__codelineno-0-343"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-344" name="__codelineno-0-344"></a><span class="sd">            q, k, v: query, key and value tensors. See Shape section for shape details.</span>
<a id="__codelineno-0-345" name="__codelineno-0-345"></a><span class="sd">            attn_mask: optional tensor containing mask values to be added to calculated</span>
<a id="__codelineno-0-346" name="__codelineno-0-346"></a><span class="sd">                attention. May be 2D or 3D; see Shape section for details.</span>
<a id="__codelineno-0-347" name="__codelineno-0-347"></a><span class="sd">            attn_bias: optional tensor containing bias values to be added to calculated</span>
<a id="__codelineno-0-348" name="__codelineno-0-348"></a><span class="sd">                attention. Used for relative positional embedding. May be 2D or 3D; see</span>
<a id="__codelineno-0-349" name="__codelineno-0-349"></a><span class="sd">                Shape section for details.</span>
<a id="__codelineno-0-350" name="__codelineno-0-350"></a><span class="sd">        Shape:</span>
<a id="__codelineno-0-351" name="__codelineno-0-351"></a><span class="sd">            - q: :math:`(B, Nt, E)` where B is batch size, Nt is the target sequence length,</span>
<a id="__codelineno-0-352" name="__codelineno-0-352"></a><span class="sd">                and E is embedding dimension.</span>
<a id="__codelineno-0-353" name="__codelineno-0-353"></a><span class="sd">            - key: :math:`(B, Ns, E)` where B is batch size, Ns is the source sequence length,</span>
<a id="__codelineno-0-354" name="__codelineno-0-354"></a><span class="sd">                and E is embedding dimension.</span>
<a id="__codelineno-0-355" name="__codelineno-0-355"></a><span class="sd">            - value: :math:`(B, Ns, E)` where B is batch size, Ns is the source sequence length,</span>
<a id="__codelineno-0-356" name="__codelineno-0-356"></a><span class="sd">                and E is embedding dimension.</span>
<a id="__codelineno-0-357" name="__codelineno-0-357"></a><span class="sd">            - attn_bias: either a 3D tensor of shape :math:`(B, Nt, Ns)` or a 2D tensor of</span>
<a id="__codelineno-0-358" name="__codelineno-0-358"></a><span class="sd">                shape :math:`(Nt, Ns)`.</span>
<a id="__codelineno-0-359" name="__codelineno-0-359"></a><span class="sd">            - attn_mask: either a 3D tensor of shape :math:`(B, Nt, Ns)` or a 2D tensor of</span>
<a id="__codelineno-0-360" name="__codelineno-0-360"></a><span class="sd">                shape :math:`(Nt, Ns)`.</span>
<a id="__codelineno-0-361" name="__codelineno-0-361"></a><span class="sd">            - Output: attention values have shape :math:`(B, Nt, E)`; attention weights</span>
<a id="__codelineno-0-362" name="__codelineno-0-362"></a><span class="sd">                have shape :math:`(B, Nt, Ns)`</span>
<a id="__codelineno-0-363" name="__codelineno-0-363"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-364" name="__codelineno-0-364"></a>        <span class="n">q</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaling</span>
<a id="__codelineno-0-365" name="__codelineno-0-365"></a>        <span class="c1"># (B, Nt, E) x (B, E, Ns) -&gt; (B, Nt, Ns)</span>
<a id="__codelineno-0-366" name="__codelineno-0-366"></a>        <span class="n">attn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<a id="__codelineno-0-367" name="__codelineno-0-367"></a>        <span class="k">if</span> <span class="n">attn_bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-368" name="__codelineno-0-368"></a>            <span class="n">attn</span> <span class="o">+=</span> <span class="n">attn_bias</span>
<a id="__codelineno-0-369" name="__codelineno-0-369"></a>        <span class="k">if</span> <span class="n">attn_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-370" name="__codelineno-0-370"></a>            <span class="n">attn</span> <span class="o">+=</span> <span class="n">attn_mask</span>
<a id="__codelineno-0-371" name="__codelineno-0-371"></a>        <span class="n">attn</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attn</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-372" name="__codelineno-0-372"></a>        <span class="n">attn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">attn</span><span class="p">)</span>
<a id="__codelineno-0-373" name="__codelineno-0-373"></a>        <span class="c1"># (B, Nt, Ns) x (B, Ns, E) -&gt; (B, Nt, E)</span>
<a id="__codelineno-0-374" name="__codelineno-0-374"></a>        <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">attn</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
<a id="__codelineno-0-375" name="__codelineno-0-375"></a>        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">attn</span>
<a id="__codelineno-0-376" name="__codelineno-0-376"></a>
<a id="__codelineno-0-377" name="__codelineno-0-377"></a>    <span class="k">def</span> <span class="nf">out_projection</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attn_output</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-378" name="__codelineno-0-378"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_proj</span><span class="p">(</span><span class="n">attn_output</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h3 id="danling.models.transformer.attention.multihead_attention.MultiHeadAttention.attention" class="doc doc-heading">
<code class="highlight language-python"><span class="n">attention</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">attn_bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attn_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#danling.models.transformer.attention.multihead_attention.MultiHeadAttention.attention" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Computes scaled dot product attention on query, key and value tensors, using
an optional attention mask if passed, and applying dropout if a probability
greater than 0.0 is specified.
Returns a tensor pair containing attended values and attention weights.
Args:
    q, k, v: query, key and value tensors. See Shape section for shape details.
    attn_mask: optional tensor containing mask values to be added to calculated
        attention. May be 2D or 3D; see Shape section for details.
    attn_bias: optional tensor containing bias values to be added to calculated
        attention. Used for relative positional embedding. May be 2D or 3D; see
        Shape section for details.
Shape:
    - q: :math:<code>(B, Nt, E)</code> where B is batch size, Nt is the target sequence length,
        and E is embedding dimension.
    - key: :math:<code>(B, Ns, E)</code> where B is batch size, Ns is the source sequence length,
        and E is embedding dimension.
    - value: :math:<code>(B, Ns, E)</code> where B is batch size, Ns is the source sequence length,
        and E is embedding dimension.
    - attn_bias: either a 3D tensor of shape :math:<code>(B, Nt, Ns)</code> or a 2D tensor of
        shape :math:<code>(Nt, Ns)</code>.
    - attn_mask: either a 3D tensor of shape :math:<code>(B, Nt, Ns)</code> or a 2D tensor of
        shape :math:<code>(Nt, Ns)</code>.
    - Output: attention values have shape :math:<code>(B, Nt, E)</code>; attention weights
        have shape :math:<code>(B, Nt, Ns)</code></p>

      <details class="quote">
        <summary>Source code in <code>danling/models/transformer/attention/multihead_attention.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-330">330</a></span>
<span class="normal"><a href="#__codelineno-0-331">331</a></span>
<span class="normal"><a href="#__codelineno-0-332">332</a></span>
<span class="normal"><a href="#__codelineno-0-333">333</a></span>
<span class="normal"><a href="#__codelineno-0-334">334</a></span>
<span class="normal"><a href="#__codelineno-0-335">335</a></span>
<span class="normal"><a href="#__codelineno-0-336">336</a></span>
<span class="normal"><a href="#__codelineno-0-337">337</a></span>
<span class="normal"><a href="#__codelineno-0-338">338</a></span>
<span class="normal"><a href="#__codelineno-0-339">339</a></span>
<span class="normal"><a href="#__codelineno-0-340">340</a></span>
<span class="normal"><a href="#__codelineno-0-341">341</a></span>
<span class="normal"><a href="#__codelineno-0-342">342</a></span>
<span class="normal"><a href="#__codelineno-0-343">343</a></span>
<span class="normal"><a href="#__codelineno-0-344">344</a></span>
<span class="normal"><a href="#__codelineno-0-345">345</a></span>
<span class="normal"><a href="#__codelineno-0-346">346</a></span>
<span class="normal"><a href="#__codelineno-0-347">347</a></span>
<span class="normal"><a href="#__codelineno-0-348">348</a></span>
<span class="normal"><a href="#__codelineno-0-349">349</a></span>
<span class="normal"><a href="#__codelineno-0-350">350</a></span>
<span class="normal"><a href="#__codelineno-0-351">351</a></span>
<span class="normal"><a href="#__codelineno-0-352">352</a></span>
<span class="normal"><a href="#__codelineno-0-353">353</a></span>
<span class="normal"><a href="#__codelineno-0-354">354</a></span>
<span class="normal"><a href="#__codelineno-0-355">355</a></span>
<span class="normal"><a href="#__codelineno-0-356">356</a></span>
<span class="normal"><a href="#__codelineno-0-357">357</a></span>
<span class="normal"><a href="#__codelineno-0-358">358</a></span>
<span class="normal"><a href="#__codelineno-0-359">359</a></span>
<span class="normal"><a href="#__codelineno-0-360">360</a></span>
<span class="normal"><a href="#__codelineno-0-361">361</a></span>
<span class="normal"><a href="#__codelineno-0-362">362</a></span>
<span class="normal"><a href="#__codelineno-0-363">363</a></span>
<span class="normal"><a href="#__codelineno-0-364">364</a></span>
<span class="normal"><a href="#__codelineno-0-365">365</a></span>
<span class="normal"><a href="#__codelineno-0-366">366</a></span>
<span class="normal"><a href="#__codelineno-0-367">367</a></span>
<span class="normal"><a href="#__codelineno-0-368">368</a></span>
<span class="normal"><a href="#__codelineno-0-369">369</a></span>
<span class="normal"><a href="#__codelineno-0-370">370</a></span>
<span class="normal"><a href="#__codelineno-0-371">371</a></span>
<span class="normal"><a href="#__codelineno-0-372">372</a></span>
<span class="normal"><a href="#__codelineno-0-373">373</a></span>
<span class="normal"><a href="#__codelineno-0-374">374</a></span>
<span class="normal"><a href="#__codelineno-0-375">375</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-330" name="__codelineno-0-330"></a><span class="k">def</span> <span class="nf">attention</span><span class="p">(</span>
<a id="__codelineno-0-331" name="__codelineno-0-331"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-332" name="__codelineno-0-332"></a>    <span class="n">q</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-333" name="__codelineno-0-333"></a>    <span class="n">k</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-334" name="__codelineno-0-334"></a>    <span class="n">v</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-335" name="__codelineno-0-335"></a>    <span class="n">attn_bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-336" name="__codelineno-0-336"></a>    <span class="n">attn_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-337" name="__codelineno-0-337"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-338" name="__codelineno-0-338"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-339" name="__codelineno-0-339"></a><span class="sd">    Computes scaled dot product attention on query, key and value tensors, using</span>
<a id="__codelineno-0-340" name="__codelineno-0-340"></a><span class="sd">    an optional attention mask if passed, and applying dropout if a probability</span>
<a id="__codelineno-0-341" name="__codelineno-0-341"></a><span class="sd">    greater than 0.0 is specified.</span>
<a id="__codelineno-0-342" name="__codelineno-0-342"></a><span class="sd">    Returns a tensor pair containing attended values and attention weights.</span>
<a id="__codelineno-0-343" name="__codelineno-0-343"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-344" name="__codelineno-0-344"></a><span class="sd">        q, k, v: query, key and value tensors. See Shape section for shape details.</span>
<a id="__codelineno-0-345" name="__codelineno-0-345"></a><span class="sd">        attn_mask: optional tensor containing mask values to be added to calculated</span>
<a id="__codelineno-0-346" name="__codelineno-0-346"></a><span class="sd">            attention. May be 2D or 3D; see Shape section for details.</span>
<a id="__codelineno-0-347" name="__codelineno-0-347"></a><span class="sd">        attn_bias: optional tensor containing bias values to be added to calculated</span>
<a id="__codelineno-0-348" name="__codelineno-0-348"></a><span class="sd">            attention. Used for relative positional embedding. May be 2D or 3D; see</span>
<a id="__codelineno-0-349" name="__codelineno-0-349"></a><span class="sd">            Shape section for details.</span>
<a id="__codelineno-0-350" name="__codelineno-0-350"></a><span class="sd">    Shape:</span>
<a id="__codelineno-0-351" name="__codelineno-0-351"></a><span class="sd">        - q: :math:`(B, Nt, E)` where B is batch size, Nt is the target sequence length,</span>
<a id="__codelineno-0-352" name="__codelineno-0-352"></a><span class="sd">            and E is embedding dimension.</span>
<a id="__codelineno-0-353" name="__codelineno-0-353"></a><span class="sd">        - key: :math:`(B, Ns, E)` where B is batch size, Ns is the source sequence length,</span>
<a id="__codelineno-0-354" name="__codelineno-0-354"></a><span class="sd">            and E is embedding dimension.</span>
<a id="__codelineno-0-355" name="__codelineno-0-355"></a><span class="sd">        - value: :math:`(B, Ns, E)` where B is batch size, Ns is the source sequence length,</span>
<a id="__codelineno-0-356" name="__codelineno-0-356"></a><span class="sd">            and E is embedding dimension.</span>
<a id="__codelineno-0-357" name="__codelineno-0-357"></a><span class="sd">        - attn_bias: either a 3D tensor of shape :math:`(B, Nt, Ns)` or a 2D tensor of</span>
<a id="__codelineno-0-358" name="__codelineno-0-358"></a><span class="sd">            shape :math:`(Nt, Ns)`.</span>
<a id="__codelineno-0-359" name="__codelineno-0-359"></a><span class="sd">        - attn_mask: either a 3D tensor of shape :math:`(B, Nt, Ns)` or a 2D tensor of</span>
<a id="__codelineno-0-360" name="__codelineno-0-360"></a><span class="sd">            shape :math:`(Nt, Ns)`.</span>
<a id="__codelineno-0-361" name="__codelineno-0-361"></a><span class="sd">        - Output: attention values have shape :math:`(B, Nt, E)`; attention weights</span>
<a id="__codelineno-0-362" name="__codelineno-0-362"></a><span class="sd">            have shape :math:`(B, Nt, Ns)`</span>
<a id="__codelineno-0-363" name="__codelineno-0-363"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-364" name="__codelineno-0-364"></a>    <span class="n">q</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaling</span>
<a id="__codelineno-0-365" name="__codelineno-0-365"></a>    <span class="c1"># (B, Nt, E) x (B, E, Ns) -&gt; (B, Nt, Ns)</span>
<a id="__codelineno-0-366" name="__codelineno-0-366"></a>    <span class="n">attn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<a id="__codelineno-0-367" name="__codelineno-0-367"></a>    <span class="k">if</span> <span class="n">attn_bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-368" name="__codelineno-0-368"></a>        <span class="n">attn</span> <span class="o">+=</span> <span class="n">attn_bias</span>
<a id="__codelineno-0-369" name="__codelineno-0-369"></a>    <span class="k">if</span> <span class="n">attn_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-370" name="__codelineno-0-370"></a>        <span class="n">attn</span> <span class="o">+=</span> <span class="n">attn_mask</span>
<a id="__codelineno-0-371" name="__codelineno-0-371"></a>    <span class="n">attn</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attn</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-372" name="__codelineno-0-372"></a>    <span class="n">attn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">attn</span><span class="p">)</span>
<a id="__codelineno-0-373" name="__codelineno-0-373"></a>    <span class="c1"># (B, Nt, Ns) x (B, Ns, E) -&gt; (B, Nt, E)</span>
<a id="__codelineno-0-374" name="__codelineno-0-374"></a>    <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">attn</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
<a id="__codelineno-0-375" name="__codelineno-0-375"></a>    <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">attn</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="danling.models.transformer.attention.multihead_attention.MultiHeadAttention.forward" class="doc doc-heading">
<code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">attn_bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attn_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">key_padding_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">need_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">static_k</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">static_v</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#danling.models.transformer.attention.multihead_attention.MultiHeadAttention.forward" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Shapes for inputs:
    - query: :math:<code>(L, N, E)</code> where L is the target sequence length, N is the batch size, E is
        the embedding dimension. :math:<code>(N, L, E)</code> if <code>batch_first</code> is <code>True</code>.
    - key: :math:<code>(S, N, E)</code>, where S is the source sequence length, N is the batch size, E is
        the embedding dimension. :math:<code>(N, S, E)</code> if <code>batch_first</code> is <code>True</code>.
    - value: :math:<code>(S, N, E)</code> where S is the source sequence length, N is the batch size, E is
        the embedding dimension. :math:<code>(N, S, E)</code> if <code>batch_first</code> is <code>True</code>.
    - attn_bias: if a 2D mask: :math:<code>(L, S)</code> where L is the target sequence length, S is the
        source sequence length.
        If a 3D mask: :math:<code>(N\cdot\text{num\_heads}, L, S)</code> where N is the batch size, L is the target sequence
        length, S is the source sequence length. <code>attn_bias</code> allows to pass pos embed directly into attention
        If a ByteTensor is provided, the non-zero positions are not allowed to attend while the zero positions will
        be unchanged. If a BoolTensor is provided, positions with <code>True</code> is not allowed to attend while <code>False</code>
        values will be unchanged. If a FloatTensor is provided, it will be added to the attention weight.
    - attn_mask: if a 2D mask: :math:<code>(L, S)</code> where L is the target sequence length, S is the
        source sequence length.
        If a 3D mask: :math:<code>(N\cdot\text{num\_heads}, L, S)</code> where N is the batch size, L is the target sequence
        length, S is the source sequence length. <code>attn_mask</code> ensure that position i is allowed to attend
        the unmasked positions. If a ByteTensor is provided, the non-zero positions are not allowed to attend
        while the zero positions will be unchanged. If a BoolTensor is provided, positions with <code>True</code>
        is not allowed to attend while <code>False</code> values will be unchanged. If a FloatTensor
        is provided, it will be added to the attention weight.
    - key_padding_mask: :math:<code>(N, S)</code> where N is the batch size, S is the source sequence length.
        If a ByteTensor is provided, the non-zero positions will be ignored while the position
        with the zero positions will be unchanged. If a BoolTensor is provided, the positions with the
        value of <code>True</code> will be ignored while the position with the value of <code>False</code> will be unchanged.
    - static_k: :math:<code>(N*num_heads, S, E/num_heads)</code>, where S is the source sequence length,
        N is the batch size, E is the embedding dimension. E/num_heads is the head dimension.
    - static_v: :math:<code>(N*num_heads, S, E/num_heads)</code>, where S is the source sequence length,
        N is the batch size, E is the embedding dimension. E/num_heads is the head dimension.
Outputs:
    - attn_output: :math:<code>(L, N, E)</code> where L is the target sequence length, N is the batch size,
        E is the embedding dimension. :math:<code>(N, L, E)</code> if <code>batch_first</code> is <code>True</code>.
    - attn_output_weights: :math:<code>(N, L, S)</code> where N is the batch size,
        L is the target sequence length, S is the source sequence length.</p>

      <details class="quote">
        <summary>Source code in <code>danling/models/transformer/attention/multihead_attention.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span>
<span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span>
<span class="normal"><a href="#__codelineno-0-203">203</a></span>
<span class="normal"><a href="#__codelineno-0-204">204</a></span>
<span class="normal"><a href="#__codelineno-0-205">205</a></span>
<span class="normal"><a href="#__codelineno-0-206">206</a></span>
<span class="normal"><a href="#__codelineno-0-207">207</a></span>
<span class="normal"><a href="#__codelineno-0-208">208</a></span>
<span class="normal"><a href="#__codelineno-0-209">209</a></span>
<span class="normal"><a href="#__codelineno-0-210">210</a></span>
<span class="normal"><a href="#__codelineno-0-211">211</a></span>
<span class="normal"><a href="#__codelineno-0-212">212</a></span>
<span class="normal"><a href="#__codelineno-0-213">213</a></span>
<span class="normal"><a href="#__codelineno-0-214">214</a></span>
<span class="normal"><a href="#__codelineno-0-215">215</a></span>
<span class="normal"><a href="#__codelineno-0-216">216</a></span>
<span class="normal"><a href="#__codelineno-0-217">217</a></span>
<span class="normal"><a href="#__codelineno-0-218">218</a></span>
<span class="normal"><a href="#__codelineno-0-219">219</a></span>
<span class="normal"><a href="#__codelineno-0-220">220</a></span>
<span class="normal"><a href="#__codelineno-0-221">221</a></span>
<span class="normal"><a href="#__codelineno-0-222">222</a></span>
<span class="normal"><a href="#__codelineno-0-223">223</a></span>
<span class="normal"><a href="#__codelineno-0-224">224</a></span>
<span class="normal"><a href="#__codelineno-0-225">225</a></span>
<span class="normal"><a href="#__codelineno-0-226">226</a></span>
<span class="normal"><a href="#__codelineno-0-227">227</a></span>
<span class="normal"><a href="#__codelineno-0-228">228</a></span>
<span class="normal"><a href="#__codelineno-0-229">229</a></span>
<span class="normal"><a href="#__codelineno-0-230">230</a></span>
<span class="normal"><a href="#__codelineno-0-231">231</a></span>
<span class="normal"><a href="#__codelineno-0-232">232</a></span>
<span class="normal"><a href="#__codelineno-0-233">233</a></span>
<span class="normal"><a href="#__codelineno-0-234">234</a></span>
<span class="normal"><a href="#__codelineno-0-235">235</a></span>
<span class="normal"><a href="#__codelineno-0-236">236</a></span>
<span class="normal"><a href="#__codelineno-0-237">237</a></span>
<span class="normal"><a href="#__codelineno-0-238">238</a></span>
<span class="normal"><a href="#__codelineno-0-239">239</a></span>
<span class="normal"><a href="#__codelineno-0-240">240</a></span>
<span class="normal"><a href="#__codelineno-0-241">241</a></span>
<span class="normal"><a href="#__codelineno-0-242">242</a></span>
<span class="normal"><a href="#__codelineno-0-243">243</a></span>
<span class="normal"><a href="#__codelineno-0-244">244</a></span>
<span class="normal"><a href="#__codelineno-0-245">245</a></span>
<span class="normal"><a href="#__codelineno-0-246">246</a></span>
<span class="normal"><a href="#__codelineno-0-247">247</a></span>
<span class="normal"><a href="#__codelineno-0-248">248</a></span>
<span class="normal"><a href="#__codelineno-0-249">249</a></span>
<span class="normal"><a href="#__codelineno-0-250">250</a></span>
<span class="normal"><a href="#__codelineno-0-251">251</a></span>
<span class="normal"><a href="#__codelineno-0-252">252</a></span>
<span class="normal"><a href="#__codelineno-0-253">253</a></span>
<span class="normal"><a href="#__codelineno-0-254">254</a></span>
<span class="normal"><a href="#__codelineno-0-255">255</a></span>
<span class="normal"><a href="#__codelineno-0-256">256</a></span>
<span class="normal"><a href="#__codelineno-0-257">257</a></span>
<span class="normal"><a href="#__codelineno-0-258">258</a></span>
<span class="normal"><a href="#__codelineno-0-259">259</a></span>
<span class="normal"><a href="#__codelineno-0-260">260</a></span>
<span class="normal"><a href="#__codelineno-0-261">261</a></span>
<span class="normal"><a href="#__codelineno-0-262">262</a></span>
<span class="normal"><a href="#__codelineno-0-263">263</a></span>
<span class="normal"><a href="#__codelineno-0-264">264</a></span>
<span class="normal"><a href="#__codelineno-0-265">265</a></span>
<span class="normal"><a href="#__codelineno-0-266">266</a></span>
<span class="normal"><a href="#__codelineno-0-267">267</a></span>
<span class="normal"><a href="#__codelineno-0-268">268</a></span>
<span class="normal"><a href="#__codelineno-0-269">269</a></span>
<span class="normal"><a href="#__codelineno-0-270">270</a></span>
<span class="normal"><a href="#__codelineno-0-271">271</a></span>
<span class="normal"><a href="#__codelineno-0-272">272</a></span>
<span class="normal"><a href="#__codelineno-0-273">273</a></span>
<span class="normal"><a href="#__codelineno-0-274">274</a></span>
<span class="normal"><a href="#__codelineno-0-275">275</a></span>
<span class="normal"><a href="#__codelineno-0-276">276</a></span>
<span class="normal"><a href="#__codelineno-0-277">277</a></span>
<span class="normal"><a href="#__codelineno-0-278">278</a></span>
<span class="normal"><a href="#__codelineno-0-279">279</a></span>
<span class="normal"><a href="#__codelineno-0-280">280</a></span>
<span class="normal"><a href="#__codelineno-0-281">281</a></span>
<span class="normal"><a href="#__codelineno-0-282">282</a></span>
<span class="normal"><a href="#__codelineno-0-283">283</a></span>
<span class="normal"><a href="#__codelineno-0-284">284</a></span>
<span class="normal"><a href="#__codelineno-0-285">285</a></span>
<span class="normal"><a href="#__codelineno-0-286">286</a></span>
<span class="normal"><a href="#__codelineno-0-287">287</a></span>
<span class="normal"><a href="#__codelineno-0-288">288</a></span>
<span class="normal"><a href="#__codelineno-0-289">289</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-97" name="__codelineno-0-97"></a><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>    <span class="n">query</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>    <span class="n">key</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>    <span class="n">value</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>    <span class="n">attn_bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>    <span class="n">attn_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>    <span class="n">key_padding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>    <span class="n">need_weights</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>    <span class="n">static_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>    <span class="n">static_v</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]]:</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a><span class="sd">        query, key, value: map a query and a set of key-value pairs to an output.</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a><span class="sd">            See &quot;Attention Is All You Need&quot; for more details.</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a><span class="sd">        attn_bias: 2D or 3D mask that add bias to attention output weights. Used for relative positional embedding.</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a><span class="sd">            A 2D bias will be broadcasted for all the batches while a 3D mask allows to specify a different mask for</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a><span class="sd">            the entries of each batch.</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a><span class="sd">        attn_mask: 2D or 3D mask that prevents attention to certain positions. A 2D mask will be broadcasted for all</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a><span class="sd">            the batches while a 3D mask allows to specify a different mask for the entries of each batch.</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a><span class="sd">        key_padding_mask: if provided, specified padding elements in the key will</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a><span class="sd">            be ignored by the attention. When given a binary mask and a value is True,</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a><span class="sd">            the corresponding value on the attention layer will be ignored. When given</span>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a><span class="sd">            a byte mask and a value is non-zero, the corresponding value on the attention</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a><span class="sd">            layer will be ignored</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a><span class="sd">        need_weights: output attn_output_weights.</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a><span class="sd">        static_k, static_v: static key and value used for attention operators.</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a><span class="sd">    Shapes for inputs:</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a><span class="sd">        - query: :math:`(L, N, E)` where L is the target sequence length, N is the batch size, E is</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a><span class="sd">            the embedding dimension. :math:`(N, L, E)` if ``batch_first`` is ``True``.</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a><span class="sd">        - key: :math:`(S, N, E)`, where S is the source sequence length, N is the batch size, E is</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a><span class="sd">            the embedding dimension. :math:`(N, S, E)` if ``batch_first`` is ``True``.</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a><span class="sd">        - value: :math:`(S, N, E)` where S is the source sequence length, N is the batch size, E is</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a><span class="sd">            the embedding dimension. :math:`(N, S, E)` if ``batch_first`` is ``True``.</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a><span class="sd">        - attn_bias: if a 2D mask: :math:`(L, S)` where L is the target sequence length, S is the</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a><span class="sd">            source sequence length.</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a><span class="sd">            If a 3D mask: :math:`(N\cdot\text{num\_heads}, L, S)` where N is the batch size, L is the target sequence</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a><span class="sd">            length, S is the source sequence length. ``attn_bias`` allows to pass pos embed directly into attention</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a><span class="sd">            If a ByteTensor is provided, the non-zero positions are not allowed to attend while the zero positions will</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a><span class="sd">            be unchanged. If a BoolTensor is provided, positions with ``True`` is not allowed to attend while ``False``</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a><span class="sd">            values will be unchanged. If a FloatTensor is provided, it will be added to the attention weight.</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a><span class="sd">        - attn_mask: if a 2D mask: :math:`(L, S)` where L is the target sequence length, S is the</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a><span class="sd">            source sequence length.</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a><span class="sd">            If a 3D mask: :math:`(N\cdot\text{num\_heads}, L, S)` where N is the batch size, L is the target sequence</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a><span class="sd">            length, S is the source sequence length. ``attn_mask`` ensure that position i is allowed to attend</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a><span class="sd">            the unmasked positions. If a ByteTensor is provided, the non-zero positions are not allowed to attend</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a><span class="sd">            while the zero positions will be unchanged. If a BoolTensor is provided, positions with ``True``</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a><span class="sd">            is not allowed to attend while ``False`` values will be unchanged. If a FloatTensor</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a><span class="sd">            is provided, it will be added to the attention weight.</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a><span class="sd">        - key_padding_mask: :math:`(N, S)` where N is the batch size, S is the source sequence length.</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a><span class="sd">            If a ByteTensor is provided, the non-zero positions will be ignored while the position</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a><span class="sd">            with the zero positions will be unchanged. If a BoolTensor is provided, the positions with the</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a><span class="sd">            value of ``True`` will be ignored while the position with the value of ``False`` will be unchanged.</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a><span class="sd">        - static_k: :math:`(N*num_heads, S, E/num_heads)`, where S is the source sequence length,</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a><span class="sd">            N is the batch size, E is the embedding dimension. E/num_heads is the head dimension.</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a><span class="sd">        - static_v: :math:`(N*num_heads, S, E/num_heads)`, where S is the source sequence length,</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a><span class="sd">            N is the batch size, E is the embedding dimension. E/num_heads is the head dimension.</span>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a><span class="sd">    Outputs:</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a><span class="sd">        - attn_output: :math:`(L, N, E)` where L is the target sequence length, N is the batch size,</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a><span class="sd">            E is the embedding dimension. :math:`(N, L, E)` if ``batch_first`` is ``True``.</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a><span class="sd">        - attn_output_weights: :math:`(N, L, S)` where N is the batch size,</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a><span class="sd">            L is the target sequence length, S is the source sequence length.</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_first</span><span class="p">:</span>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a>        <span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)]</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a>    <span class="c1"># set up shape vars</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a>    <span class="n">target_len</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">embed_dim</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a>    <span class="n">source_len</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">key</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]:</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;key&#39;s sequence and batch dims </span><span class="si">{</span><span class="n">key</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="s2"> do not match value&#39;s </span><span class="si">{</span><span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a>    <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_projection</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a>    <span class="c1"># prep attention mask</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a>    <span class="k">if</span> <span class="n">attn_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a>        <span class="k">if</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">:</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a>            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a>                <span class="s2">&quot;attn_mask is of type uint8. This type is deprecated. Please use bool or float tensors instead.&quot;</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a>            <span class="p">)</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a>            <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a>        <span class="k">elif</span> <span class="ow">not</span> <span class="p">(</span><span class="n">attn_mask</span><span class="o">.</span><span class="n">is_floating_point</span><span class="p">()</span> <span class="ow">or</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">):</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;attn_mask should have type float or bool, but got </span><span class="si">{</span><span class="n">attn_mask</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a>        <span class="c1"># ensure attn_mask&#39;s dim is 3</span>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a>        <span class="k">if</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a>            <span class="n">correct_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">target_len</span><span class="p">,</span> <span class="n">source_len</span><span class="p">)</span>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a>            <span class="k">if</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">correct_shape</span><span class="p">:</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;attn_mask should have shape </span><span class="si">{</span><span class="n">correct_shape</span><span class="si">}</span><span class="s2">, but got </span><span class="si">{</span><span class="n">attn_mask</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a>            <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a>        <span class="k">elif</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a>            <span class="n">correct_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">target_len</span><span class="p">,</span> <span class="n">source_len</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>            <span class="k">if</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">correct_shape</span><span class="p">:</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;attn_mask should have shape </span><span class="si">{</span><span class="n">correct_shape</span><span class="si">}</span><span class="s2">, but got </span><span class="si">{</span><span class="n">attn_mask</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a>            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;attn_mask should have dimension 2 or 3, bug got </span><span class="si">{</span><span class="n">attn_mask</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a>    <span class="c1"># prep key padding mask</span>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a>    <span class="k">if</span> <span class="n">key_padding_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">key_padding_mask</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">:</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a>        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a>            <span class="s2">&quot;key_padding_mask is of type uint8. This type is deprecated. Please use bool or float tensors instead.&quot;</span>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a>        <span class="p">)</span>
<a id="__codelineno-0-199" name="__codelineno-0-199"></a>        <span class="n">key_padding_mask</span> <span class="o">=</span> <span class="n">key_padding_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a>
<a id="__codelineno-0-201" name="__codelineno-0-201"></a>    <span class="c1"># add bias along batch dimension (currently second)</span>
<a id="__codelineno-0-202" name="__codelineno-0-202"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_k</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-203" name="__codelineno-0-203"></a>        <span class="k">assert</span> <span class="n">static_k</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;bias cannot be added to static key.&quot;</span>
<a id="__codelineno-0-204" name="__codelineno-0-204"></a>        <span class="k">assert</span> <span class="n">static_v</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;bias cannot be added to static value.&quot;</span>
<a id="__codelineno-0-205" name="__codelineno-0-205"></a>        <span class="n">k</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">k</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_k</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)])</span>
<a id="__codelineno-0-206" name="__codelineno-0-206"></a>        <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">v</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_v</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)])</span>
<a id="__codelineno-0-207" name="__codelineno-0-207"></a>        <span class="k">if</span> <span class="n">attn_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-208" name="__codelineno-0-208"></a>            <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">attn_mask</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<a id="__codelineno-0-209" name="__codelineno-0-209"></a>        <span class="k">if</span> <span class="n">key_padding_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-210" name="__codelineno-0-210"></a>            <span class="n">key_padding_mask</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">key_padding_mask</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<a id="__codelineno-0-211" name="__codelineno-0-211"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-212" name="__codelineno-0-212"></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_k</span> <span class="ow">is</span> <span class="kc">None</span>
<a id="__codelineno-0-213" name="__codelineno-0-213"></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_v</span> <span class="ow">is</span> <span class="kc">None</span>
<a id="__codelineno-0-214" name="__codelineno-0-214"></a>
<a id="__codelineno-0-215" name="__codelineno-0-215"></a>    <span class="c1"># reshape q, k, v for multihead attention and make em batch first</span>
<a id="__codelineno-0-216" name="__codelineno-0-216"></a>    <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">target_len</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-217" name="__codelineno-0-217"></a>    <span class="n">k</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">static_k</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">static_k</span>
<a id="__codelineno-0-218" name="__codelineno-0-218"></a>    <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">static_v</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">static_v</span>
<a id="__codelineno-0-219" name="__codelineno-0-219"></a>
<a id="__codelineno-0-220" name="__codelineno-0-220"></a>    <span class="k">if</span> <span class="n">static_k</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-221" name="__codelineno-0-221"></a>        <span class="n">correct_shape</span> <span class="o">=</span> <span class="p">(</span>  <span class="c1"># type: ignore</span>
<a id="__codelineno-0-222" name="__codelineno-0-222"></a>            <span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span>
<a id="__codelineno-0-223" name="__codelineno-0-223"></a>            <span class="n">static_k</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
<a id="__codelineno-0-224" name="__codelineno-0-224"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">,</span>
<a id="__codelineno-0-225" name="__codelineno-0-225"></a>        <span class="p">)</span>
<a id="__codelineno-0-226" name="__codelineno-0-226"></a>        <span class="k">if</span> <span class="n">static_k</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">correct_shape</span><span class="p">:</span>
<a id="__codelineno-0-227" name="__codelineno-0-227"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;static_k should have shape </span><span class="si">{</span><span class="n">correct_shape</span><span class="si">}</span><span class="s2">, but got </span><span class="si">{</span><span class="n">static_k</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-228" name="__codelineno-0-228"></a>    <span class="k">if</span> <span class="n">static_v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-229" name="__codelineno-0-229"></a>        <span class="n">correct_shape</span> <span class="o">=</span> <span class="p">(</span>  <span class="c1"># type: ignore</span>
<a id="__codelineno-0-230" name="__codelineno-0-230"></a>            <span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span>
<a id="__codelineno-0-231" name="__codelineno-0-231"></a>            <span class="n">static_v</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
<a id="__codelineno-0-232" name="__codelineno-0-232"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">,</span>
<a id="__codelineno-0-233" name="__codelineno-0-233"></a>        <span class="p">)</span>
<a id="__codelineno-0-234" name="__codelineno-0-234"></a>        <span class="k">if</span> <span class="n">static_v</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">correct_shape</span><span class="p">:</span>
<a id="__codelineno-0-235" name="__codelineno-0-235"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;static_v should have shape </span><span class="si">{</span><span class="n">correct_shape</span><span class="si">}</span><span class="s2">, but got </span><span class="si">{</span><span class="n">static_v</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-236" name="__codelineno-0-236"></a>
<a id="__codelineno-0-237" name="__codelineno-0-237"></a>    <span class="c1"># add zero attention along batch dimension (now first)</span>
<a id="__codelineno-0-238" name="__codelineno-0-238"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_zero_attn</span><span class="p">:</span>
<a id="__codelineno-0-239" name="__codelineno-0-239"></a>        <span class="n">zero_attn_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">)</span>
<a id="__codelineno-0-240" name="__codelineno-0-240"></a>        <span class="n">k</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">k</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">zero_attn_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">k</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">k</span><span class="o">.</span><span class="n">device</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-241" name="__codelineno-0-241"></a>        <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">v</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">zero_attn_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">v</span><span class="o">.</span><span class="n">device</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-242" name="__codelineno-0-242"></a>        <span class="k">if</span> <span class="n">attn_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-243" name="__codelineno-0-243"></a>            <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">attn_mask</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<a id="__codelineno-0-244" name="__codelineno-0-244"></a>        <span class="k">if</span> <span class="n">key_padding_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-245" name="__codelineno-0-245"></a>            <span class="n">key_padding_mask</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">key_padding_mask</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<a id="__codelineno-0-246" name="__codelineno-0-246"></a>
<a id="__codelineno-0-247" name="__codelineno-0-247"></a>    <span class="c1"># update source sequence length after adjustments</span>
<a id="__codelineno-0-248" name="__codelineno-0-248"></a>    <span class="n">source_len</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-249" name="__codelineno-0-249"></a>
<a id="__codelineno-0-250" name="__codelineno-0-250"></a>    <span class="c1"># merge key padding and attention masks</span>
<a id="__codelineno-0-251" name="__codelineno-0-251"></a>    <span class="k">if</span> <span class="n">key_padding_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-252" name="__codelineno-0-252"></a>        <span class="k">if</span> <span class="n">key_padding_mask</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">source_len</span><span class="p">):</span>
<a id="__codelineno-0-253" name="__codelineno-0-253"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-254" name="__codelineno-0-254"></a>                <span class="sa">f</span><span class="s2">&quot;key_padding_mask should have shape </span><span class="si">{</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">source_len</span><span class="p">)</span><span class="si">}</span><span class="s2">, but got </span><span class="si">{</span><span class="n">key_padding_mask</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
<a id="__codelineno-0-255" name="__codelineno-0-255"></a>            <span class="p">)</span>
<a id="__codelineno-0-256" name="__codelineno-0-256"></a>        <span class="n">key_padding_mask</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-257" name="__codelineno-0-257"></a>            <span class="n">key_padding_mask</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">source_len</span><span class="p">)</span>
<a id="__codelineno-0-258" name="__codelineno-0-258"></a>            <span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-259" name="__codelineno-0-259"></a>            <span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">source_len</span><span class="p">)</span>
<a id="__codelineno-0-260" name="__codelineno-0-260"></a>        <span class="p">)</span>
<a id="__codelineno-0-261" name="__codelineno-0-261"></a>        <span class="k">if</span> <span class="n">attn_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-262" name="__codelineno-0-262"></a>            <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">key_padding_mask</span>
<a id="__codelineno-0-263" name="__codelineno-0-263"></a>        <span class="k">elif</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">:</span>
<a id="__codelineno-0-264" name="__codelineno-0-264"></a>            <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">logical_or</span><span class="p">(</span><span class="n">key_padding_mask</span><span class="p">)</span>
<a id="__codelineno-0-265" name="__codelineno-0-265"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-266" name="__codelineno-0-266"></a>            <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">key_padding_mask</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;-inf&quot;</span><span class="p">))</span>
<a id="__codelineno-0-267" name="__codelineno-0-267"></a>
<a id="__codelineno-0-268" name="__codelineno-0-268"></a>    <span class="c1"># convert mask to float</span>
<a id="__codelineno-0-269" name="__codelineno-0-269"></a>    <span class="k">if</span> <span class="n">attn_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">:</span>
<a id="__codelineno-0-270" name="__codelineno-0-270"></a>        <span class="n">new_attn_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">attn_mask</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
<a id="__codelineno-0-271" name="__codelineno-0-271"></a>        <span class="n">new_attn_mask</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">attn_mask</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;-inf&quot;</span><span class="p">))</span>
<a id="__codelineno-0-272" name="__codelineno-0-272"></a>        <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">new_attn_mask</span>
<a id="__codelineno-0-273" name="__codelineno-0-273"></a>
<a id="__codelineno-0-274" name="__codelineno-0-274"></a>    <span class="c1"># (deep breath) calculate attention and out projection</span>
<a id="__codelineno-0-275" name="__codelineno-0-275"></a>    <span class="n">attn_output</span><span class="p">,</span> <span class="n">attn_output_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">attn_bias</span><span class="p">,</span> <span class="n">attn_mask</span><span class="p">)</span>
<a id="__codelineno-0-276" name="__codelineno-0-276"></a>    <span class="n">attn_output</span> <span class="o">=</span> <span class="n">attn_output</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">target_len</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">)</span>
<a id="__codelineno-0-277" name="__codelineno-0-277"></a>    <span class="n">attn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_projection</span><span class="p">(</span><span class="n">attn_output</span><span class="p">)</span>
<a id="__codelineno-0-278" name="__codelineno-0-278"></a>
<a id="__codelineno-0-279" name="__codelineno-0-279"></a>    <span class="c1"># attn_output_weights is set to torch.empty(0, requires_grad=False) to avoid errors in DDP</span>
<a id="__codelineno-0-280" name="__codelineno-0-280"></a>    <span class="n">attn_output_weights</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-281" name="__codelineno-0-281"></a>        <span class="n">attn_output_weights</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">target_len</span><span class="p">,</span> <span class="n">source_len</span><span class="p">)</span>
<a id="__codelineno-0-282" name="__codelineno-0-282"></a>        <span class="k">if</span> <span class="n">need_weights</span>
<a id="__codelineno-0-283" name="__codelineno-0-283"></a>        <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-0-284" name="__codelineno-0-284"></a>    <span class="p">)</span>
<a id="__codelineno-0-285" name="__codelineno-0-285"></a>
<a id="__codelineno-0-286" name="__codelineno-0-286"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_first</span><span class="p">:</span>
<a id="__codelineno-0-287" name="__codelineno-0-287"></a>        <span class="k">return</span> <span class="n">attn_output</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">attn_output_weights</span>
<a id="__codelineno-0-288" name="__codelineno-0-288"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-289" name="__codelineno-0-289"></a>        <span class="k">return</span> <span class="n">attn_output</span><span class="p">,</span> <span class="n">attn_output_weights</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="danling.models.transformer.attention.multihead_attention.MultiHeadAttention.in_projection" class="doc doc-heading">
<code class="highlight language-python"><span class="n">in_projection</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span></code>

<a href="#danling.models.transformer.attention.multihead_attention.MultiHeadAttention.in_projection" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Performs the in-projection step of the attention operation, using packed weights.
Output is a triple containing projection tensors for query, key and value.
Args:
    q, k, v: query, key and value tensors to be projected. For self-attention,
        these are typically the same tensor; for encoder-decoder attention,
        k and v are typically the same tensor. (We take advantage of these
        identities for performance if they are present.) Regardless, q, k and v
        must share a common embedding dimension; otherwise their shapes may vary.
Shape:
    Inputs:
    - q: :math:<code>(..., E)</code> where E is the embedding dimension
    - k: :math:<code>(..., E)</code> where E is the embedding dimension
    - v: :math:<code>(..., E)</code> where E is the embedding dimension
    Output:
    - in output list :math:<code>[q', k', v']</code>, each output tensor will have the
        same shape as the corresponding input tensor.</p>

      <details class="quote">
        <summary>Source code in <code>danling/models/transformer/attention/multihead_attention.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-291">291</a></span>
<span class="normal"><a href="#__codelineno-0-292">292</a></span>
<span class="normal"><a href="#__codelineno-0-293">293</a></span>
<span class="normal"><a href="#__codelineno-0-294">294</a></span>
<span class="normal"><a href="#__codelineno-0-295">295</a></span>
<span class="normal"><a href="#__codelineno-0-296">296</a></span>
<span class="normal"><a href="#__codelineno-0-297">297</a></span>
<span class="normal"><a href="#__codelineno-0-298">298</a></span>
<span class="normal"><a href="#__codelineno-0-299">299</a></span>
<span class="normal"><a href="#__codelineno-0-300">300</a></span>
<span class="normal"><a href="#__codelineno-0-301">301</a></span>
<span class="normal"><a href="#__codelineno-0-302">302</a></span>
<span class="normal"><a href="#__codelineno-0-303">303</a></span>
<span class="normal"><a href="#__codelineno-0-304">304</a></span>
<span class="normal"><a href="#__codelineno-0-305">305</a></span>
<span class="normal"><a href="#__codelineno-0-306">306</a></span>
<span class="normal"><a href="#__codelineno-0-307">307</a></span>
<span class="normal"><a href="#__codelineno-0-308">308</a></span>
<span class="normal"><a href="#__codelineno-0-309">309</a></span>
<span class="normal"><a href="#__codelineno-0-310">310</a></span>
<span class="normal"><a href="#__codelineno-0-311">311</a></span>
<span class="normal"><a href="#__codelineno-0-312">312</a></span>
<span class="normal"><a href="#__codelineno-0-313">313</a></span>
<span class="normal"><a href="#__codelineno-0-314">314</a></span>
<span class="normal"><a href="#__codelineno-0-315">315</a></span>
<span class="normal"><a href="#__codelineno-0-316">316</a></span>
<span class="normal"><a href="#__codelineno-0-317">317</a></span>
<span class="normal"><a href="#__codelineno-0-318">318</a></span>
<span class="normal"><a href="#__codelineno-0-319">319</a></span>
<span class="normal"><a href="#__codelineno-0-320">320</a></span>
<span class="normal"><a href="#__codelineno-0-321">321</a></span>
<span class="normal"><a href="#__codelineno-0-322">322</a></span>
<span class="normal"><a href="#__codelineno-0-323">323</a></span>
<span class="normal"><a href="#__codelineno-0-324">324</a></span>
<span class="normal"><a href="#__codelineno-0-325">325</a></span>
<span class="normal"><a href="#__codelineno-0-326">326</a></span>
<span class="normal"><a href="#__codelineno-0-327">327</a></span>
<span class="normal"><a href="#__codelineno-0-328">328</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-291" name="__codelineno-0-291"></a><span class="k">def</span> <span class="nf">in_projection</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">v</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-292" name="__codelineno-0-292"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-293" name="__codelineno-0-293"></a><span class="sd">    Performs the in-projection step of the attention operation, using packed weights.</span>
<a id="__codelineno-0-294" name="__codelineno-0-294"></a><span class="sd">    Output is a triple containing projection tensors for query, key and value.</span>
<a id="__codelineno-0-295" name="__codelineno-0-295"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-296" name="__codelineno-0-296"></a><span class="sd">        q, k, v: query, key and value tensors to be projected. For self-attention,</span>
<a id="__codelineno-0-297" name="__codelineno-0-297"></a><span class="sd">            these are typically the same tensor; for encoder-decoder attention,</span>
<a id="__codelineno-0-298" name="__codelineno-0-298"></a><span class="sd">            k and v are typically the same tensor. (We take advantage of these</span>
<a id="__codelineno-0-299" name="__codelineno-0-299"></a><span class="sd">            identities for performance if they are present.) Regardless, q, k and v</span>
<a id="__codelineno-0-300" name="__codelineno-0-300"></a><span class="sd">            must share a common embedding dimension; otherwise their shapes may vary.</span>
<a id="__codelineno-0-301" name="__codelineno-0-301"></a><span class="sd">    Shape:</span>
<a id="__codelineno-0-302" name="__codelineno-0-302"></a><span class="sd">        Inputs:</span>
<a id="__codelineno-0-303" name="__codelineno-0-303"></a><span class="sd">        - q: :math:`(..., E)` where E is the embedding dimension</span>
<a id="__codelineno-0-304" name="__codelineno-0-304"></a><span class="sd">        - k: :math:`(..., E)` where E is the embedding dimension</span>
<a id="__codelineno-0-305" name="__codelineno-0-305"></a><span class="sd">        - v: :math:`(..., E)` where E is the embedding dimension</span>
<a id="__codelineno-0-306" name="__codelineno-0-306"></a><span class="sd">        Output:</span>
<a id="__codelineno-0-307" name="__codelineno-0-307"></a><span class="sd">        - in output list :math:`[q&#39;, k&#39;, v&#39;]`, each output tensor will have the</span>
<a id="__codelineno-0-308" name="__codelineno-0-308"></a><span class="sd">            same shape as the corresponding input tensor.</span>
<a id="__codelineno-0-309" name="__codelineno-0-309"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-310" name="__codelineno-0-310"></a>    <span class="k">if</span> <span class="n">k</span> <span class="ow">is</span> <span class="n">v</span><span class="p">:</span>
<a id="__codelineno-0-311" name="__codelineno-0-311"></a>        <span class="c1"># self-attention</span>
<a id="__codelineno-0-312" name="__codelineno-0-312"></a>        <span class="k">if</span> <span class="n">q</span> <span class="ow">is</span> <span class="n">k</span><span class="p">:</span>
<a id="__codelineno-0-313" name="__codelineno-0-313"></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="p">(</span><span class="n">q</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_dim</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-314" name="__codelineno-0-314"></a>        <span class="c1"># encoder-decoder attention</span>
<a id="__codelineno-0-315" name="__codelineno-0-315"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-316" name="__codelineno-0-316"></a>            <span class="n">w_q</span><span class="p">,</span> <span class="n">w_kv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">split</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_dim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_dim</span><span class="p">])</span>
<a id="__codelineno-0-317" name="__codelineno-0-317"></a>            <span class="n">b_q</span><span class="p">,</span> <span class="n">b_kv</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-318" name="__codelineno-0-318"></a>                <span class="kc">None</span>
<a id="__codelineno-0-319" name="__codelineno-0-319"></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="kc">None</span>
<a id="__codelineno-0-320" name="__codelineno-0-320"></a>                <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">split</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_dim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_dim</span><span class="p">])</span>
<a id="__codelineno-0-321" name="__codelineno-0-321"></a>            <span class="p">)</span>
<a id="__codelineno-0-322" name="__codelineno-0-322"></a>            <span class="k">return</span> <span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">w_q</span><span class="p">,</span> <span class="n">b_q</span><span class="p">),)</span> <span class="o">+</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">w_kv</span><span class="p">,</span> <span class="n">b_kv</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">k_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_dim</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-323" name="__codelineno-0-323"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-324" name="__codelineno-0-324"></a>        <span class="n">w_q</span><span class="p">,</span> <span class="n">w_k</span><span class="p">,</span> <span class="n">w_v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">split</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_dim</span><span class="p">])</span>
<a id="__codelineno-0-325" name="__codelineno-0-325"></a>        <span class="n">b_q</span><span class="p">,</span> <span class="n">b_k</span><span class="p">,</span> <span class="n">b_v</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-326" name="__codelineno-0-326"></a>            <span class="kc">None</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">split</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_dim</span><span class="p">])</span>
<a id="__codelineno-0-327" name="__codelineno-0-327"></a>        <span class="p">)</span>
<a id="__codelineno-0-328" name="__codelineno-0-328"></a>        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">w_q</span><span class="p">,</span> <span class="n">b_q</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">w_k</span><span class="p">,</span> <span class="n">b_k</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">w_v</span><span class="p">,</span> <span class="n">b_v</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="danling.NestedTensor" class="doc doc-heading">
        <code>NestedTensor</code>


<a href="#danling.NestedTensor" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">

  
      <p>Wrap a sequence of tensors into a single tensor with a mask.</p>
<p>In sequence to sequence tasks, elements of a batch are usually not of the same length.
This made it tricky to use a single tensor to represent a batch of sequences.</p>
<p>NestedTensor allows to store a sequence of tensors of different lengths in a single object.
It also provides a mask that can be used to retrieve the original sequence of tensors.</p>

  <p><strong>Attributes:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>storage</code></td>
          <td>
                <code><span title="typing.Sequence">Sequence</span>[torch.<span title="torch.Tensor">Tensor</span>]</code>
          </td>
          <td><p>The sequence of tensors.</p></td>
        </tr>
        <tr>
          <td><code>batch_first</code></td>
          <td>
                <code>bool = True</code>
          </td>
          <td><p>Whether the first dimension of the tensors is the batch dimension.</p>
<p>If <code>True</code>, the first dimension is the batch dimension, i.e., <code>B, N, *</code>.</p>
<p>If <code>False</code>, the first dimension is the sequence dimension, i.e., <code>N, B, *</code></p></td>
        </tr>
    </tbody>
  </table>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>tensors</code></td>
          <td>
                <code><span title="typing.Sequence">Sequence</span>[<span title="torch.Tensor">Tensor</span>]</code>
          </td>
          <td></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>batch_first</code></td>
          <td>
                <code>bool</code>
          </td>
          <td></td>
          <td>
                <code>True</code>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Raises:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>ValueError</code>
          </td>
          <td><p>If <code>tensors</code> is not a sequence.</p>
<p>If <code>tensors</code> is empty.</p></td>
        </tr>
    </tbody>
  </table>
      <h4 id="danling.NestedTensor--notes">Notes<a class="headerlink" href="#danling.NestedTensor--notes" title="Permanent link">&para;</a></h4>
<p>We have rewritten the <code>__getattr__</code> function to support as much native tensor operations as possible.
However, not all operations are tested.</p>
<p>Please file an issue if you find any bugs.</p>

<p><strong>Examples:</strong></p>
    <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-0-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-0-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-0-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-0-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-0-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-0-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-0-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-0-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-0-10">10</a></span>
<span class="normal"><a href="#__codelineno-0-11">11</a></span>
<span class="normal"><a href="#__codelineno-0-12">12</a></span>
<span class="normal"><a href="#__codelineno-0-13">13</a></span>
<span class="normal"><a href="#__codelineno-0-14">14</a></span>
<span class="normal"><a href="#__codelineno-0-15">15</a></span>
<span class="normal"><a href="#__codelineno-0-16">16</a></span>
<span class="normal"><a href="#__codelineno-0-17">17</a></span>
<span class="normal"><a href="#__codelineno-0-18">18</a></span>
<span class="normal"><a href="#__codelineno-0-19">19</a></span>
<span class="normal"><a href="#__codelineno-0-20">20</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">danling.tensors</span> <span class="kn">import</span> <span class="n">NestedTensor</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">nested_tensor</span> <span class="o">=</span> <span class="n">NestedTensor</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">])])</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">nested_tensor</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">nested_tensor</span><span class="o">.</span><span class="n">device</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="n">device</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">nested_tensor</span><span class="o">.</span><span class="n">dtype</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="n">torch</span><span class="o">.</span><span class="n">int64</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">nested_tensor</span><span class="o">.</span><span class="n">tensor</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>        <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">nested_tensor</span><span class="o">.</span><span class="n">mask</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a><span class="n">tensor</span><span class="p">([[</span> <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">],</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>        <span class="p">[</span> <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]])</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">nested_tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span><span class="o">.</span><span class="n">tensor</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">],</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>        <span class="p">[</span><span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]])</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">nested_tensor</span><span class="o">.</span><span class="n">half</span><span class="p">()</span><span class="o">.</span><span class="n">tensor</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">],</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a>        <span class="p">[</span><span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>


        <details class="quote">
          <summary>Source code in <code>danling/tensors/nested_tensor.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-9">  9</a></span>
<span class="normal"><a href="#__codelineno-0-10"> 10</a></span>
<span class="normal"><a href="#__codelineno-0-11"> 11</a></span>
<span class="normal"><a href="#__codelineno-0-12"> 12</a></span>
<span class="normal"><a href="#__codelineno-0-13"> 13</a></span>
<span class="normal"><a href="#__codelineno-0-14"> 14</a></span>
<span class="normal"><a href="#__codelineno-0-15"> 15</a></span>
<span class="normal"><a href="#__codelineno-0-16"> 16</a></span>
<span class="normal"><a href="#__codelineno-0-17"> 17</a></span>
<span class="normal"><a href="#__codelineno-0-18"> 18</a></span>
<span class="normal"><a href="#__codelineno-0-19"> 19</a></span>
<span class="normal"><a href="#__codelineno-0-20"> 20</a></span>
<span class="normal"><a href="#__codelineno-0-21"> 21</a></span>
<span class="normal"><a href="#__codelineno-0-22"> 22</a></span>
<span class="normal"><a href="#__codelineno-0-23"> 23</a></span>
<span class="normal"><a href="#__codelineno-0-24"> 24</a></span>
<span class="normal"><a href="#__codelineno-0-25"> 25</a></span>
<span class="normal"><a href="#__codelineno-0-26"> 26</a></span>
<span class="normal"><a href="#__codelineno-0-27"> 27</a></span>
<span class="normal"><a href="#__codelineno-0-28"> 28</a></span>
<span class="normal"><a href="#__codelineno-0-29"> 29</a></span>
<span class="normal"><a href="#__codelineno-0-30"> 30</a></span>
<span class="normal"><a href="#__codelineno-0-31"> 31</a></span>
<span class="normal"><a href="#__codelineno-0-32"> 32</a></span>
<span class="normal"><a href="#__codelineno-0-33"> 33</a></span>
<span class="normal"><a href="#__codelineno-0-34"> 34</a></span>
<span class="normal"><a href="#__codelineno-0-35"> 35</a></span>
<span class="normal"><a href="#__codelineno-0-36"> 36</a></span>
<span class="normal"><a href="#__codelineno-0-37"> 37</a></span>
<span class="normal"><a href="#__codelineno-0-38"> 38</a></span>
<span class="normal"><a href="#__codelineno-0-39"> 39</a></span>
<span class="normal"><a href="#__codelineno-0-40"> 40</a></span>
<span class="normal"><a href="#__codelineno-0-41"> 41</a></span>
<span class="normal"><a href="#__codelineno-0-42"> 42</a></span>
<span class="normal"><a href="#__codelineno-0-43"> 43</a></span>
<span class="normal"><a href="#__codelineno-0-44"> 44</a></span>
<span class="normal"><a href="#__codelineno-0-45"> 45</a></span>
<span class="normal"><a href="#__codelineno-0-46"> 46</a></span>
<span class="normal"><a href="#__codelineno-0-47"> 47</a></span>
<span class="normal"><a href="#__codelineno-0-48"> 48</a></span>
<span class="normal"><a href="#__codelineno-0-49"> 49</a></span>
<span class="normal"><a href="#__codelineno-0-50"> 50</a></span>
<span class="normal"><a href="#__codelineno-0-51"> 51</a></span>
<span class="normal"><a href="#__codelineno-0-52"> 52</a></span>
<span class="normal"><a href="#__codelineno-0-53"> 53</a></span>
<span class="normal"><a href="#__codelineno-0-54"> 54</a></span>
<span class="normal"><a href="#__codelineno-0-55"> 55</a></span>
<span class="normal"><a href="#__codelineno-0-56"> 56</a></span>
<span class="normal"><a href="#__codelineno-0-57"> 57</a></span>
<span class="normal"><a href="#__codelineno-0-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-0-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-0-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-0-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-0-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-0-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-0-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-0-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-0-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-0-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-0-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-0-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-0-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-0-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span>
<span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span>
<span class="normal"><a href="#__codelineno-0-203">203</a></span>
<span class="normal"><a href="#__codelineno-0-204">204</a></span>
<span class="normal"><a href="#__codelineno-0-205">205</a></span>
<span class="normal"><a href="#__codelineno-0-206">206</a></span>
<span class="normal"><a href="#__codelineno-0-207">207</a></span>
<span class="normal"><a href="#__codelineno-0-208">208</a></span>
<span class="normal"><a href="#__codelineno-0-209">209</a></span>
<span class="normal"><a href="#__codelineno-0-210">210</a></span>
<span class="normal"><a href="#__codelineno-0-211">211</a></span>
<span class="normal"><a href="#__codelineno-0-212">212</a></span>
<span class="normal"><a href="#__codelineno-0-213">213</a></span>
<span class="normal"><a href="#__codelineno-0-214">214</a></span>
<span class="normal"><a href="#__codelineno-0-215">215</a></span>
<span class="normal"><a href="#__codelineno-0-216">216</a></span>
<span class="normal"><a href="#__codelineno-0-217">217</a></span>
<span class="normal"><a href="#__codelineno-0-218">218</a></span>
<span class="normal"><a href="#__codelineno-0-219">219</a></span>
<span class="normal"><a href="#__codelineno-0-220">220</a></span>
<span class="normal"><a href="#__codelineno-0-221">221</a></span>
<span class="normal"><a href="#__codelineno-0-222">222</a></span>
<span class="normal"><a href="#__codelineno-0-223">223</a></span>
<span class="normal"><a href="#__codelineno-0-224">224</a></span>
<span class="normal"><a href="#__codelineno-0-225">225</a></span>
<span class="normal"><a href="#__codelineno-0-226">226</a></span>
<span class="normal"><a href="#__codelineno-0-227">227</a></span>
<span class="normal"><a href="#__codelineno-0-228">228</a></span>
<span class="normal"><a href="#__codelineno-0-229">229</a></span>
<span class="normal"><a href="#__codelineno-0-230">230</a></span>
<span class="normal"><a href="#__codelineno-0-231">231</a></span>
<span class="normal"><a href="#__codelineno-0-232">232</a></span>
<span class="normal"><a href="#__codelineno-0-233">233</a></span>
<span class="normal"><a href="#__codelineno-0-234">234</a></span>
<span class="normal"><a href="#__codelineno-0-235">235</a></span>
<span class="normal"><a href="#__codelineno-0-236">236</a></span>
<span class="normal"><a href="#__codelineno-0-237">237</a></span>
<span class="normal"><a href="#__codelineno-0-238">238</a></span>
<span class="normal"><a href="#__codelineno-0-239">239</a></span>
<span class="normal"><a href="#__codelineno-0-240">240</a></span>
<span class="normal"><a href="#__codelineno-0-241">241</a></span>
<span class="normal"><a href="#__codelineno-0-242">242</a></span>
<span class="normal"><a href="#__codelineno-0-243">243</a></span>
<span class="normal"><a href="#__codelineno-0-244">244</a></span>
<span class="normal"><a href="#__codelineno-0-245">245</a></span>
<span class="normal"><a href="#__codelineno-0-246">246</a></span>
<span class="normal"><a href="#__codelineno-0-247">247</a></span>
<span class="normal"><a href="#__codelineno-0-248">248</a></span>
<span class="normal"><a href="#__codelineno-0-249">249</a></span>
<span class="normal"><a href="#__codelineno-0-250">250</a></span>
<span class="normal"><a href="#__codelineno-0-251">251</a></span>
<span class="normal"><a href="#__codelineno-0-252">252</a></span>
<span class="normal"><a href="#__codelineno-0-253">253</a></span>
<span class="normal"><a href="#__codelineno-0-254">254</a></span>
<span class="normal"><a href="#__codelineno-0-255">255</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="k">class</span> <span class="nc">NestedTensor</span><span class="p">:</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">    Wrap a sequence of tensors into a single tensor with a mask.</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a><span class="sd">    In sequence to sequence tasks, elements of a batch are usually not of the same length.</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a><span class="sd">    This made it tricky to use a single tensor to represent a batch of sequences.</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a><span class="sd">    NestedTensor allows to store a sequence of tensors of different lengths in a single object.</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a><span class="sd">    It also provides a mask that can be used to retrieve the original sequence of tensors.</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a><span class="sd">    Attributes</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a><span class="sd">    storage: Sequence[torch.Tensor]</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a><span class="sd">        The sequence of tensors.</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a><span class="sd">    batch_first: bool = True</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a><span class="sd">        Whether the first dimension of the tensors is the batch dimension.</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a><span class="sd">        If `True`, the first dimension is the batch dimension, i.e., `B, N, *`.</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a><span class="sd">        If `False`, the first dimension is the sequence dimension, i.e., `N, B, *`</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a><span class="sd">    tensors: Sequence[torch.Tensor]</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a><span class="sd">    batch_first: bool = True</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a><span class="sd">    Raises</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a><span class="sd">    ------</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a><span class="sd">    ValueError</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a><span class="sd">        If `tensors` is not a sequence.</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a><span class="sd">        If `tensors` is empty.</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a><span class="sd">    Notes</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a><span class="sd">    -----</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a><span class="sd">    We have rewritten the `__getattr__` function to support as much native tensor operations as possible.</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a><span class="sd">    However, not all operations are tested.</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a><span class="sd">    Please file an issue if you find any bugs.</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="sd">    Examples</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">    --------</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a><span class="sd">    &gt;&gt;&gt; from danling.tensors import NestedTensor</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a><span class="sd">    &gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="sd">    &gt;&gt;&gt; nested_tensor.shape</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a><span class="sd">    torch.Size([2, 3])</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="sd">    &gt;&gt;&gt; nested_tensor.device</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a><span class="sd">    device(type=&#39;cpu&#39;)</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a><span class="sd">    &gt;&gt;&gt; nested_tensor.dtype</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a><span class="sd">    torch.int64</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="sd">    &gt;&gt;&gt; nested_tensor.tensor</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a><span class="sd">    tensor([[1, 2, 3],</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">            [4, 5, 0]])</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a><span class="sd">    &gt;&gt;&gt; nested_tensor.mask</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a><span class="sd">    tensor([[ True,  True,  True],</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a><span class="sd">            [ True,  True, False]])</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a><span class="sd">    &gt;&gt;&gt; nested_tensor.to(torch.float).tensor</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a><span class="sd">    tensor([[1., 2., 3.],</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a><span class="sd">            [4., 5., 0.]])</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a><span class="sd">    &gt;&gt;&gt; nested_tensor.half().tensor</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a><span class="sd">    tensor([[1., 2., 3.],</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a><span class="sd">            [4., 5., 0.]], dtype=torch.float16)</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a><span class="sd">    ```</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>    <span class="n">storage</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>    <span class="n">batch_first</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensors</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">batch_first</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;NestedTensor should be initialised with a Sequence, bug got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">values</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensors</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;NestedTensor should be initialised with a non-empty sequence.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">):</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>            <span class="n">tensors</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span> <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">tensors</span><span class="p">)</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">storage</span> <span class="o">=</span> <span class="n">tensors</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">batch_first</span> <span class="o">=</span> <span class="n">batch_first</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a>    <span class="k">def</span> <span class="nf">tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a>        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a><span class="sd">        Return a single tensor by padding all the tensors.</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a><span class="sd">        Returns</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a><span class="sd">        -------</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a><span class="sd">        torch.Tensor</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a><span class="sd">        Examples</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a><span class="sd">        --------</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a><span class="sd">        ```python</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a><span class="sd">        &gt;&gt;&gt; from danling.tensors import NestedTensor</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a><span class="sd">        &gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a><span class="sd">        &gt;&gt;&gt; nested_tensor.tensor</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a><span class="sd">        tensor([[1, 2, 3],</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a><span class="sd">                [4, 5, 0]])</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a><span class="sd">        ```</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_first</span><span class="p">)</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>    <span class="k">def</span> <span class="nf">mask</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a><span class="sd">        Padding mask of `tensor`.</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a><span class="sd">        Returns</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a><span class="sd">        -------</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a><span class="sd">        torch.Tensor</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a><span class="sd">        Examples</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a><span class="sd">        --------</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a><span class="sd">        ```python</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a><span class="sd">        &gt;&gt;&gt; from danling.tensors import NestedTensor</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a><span class="sd">        &gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a><span class="sd">        &gt;&gt;&gt; nested_tensor.mask</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a><span class="sd">        tensor([[ True,  True,  True],</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a><span class="sd">                [ True,  True, False]])</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a><span class="sd">        ```</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mask</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="p">))</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a><span class="sd">        Device of the NestedTensor.</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a><span class="sd">        Returns</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a><span class="sd">        -------</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a><span class="sd">        torch.Tensor</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a><span class="sd">        Examples</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a><span class="sd">        --------</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a><span class="sd">        ```python</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a><span class="sd">        &gt;&gt;&gt; from danling.tensors import NestedTensor</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a><span class="sd">        &gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a><span class="sd">        &gt;&gt;&gt; nested_tensor.device</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a><span class="sd">        device(type=&#39;cpu&#39;)</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a><span class="sd">        ```</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="p">))</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a>    <span class="k">def</span> <span class="nf">shape</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">:</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a>        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a><span class="sd">        Alias for `size`.</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a><span class="sd">        Returns</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a><span class="sd">        -------</span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a><span class="sd">        torch.Size</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a><span class="sd">        Examples</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a><span class="sd">        --------</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a><span class="sd">        ```python</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a><span class="sd">        &gt;&gt;&gt; from danling.tensors import NestedTensor</span>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a><span class="sd">        &gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a><span class="sd">        &gt;&gt;&gt; nested_tensor.shape</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a><span class="sd">        torch.Size([2, 3])</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a><span class="sd">        &gt;&gt;&gt; nested_tensor.storage.append(torch.tensor([6, 7, 8, 9]))</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a><span class="sd">        &gt;&gt;&gt; nested_tensor.shape</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a><span class="sd">        torch.Size([3, 4])</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a><span class="sd">        ```</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a>    <span class="k">def</span> <span class="nf">size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">:</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a>        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a><span class="sd">        Shape of the NestedTensor.</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a><span class="sd">        Returns</span>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a><span class="sd">        -------</span>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a><span class="sd">        torch.Size</span>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a><span class="sd">        Examples</span>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a><span class="sd">        --------</span>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a><span class="sd">        ```python</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a><span class="sd">        &gt;&gt;&gt; from danling.tensors import NestedTensor</span>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a><span class="sd">        &gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])</span>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a><span class="sd">        &gt;&gt;&gt; nested_tensor.size()</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a><span class="sd">        torch.Size([2, 3])</span>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a><span class="sd">        &gt;&gt;&gt; nested_tensor.storage[1] = torch.tensor([4, 5, 6, 7])</span>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a><span class="sd">        &gt;&gt;&gt; nested_tensor.size()</span>
<a id="__codelineno-0-199" name="__codelineno-0-199"></a><span class="sd">        torch.Size([2, 4])</span>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a>
<a id="__codelineno-0-201" name="__codelineno-0-201"></a><span class="sd">        ```</span>
<a id="__codelineno-0-202" name="__codelineno-0-202"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-203" name="__codelineno-0-203"></a>
<a id="__codelineno-0-204" name="__codelineno-0-204"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_size</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="p">))</span>
<a id="__codelineno-0-205" name="__codelineno-0-205"></a>
<a id="__codelineno-0-206" name="__codelineno-0-206"></a>    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-207" name="__codelineno-0-207"></a>        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
<a id="__codelineno-0-208" name="__codelineno-0-208"></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ret</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
<a id="__codelineno-0-209" name="__codelineno-0-209"></a>            <span class="k">return</span> <span class="n">ret</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span>  <span class="c1"># pylint: disable=E1101</span>
<a id="__codelineno-0-210" name="__codelineno-0-210"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span>
<a id="__codelineno-0-211" name="__codelineno-0-211"></a>
<a id="__codelineno-0-212" name="__codelineno-0-212"></a>    <span class="k">def</span> <span class="fm">__getattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<a id="__codelineno-0-213" name="__codelineno-0-213"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="p">:</span>
<a id="__codelineno-0-214" name="__codelineno-0-214"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unable to get </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> from an empty </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<a id="__codelineno-0-215" name="__codelineno-0-215"></a>        <span class="n">ret</span> <span class="o">=</span> <span class="p">[</span><span class="nb">getattr</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="p">]</span>
<a id="__codelineno-0-216" name="__codelineno-0-216"></a>        <span class="n">elem</span> <span class="o">=</span> <span class="n">ret</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-217" name="__codelineno-0-217"></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">elem</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
<a id="__codelineno-0-218" name="__codelineno-0-218"></a>            <span class="k">return</span> <span class="n">NestedTensor</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span>
<a id="__codelineno-0-219" name="__codelineno-0-219"></a>        <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="n">elem</span><span class="p">):</span>
<a id="__codelineno-0-220" name="__codelineno-0-220"></a>            <span class="k">return</span> <span class="n">_TensorFuncWrapper</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span>
<a id="__codelineno-0-221" name="__codelineno-0-221"></a>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">ret</span><span class="p">))</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
<a id="__codelineno-0-222" name="__codelineno-0-222"></a>            <span class="k">return</span> <span class="n">elem</span>
<a id="__codelineno-0-223" name="__codelineno-0-223"></a>        <span class="k">return</span> <span class="n">ret</span>
<a id="__codelineno-0-224" name="__codelineno-0-224"></a>
<a id="__codelineno-0-225" name="__codelineno-0-225"></a>    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<a id="__codelineno-0-226" name="__codelineno-0-226"></a>        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="p">)</span>
<a id="__codelineno-0-227" name="__codelineno-0-227"></a>
<a id="__codelineno-0-228" name="__codelineno-0-228"></a>    <span class="k">def</span> <span class="nf">__setstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">storage</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-229" name="__codelineno-0-229"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">storage</span> <span class="o">=</span> <span class="n">storage</span>
<a id="__codelineno-0-230" name="__codelineno-0-230"></a>
<a id="__codelineno-0-231" name="__codelineno-0-231"></a>    <span class="k">def</span> <span class="nf">__getstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-232" name="__codelineno-0-232"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">storage</span>
<a id="__codelineno-0-233" name="__codelineno-0-233"></a>
<a id="__codelineno-0-234" name="__codelineno-0-234"></a>    <span class="nd">@staticmethod</span>
<a id="__codelineno-0-235" name="__codelineno-0-235"></a>    <span class="nd">@lru_cache</span><span class="p">(</span><span class="n">maxsize</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<a id="__codelineno-0-236" name="__codelineno-0-236"></a>    <span class="k">def</span> <span class="nf">_tensor</span><span class="p">(</span><span class="n">storage</span><span class="p">,</span> <span class="n">batch_first</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-237" name="__codelineno-0-237"></a>        <span class="k">return</span> <span class="n">pad_sequence</span><span class="p">(</span><span class="n">storage</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="n">batch_first</span><span class="p">)</span>
<a id="__codelineno-0-238" name="__codelineno-0-238"></a>
<a id="__codelineno-0-239" name="__codelineno-0-239"></a>    <span class="nd">@staticmethod</span>
<a id="__codelineno-0-240" name="__codelineno-0-240"></a>    <span class="nd">@lru_cache</span><span class="p">(</span><span class="n">maxsize</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<a id="__codelineno-0-241" name="__codelineno-0-241"></a>    <span class="k">def</span> <span class="nf">_mask</span><span class="p">(</span><span class="n">storage</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-242" name="__codelineno-0-242"></a>        <span class="n">lens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">storage</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">storage</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-243" name="__codelineno-0-243"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">lens</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">storage</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">&lt;</span> <span class="n">lens</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>  <span class="c1"># pylint: disable=E1101</span>
<a id="__codelineno-0-244" name="__codelineno-0-244"></a>
<a id="__codelineno-0-245" name="__codelineno-0-245"></a>    <span class="nd">@staticmethod</span>
<a id="__codelineno-0-246" name="__codelineno-0-246"></a>    <span class="nd">@lru_cache</span><span class="p">(</span><span class="n">maxsize</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<a id="__codelineno-0-247" name="__codelineno-0-247"></a>    <span class="k">def</span> <span class="nf">_device</span><span class="p">(</span><span class="n">storage</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
<a id="__codelineno-0-248" name="__codelineno-0-248"></a>        <span class="k">return</span> <span class="n">storage</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span>
<a id="__codelineno-0-249" name="__codelineno-0-249"></a>
<a id="__codelineno-0-250" name="__codelineno-0-250"></a>    <span class="nd">@staticmethod</span>
<a id="__codelineno-0-251" name="__codelineno-0-251"></a>    <span class="nd">@lru_cache</span><span class="p">(</span><span class="n">maxsize</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<a id="__codelineno-0-252" name="__codelineno-0-252"></a>    <span class="k">def</span> <span class="nf">_size</span><span class="p">(</span><span class="n">storage</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">:</span>
<a id="__codelineno-0-253" name="__codelineno-0-253"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(</span>  <span class="c1"># pylint: disable=E1101</span>
<a id="__codelineno-0-254" name="__codelineno-0-254"></a>            <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">storage</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">storage</span><span class="p">),</span> <span class="o">*</span><span class="n">storage</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span>
<a id="__codelineno-0-255" name="__codelineno-0-255"></a>        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h3 id="danling.tensors.nested_tensor.NestedTensor.device" class="doc doc-heading">
<code class="highlight language-python"><span class="n">device</span><span class="p">()</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#danling.tensors.nested_tensor.NestedTensor.device" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Device of the NestedTensor.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>torch.<span title="torch.Tensor">Tensor</span></code>
          </td>
          <td></td>
        </tr>
    </tbody>
  </table>

<p><strong>Examples:</strong></p>
    <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1">1</a></span>
<span class="normal"><a href="#__codelineno-0-2">2</a></span>
<span class="normal"><a href="#__codelineno-0-3">3</a></span>
<span class="normal"><a href="#__codelineno-0-4">4</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">danling.tensors</span> <span class="kn">import</span> <span class="n">NestedTensor</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">nested_tensor</span> <span class="o">=</span> <span class="n">NestedTensor</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">])])</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">nested_tensor</span><span class="o">.</span><span class="n">device</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="n">device</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>

      <details class="quote">
        <summary>Source code in <code>danling/tensors/nested_tensor.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-135" name="__codelineno-0-135"></a><span class="nd">@property</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a><span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a><span class="sd">    Device of the NestedTensor.</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a><span class="sd">    -------</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a><span class="sd">    torch.Tensor</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a><span class="sd">    Examples</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a><span class="sd">    --------</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a><span class="sd">    &gt;&gt;&gt; from danling.tensors import NestedTensor</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a><span class="sd">    &gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a><span class="sd">    &gt;&gt;&gt; nested_tensor.device</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a><span class="sd">    device(type=&#39;cpu&#39;)</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a><span class="sd">    ```</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="danling.tensors.nested_tensor.NestedTensor.mask" class="doc doc-heading">
<code class="highlight language-python"><span class="n">mask</span><span class="p">()</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#danling.tensors.nested_tensor.NestedTensor.mask" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Padding mask of <code>tensor</code>.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>torch.<span title="torch.Tensor">Tensor</span></code>
          </td>
          <td></td>
        </tr>
    </tbody>
  </table>

<p><strong>Examples:</strong></p>
    <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1">1</a></span>
<span class="normal"><a href="#__codelineno-0-2">2</a></span>
<span class="normal"><a href="#__codelineno-0-3">3</a></span>
<span class="normal"><a href="#__codelineno-0-4">4</a></span>
<span class="normal"><a href="#__codelineno-0-5">5</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">danling.tensors</span> <span class="kn">import</span> <span class="n">NestedTensor</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">nested_tensor</span> <span class="o">=</span> <span class="n">NestedTensor</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">])])</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">nested_tensor</span><span class="o">.</span><span class="n">mask</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="n">tensor</span><span class="p">([[</span> <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">],</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>        <span class="p">[</span> <span class="kc">True</span><span class="p">,</span>  <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]])</span>
</code></pre></div></td></tr></table></div>

      <details class="quote">
        <summary>Source code in <code>danling/tensors/nested_tensor.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-112" name="__codelineno-0-112"></a><span class="nd">@property</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a><span class="k">def</span> <span class="nf">mask</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a><span class="sd">    Padding mask of `tensor`.</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a><span class="sd">    -------</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a><span class="sd">    torch.Tensor</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a><span class="sd">    Examples</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a><span class="sd">    --------</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a><span class="sd">    &gt;&gt;&gt; from danling.tensors import NestedTensor</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a><span class="sd">    &gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a><span class="sd">    &gt;&gt;&gt; nested_tensor.mask</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a><span class="sd">    tensor([[ True,  True,  True],</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a><span class="sd">            [ True,  True, False]])</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a><span class="sd">    ```</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mask</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="danling.tensors.nested_tensor.NestedTensor.shape" class="doc doc-heading">
<code class="highlight language-python"><span class="n">shape</span><span class="p">()</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#danling.tensors.nested_tensor.NestedTensor.shape" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Alias for <code>size</code>.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>torch.<span title="torch.Size">Size</span></code>
          </td>
          <td></td>
        </tr>
    </tbody>
  </table>

<p><strong>Examples:</strong></p>
    <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1">1</a></span>
<span class="normal"><a href="#__codelineno-0-2">2</a></span>
<span class="normal"><a href="#__codelineno-0-3">3</a></span>
<span class="normal"><a href="#__codelineno-0-4">4</a></span>
<span class="normal"><a href="#__codelineno-0-5">5</a></span>
<span class="normal"><a href="#__codelineno-0-6">6</a></span>
<span class="normal"><a href="#__codelineno-0-7">7</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">danling.tensors</span> <span class="kn">import</span> <span class="n">NestedTensor</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">nested_tensor</span> <span class="o">=</span> <span class="n">NestedTensor</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">])])</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">nested_tensor</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">nested_tensor</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]))</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">nested_tensor</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
</code></pre></div></td></tr></table></div>

      <details class="quote">
        <summary>Source code in <code>danling/tensors/nested_tensor.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-157" name="__codelineno-0-157"></a><span class="nd">@property</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a><span class="k">def</span> <span class="nf">shape</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">:</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a><span class="sd">    Alias for `size`.</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a><span class="sd">    -------</span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a><span class="sd">    torch.Size</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a><span class="sd">    Examples</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a><span class="sd">    --------</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a><span class="sd">    &gt;&gt;&gt; from danling.tensors import NestedTensor</span>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a><span class="sd">    &gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a><span class="sd">    &gt;&gt;&gt; nested_tensor.shape</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a><span class="sd">    torch.Size([2, 3])</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a><span class="sd">    &gt;&gt;&gt; nested_tensor.storage.append(torch.tensor([6, 7, 8, 9]))</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a><span class="sd">    &gt;&gt;&gt; nested_tensor.shape</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a><span class="sd">    torch.Size([3, 4])</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a><span class="sd">    ```</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="danling.tensors.nested_tensor.NestedTensor.size" class="doc doc-heading">
<code class="highlight language-python"><span class="n">size</span><span class="p">()</span></code>

<a href="#danling.tensors.nested_tensor.NestedTensor.size" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Shape of the NestedTensor.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>torch.<span title="torch.Size">Size</span></code>
          </td>
          <td></td>
        </tr>
    </tbody>
  </table>

<p><strong>Examples:</strong></p>
    <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1">1</a></span>
<span class="normal"><a href="#__codelineno-0-2">2</a></span>
<span class="normal"><a href="#__codelineno-0-3">3</a></span>
<span class="normal"><a href="#__codelineno-0-4">4</a></span>
<span class="normal"><a href="#__codelineno-0-5">5</a></span>
<span class="normal"><a href="#__codelineno-0-6">6</a></span>
<span class="normal"><a href="#__codelineno-0-7">7</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">danling.tensors</span> <span class="kn">import</span> <span class="n">NestedTensor</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">nested_tensor</span> <span class="o">=</span> <span class="n">NestedTensor</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">])])</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">nested_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">nested_tensor</span><span class="o">.</span><span class="n">storage</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">nested_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
</code></pre></div></td></tr></table></div>

      <details class="quote">
        <summary>Source code in <code>danling/tensors/nested_tensor.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span>
<span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span>
<span class="normal"><a href="#__codelineno-0-203">203</a></span>
<span class="normal"><a href="#__codelineno-0-204">204</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-182" name="__codelineno-0-182"></a><span class="k">def</span> <span class="nf">size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">:</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a><span class="sd">    Shape of the NestedTensor.</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a><span class="sd">    -------</span>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a><span class="sd">    torch.Size</span>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a><span class="sd">    Examples</span>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a><span class="sd">    --------</span>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a><span class="sd">    &gt;&gt;&gt; from danling.tensors import NestedTensor</span>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a><span class="sd">    &gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])</span>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a><span class="sd">    &gt;&gt;&gt; nested_tensor.size()</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a><span class="sd">    torch.Size([2, 3])</span>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a><span class="sd">    &gt;&gt;&gt; nested_tensor.storage[1] = torch.tensor([4, 5, 6, 7])</span>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a><span class="sd">    &gt;&gt;&gt; nested_tensor.size()</span>
<a id="__codelineno-0-199" name="__codelineno-0-199"></a><span class="sd">    torch.Size([2, 4])</span>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a>
<a id="__codelineno-0-201" name="__codelineno-0-201"></a><span class="sd">    ```</span>
<a id="__codelineno-0-202" name="__codelineno-0-202"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-203" name="__codelineno-0-203"></a>
<a id="__codelineno-0-204" name="__codelineno-0-204"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_size</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="danling.tensors.nested_tensor.NestedTensor.tensor" class="doc doc-heading">
<code class="highlight language-python"><span class="n">tensor</span><span class="p">()</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#danling.tensors.nested_tensor.NestedTensor.tensor" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Return a single tensor by padding all the tensors.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>torch.<span title="torch.Tensor">Tensor</span></code>
          </td>
          <td></td>
        </tr>
    </tbody>
  </table>

<p><strong>Examples:</strong></p>
    <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1">1</a></span>
<span class="normal"><a href="#__codelineno-0-2">2</a></span>
<span class="normal"><a href="#__codelineno-0-3">3</a></span>
<span class="normal"><a href="#__codelineno-0-4">4</a></span>
<span class="normal"><a href="#__codelineno-0-5">5</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">danling.tensors</span> <span class="kn">import</span> <span class="n">NestedTensor</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">nested_tensor</span> <span class="o">=</span> <span class="n">NestedTensor</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">])])</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">nested_tensor</span><span class="o">.</span><span class="n">tensor</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>        <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
</code></pre></div></td></tr></table></div>

      <details class="quote">
        <summary>Source code in <code>danling/tensors/nested_tensor.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-89" name="__codelineno-0-89"></a><span class="nd">@property</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a><span class="k">def</span> <span class="nf">tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a><span class="sd">    Return a single tensor by padding all the tensors.</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a><span class="sd">    -------</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a><span class="sd">    torch.Tensor</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a><span class="sd">    Examples</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a><span class="sd">    --------</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a><span class="sd">    &gt;&gt;&gt; from danling.tensors import NestedTensor</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a><span class="sd">    &gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a><span class="sd">    &gt;&gt;&gt; nested_tensor.tensor</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a><span class="sd">    tensor([[1, 2, 3],</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a><span class="sd">            [4, 5, 0]])</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a><span class="sd">    ```</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_first</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="danling.Registry" class="doc doc-heading">
        <code>Registry</code>


<a href="#danling.Registry" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
      <p class="doc doc-class-bases">
        Bases: <code><span title="chanfig.NestedDict">NestedDict</span></code></p>

  
      <p><code>Registry</code> for components.</p>
<h4 id="danling.Registry--notes">Notes<a class="headerlink" href="#danling.Registry--notes" title="Permanent link">&para;</a></h4>
<p><code>Registry</code> inherits from <a href="https://chanfig.danling.org/nested_dict/"><code>NestedDict</code></a>.</p>
<p>Therefore, <code>Registry</code> comes in a nested structure by nature.
You could create a sub-registry by simply calling <code>registry.sub_registry = Registry</code>,
and access through <code>registry.sub_registry.register()</code>.</p>

<p><strong>Examples:</strong></p>
    <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-0-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-0-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-0-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-0-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-0-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-0-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-0-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-0-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-0-10">10</a></span>
<span class="normal"><a href="#__codelineno-0-11">11</a></span>
<span class="normal"><a href="#__codelineno-0-12">12</a></span>
<span class="normal"><a href="#__codelineno-0-13">13</a></span>
<span class="normal"><a href="#__codelineno-0-14">14</a></span>
<span class="normal"><a href="#__codelineno-0-15">15</a></span>
<span class="normal"><a href="#__codelineno-0-16">16</a></span>
<span class="normal"><a href="#__codelineno-0-17">17</a></span>
<span class="normal"><a href="#__codelineno-0-18">18</a></span>
<span class="normal"><a href="#__codelineno-0-19">19</a></span>
<span class="normal"><a href="#__codelineno-0-20">20</a></span>
<span class="normal"><a href="#__codelineno-0-21">21</a></span>
<span class="normal"><a href="#__codelineno-0-22">22</a></span>
<span class="normal"><a href="#__codelineno-0-23">23</a></span>
<span class="normal"><a href="#__codelineno-0-24">24</a></span>
<span class="normal"><a href="#__codelineno-0-25">25</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">registry</span> <span class="o">=</span> <span class="n">Registry</span><span class="p">(</span><span class="s2">&quot;test&quot;</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="nd">@registry</span><span class="o">.</span><span class="n">register</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="o">...</span> <span class="nd">@registry</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;Module1&quot;</span><span class="p">)</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="o">...</span> <span class="k">class</span> <span class="nc">Module</span><span class="p">:</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="o">...</span>     <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="o">...</span>         <span class="bp">self</span><span class="o">.</span><span class="n">a</span> <span class="o">=</span> <span class="n">a</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="o">...</span>         <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">b</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">module</span> <span class="o">=</span> <span class="n">registry</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="n">Module</span><span class="p">,</span> <span class="s2">&quot;Module2&quot;</span><span class="p">)</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">registry</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="n">Registry</span><span class="p">(</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>  <span class="p">(</span><span class="n">Module1</span><span class="p">):</span> <span class="o">&lt;</span><span class="k">class</span> <span class="err">&#39;</span><span class="nc">danling</span><span class="o">.</span><span class="n">registry</span><span class="o">.</span><span class="n">registry</span><span class="o">.</span><span class="n">Module</span><span class="s1">&#39;&gt;</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>  <span class="p">(</span><span class="n">Module</span><span class="p">):</span> <span class="o">&lt;</span><span class="k">class</span> <span class="err">&#39;</span><span class="nc">danling</span><span class="o">.</span><span class="n">registry</span><span class="o">.</span><span class="n">registry</span><span class="o">.</span><span class="n">Module</span><span class="s1">&#39;&gt;</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>  <span class="p">(</span><span class="n">Module2</span><span class="p">):</span> <span class="o">&lt;</span><span class="k">class</span> <span class="err">&#39;</span><span class="nc">danling</span><span class="o">.</span><span class="n">registry</span><span class="o">.</span><span class="n">registry</span><span class="o">.</span><span class="n">Module</span><span class="s1">&#39;&gt;</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a><span class="p">)</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">registry</span><span class="o">.</span><span class="n">lookup</span><span class="p">(</span><span class="s2">&quot;Module&quot;</span><span class="p">)</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a><span class="o">&lt;</span><span class="k">class</span> <span class="err">&#39;</span><span class="nc">danling</span><span class="o">.</span><span class="n">registry</span><span class="o">.</span><span class="n">registry</span><span class="o">.</span><span class="n">Module</span><span class="s1">&#39;&gt;</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">config</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;module&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;Module&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}}</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a><span class="o">&gt;&gt;&gt;</span> <span class="c1"># registry.register(Module)</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">module</span> <span class="o">=</span> <span class="n">registry</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;module&quot;</span><span class="p">])</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a><span class="o">&gt;&gt;&gt;</span> <span class="nb">type</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a><span class="o">&lt;</span><span class="k">class</span> <span class="err">&#39;</span><span class="nc">danling</span><span class="o">.</span><span class="n">registry</span><span class="o">.</span><span class="n">registry</span><span class="o">.</span><span class="n">Module</span><span class="s1">&#39;&gt;</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">module</span><span class="o">.</span><span class="n">a</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a><span class="mi">1</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">module</span><span class="o">.</span><span class="n">b</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a><span class="mi">2</span>
</code></pre></div></td></tr></table></div>


        <details class="quote">
          <summary>Source code in <code>danling/registry/registry.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-7">  7</a></span>
<span class="normal"><a href="#__codelineno-0-8">  8</a></span>
<span class="normal"><a href="#__codelineno-0-9">  9</a></span>
<span class="normal"><a href="#__codelineno-0-10"> 10</a></span>
<span class="normal"><a href="#__codelineno-0-11"> 11</a></span>
<span class="normal"><a href="#__codelineno-0-12"> 12</a></span>
<span class="normal"><a href="#__codelineno-0-13"> 13</a></span>
<span class="normal"><a href="#__codelineno-0-14"> 14</a></span>
<span class="normal"><a href="#__codelineno-0-15"> 15</a></span>
<span class="normal"><a href="#__codelineno-0-16"> 16</a></span>
<span class="normal"><a href="#__codelineno-0-17"> 17</a></span>
<span class="normal"><a href="#__codelineno-0-18"> 18</a></span>
<span class="normal"><a href="#__codelineno-0-19"> 19</a></span>
<span class="normal"><a href="#__codelineno-0-20"> 20</a></span>
<span class="normal"><a href="#__codelineno-0-21"> 21</a></span>
<span class="normal"><a href="#__codelineno-0-22"> 22</a></span>
<span class="normal"><a href="#__codelineno-0-23"> 23</a></span>
<span class="normal"><a href="#__codelineno-0-24"> 24</a></span>
<span class="normal"><a href="#__codelineno-0-25"> 25</a></span>
<span class="normal"><a href="#__codelineno-0-26"> 26</a></span>
<span class="normal"><a href="#__codelineno-0-27"> 27</a></span>
<span class="normal"><a href="#__codelineno-0-28"> 28</a></span>
<span class="normal"><a href="#__codelineno-0-29"> 29</a></span>
<span class="normal"><a href="#__codelineno-0-30"> 30</a></span>
<span class="normal"><a href="#__codelineno-0-31"> 31</a></span>
<span class="normal"><a href="#__codelineno-0-32"> 32</a></span>
<span class="normal"><a href="#__codelineno-0-33"> 33</a></span>
<span class="normal"><a href="#__codelineno-0-34"> 34</a></span>
<span class="normal"><a href="#__codelineno-0-35"> 35</a></span>
<span class="normal"><a href="#__codelineno-0-36"> 36</a></span>
<span class="normal"><a href="#__codelineno-0-37"> 37</a></span>
<span class="normal"><a href="#__codelineno-0-38"> 38</a></span>
<span class="normal"><a href="#__codelineno-0-39"> 39</a></span>
<span class="normal"><a href="#__codelineno-0-40"> 40</a></span>
<span class="normal"><a href="#__codelineno-0-41"> 41</a></span>
<span class="normal"><a href="#__codelineno-0-42"> 42</a></span>
<span class="normal"><a href="#__codelineno-0-43"> 43</a></span>
<span class="normal"><a href="#__codelineno-0-44"> 44</a></span>
<span class="normal"><a href="#__codelineno-0-45"> 45</a></span>
<span class="normal"><a href="#__codelineno-0-46"> 46</a></span>
<span class="normal"><a href="#__codelineno-0-47"> 47</a></span>
<span class="normal"><a href="#__codelineno-0-48"> 48</a></span>
<span class="normal"><a href="#__codelineno-0-49"> 49</a></span>
<span class="normal"><a href="#__codelineno-0-50"> 50</a></span>
<span class="normal"><a href="#__codelineno-0-51"> 51</a></span>
<span class="normal"><a href="#__codelineno-0-52"> 52</a></span>
<span class="normal"><a href="#__codelineno-0-53"> 53</a></span>
<span class="normal"><a href="#__codelineno-0-54"> 54</a></span>
<span class="normal"><a href="#__codelineno-0-55"> 55</a></span>
<span class="normal"><a href="#__codelineno-0-56"> 56</a></span>
<span class="normal"><a href="#__codelineno-0-57"> 57</a></span>
<span class="normal"><a href="#__codelineno-0-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-0-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-0-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-0-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-0-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-0-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-0-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-0-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-0-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-0-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-0-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-0-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-0-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-0-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span>
<span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span>
<span class="normal"><a href="#__codelineno-0-203">203</a></span>
<span class="normal"><a href="#__codelineno-0-204">204</a></span>
<span class="normal"><a href="#__codelineno-0-205">205</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="k">class</span> <span class="nc">Registry</span><span class="p">(</span><span class="n">NestedDict</span><span class="p">):</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>    <span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="sd">    `Registry` for components.</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">    Notes</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="sd">    -----</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a><span class="sd">    `Registry` inherits from [`NestedDict`](https://chanfig.danling.org/nested_dict/).</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a><span class="sd">    Therefore, `Registry` comes in a nested structure by nature.</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a><span class="sd">    You could create a sub-registry by simply calling `registry.sub_registry = Registry`,</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a><span class="sd">    and access through `registry.sub_registry.register()`.</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a><span class="sd">    Examples</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a><span class="sd">    --------</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a><span class="sd">    &gt;&gt;&gt; registry = Registry(&quot;test&quot;)</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a><span class="sd">    &gt;&gt;&gt; @registry.register</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a><span class="sd">    ... @registry.register(&quot;Module1&quot;)</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a><span class="sd">    ... class Module:</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a><span class="sd">    ...     def __init__(self, a, b):</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a><span class="sd">    ...         self.a = a</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a><span class="sd">    ...         self.b = b</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a><span class="sd">    &gt;&gt;&gt; module = registry.register(Module, &quot;Module2&quot;)</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="sd">    &gt;&gt;&gt; registry</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a><span class="sd">    Registry(</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a><span class="sd">      (Module1): &lt;class &#39;danling.registry.registry.Module&#39;&gt;</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a><span class="sd">      (Module): &lt;class &#39;danling.registry.registry.Module&#39;&gt;</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a><span class="sd">      (Module2): &lt;class &#39;danling.registry.registry.Module&#39;&gt;</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a><span class="sd">    )</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a><span class="sd">    &gt;&gt;&gt; registry.lookup(&quot;Module&quot;)</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a><span class="sd">    &lt;class &#39;danling.registry.registry.Module&#39;&gt;</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a><span class="sd">    &gt;&gt;&gt; config = {&quot;module&quot;: {&quot;name&quot;: &quot;Module&quot;, &quot;a&quot;: 1, &quot;b&quot;: 2}}</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a><span class="sd">    &gt;&gt;&gt; # registry.register(Module)</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a><span class="sd">    &gt;&gt;&gt; module = registry.build(config[&quot;module&quot;])</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a><span class="sd">    &gt;&gt;&gt; type(module)</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a><span class="sd">    &lt;class &#39;danling.registry.registry.Module&#39;&gt;</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a><span class="sd">    &gt;&gt;&gt; module.a</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a><span class="sd">    1</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a><span class="sd">    &gt;&gt;&gt; module.b</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a><span class="sd">    2</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="sd">    ```</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>    <span class="n">override</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">override</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="s2">&quot;override&quot;</span><span class="p">,</span> <span class="n">override</span><span class="p">)</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a>    <span class="k">def</span> <span class="nf">register</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">component</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">:</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a>        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="sd">        Register a new component</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">        Parameters</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a><span class="sd">        ----------</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a><span class="sd">        component: Optional[Callable] = None</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a><span class="sd">            The component to register.</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a><span class="sd">        name: Optional[str] = component.__name__</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a><span class="sd">            The name of the component.</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a><span class="sd">        Returns</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a><span class="sd">        -------</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a><span class="sd">        component: Callable</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a><span class="sd">            The registered component.</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a><span class="sd">        Raises</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a><span class="sd">        ------</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a><span class="sd">        ValueError</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a><span class="sd">            If the component with the same name already exists and `Registry.override=False`.</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a><span class="sd">        Examples</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a><span class="sd">        --------</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a><span class="sd">        ```python</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a><span class="sd">        &gt;&gt;&gt; registry = Registry(&quot;test&quot;)</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a><span class="sd">        &gt;&gt;&gt; @registry.register</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a><span class="sd">        ... @registry.register(&quot;Module1&quot;)</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a><span class="sd">        ... class Module:</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a><span class="sd">        ...     def __init__(self, a, b):</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a><span class="sd">        ...         self.a = a</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a><span class="sd">        ...         self.b = b</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a><span class="sd">        &gt;&gt;&gt; module = registry.register(Module, &quot;Module2&quot;)</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a><span class="sd">        &gt;&gt;&gt; registry</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a><span class="sd">        Registry(</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a><span class="sd">          (Module1): &lt;class &#39;danling.registry.registry.Module&#39;&gt;</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a><span class="sd">          (Module): &lt;class &#39;danling.registry.registry.Module&#39;&gt;</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a><span class="sd">          (Module2): &lt;class &#39;danling.registry.registry.Module&#39;&gt;</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a><span class="sd">        )</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a><span class="sd">        ```</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">override</span><span class="p">:</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Component with name </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> already exists&quot;</span><span class="p">)</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>        <span class="c1"># Registry.register()</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>        <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">component</span><span class="p">)</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>        <span class="c1"># @Registry.register()</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>        <span class="nd">@wraps</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">register</span><span class="p">)</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>        <span class="k">def</span> <span class="nf">register</span><span class="p">(</span><span class="n">component</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>            <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>                <span class="n">name</span> <span class="o">=</span> <span class="n">component</span><span class="o">.</span><span class="vm">__name__</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">component</span><span class="p">)</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>            <span class="k">return</span> <span class="n">component</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>        <span class="c1"># @Registry.register</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>        <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="n">component</span><span class="p">)</span> <span class="ow">and</span> <span class="n">name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>            <span class="k">return</span> <span class="n">register</span><span class="p">(</span><span class="n">component</span><span class="p">)</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>        <span class="k">return</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">register</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">component</span><span class="p">)</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a>    <span class="k">def</span> <span class="nf">lookup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a><span class="sd">        Lookup for a component.</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a><span class="sd">        Parameters</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a><span class="sd">        ----------</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a><span class="sd">        name: str</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a><span class="sd">            The name of the component.</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a><span class="sd">        Returns</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a><span class="sd">        -------</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a><span class="sd">        value: Any</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a><span class="sd">        Raises</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a><span class="sd">        ------</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a><span class="sd">        KeyError</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a><span class="sd">            If the component is not registered.</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a><span class="sd">        Examples</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a><span class="sd">        --------</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a><span class="sd">        ```python</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a><span class="sd">        &gt;&gt;&gt; registry = Registry(&quot;test&quot;)</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a><span class="sd">        &gt;&gt;&gt; @registry.register</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a><span class="sd">        ... class Module:</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a><span class="sd">        ...     def __init__(self, a, b):</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a><span class="sd">        ...         self.a = a</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a><span class="sd">        ...         self.b = b</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a><span class="sd">        &gt;&gt;&gt; registry.lookup(&quot;Module&quot;)</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a><span class="sd">        &lt;class &#39;danling.registry.registry.Module&#39;&gt;</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a><span class="sd">        ```</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a>    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a><span class="sd">        Build a component.</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a><span class="sd">        Parameters</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a><span class="sd">        ----------</span>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a><span class="sd">        name: str</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a><span class="sd">            The name of the component.</span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a><span class="sd">        *args</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a><span class="sd">            The arguments to pass to the component.</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a><span class="sd">        **kwargs</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a><span class="sd">            The keyword arguments to pass to the component.</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a><span class="sd">        Returns</span>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a><span class="sd">        -------</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a><span class="sd">        component: Callable</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a><span class="sd">        Raises</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a><span class="sd">        ------</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a><span class="sd">        KeyError</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a><span class="sd">            If the component is not registered.</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a><span class="sd">        Examples</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a><span class="sd">        --------</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a><span class="sd">        ```python</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a><span class="sd">        &gt;&gt;&gt; registry = Registry(&quot;test&quot;)</span>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a><span class="sd">        &gt;&gt;&gt; @registry.register</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a><span class="sd">        ... class Module:</span>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a><span class="sd">        ...     def __init__(self, a, b):</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a><span class="sd">        ...         self.a = a</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a><span class="sd">        ...         self.b = b</span>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a><span class="sd">        &gt;&gt;&gt; config = {&quot;module&quot;: {&quot;name&quot;: &quot;Module&quot;, &quot;a&quot;: 1, &quot;b&quot;: 2}}</span>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a><span class="sd">        &gt;&gt;&gt; # registry.register(Module)</span>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a><span class="sd">        &gt;&gt;&gt; module = registry.build(config[&quot;module&quot;])</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a><span class="sd">        &gt;&gt;&gt; type(module)</span>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a><span class="sd">        &lt;class &#39;danling.registry.registry.Module&#39;&gt;</span>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a><span class="sd">        &gt;&gt;&gt; module.a</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a><span class="sd">        1</span>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a><span class="sd">        &gt;&gt;&gt; module.b</span>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a><span class="sd">        2</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a><span class="sd">        ```</span>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-199" name="__codelineno-0-199"></a>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">args</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">kwargs</span><span class="p">:</span>
<a id="__codelineno-0-201" name="__codelineno-0-201"></a>            <span class="n">name</span><span class="p">,</span> <span class="n">kwargs</span> <span class="o">=</span> <span class="n">name</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;name&quot;</span><span class="p">),</span> <span class="n">name</span>  <span class="c1"># type: ignore</span>
<a id="__codelineno-0-202" name="__codelineno-0-202"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">name</span><span class="p">)(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<a id="__codelineno-0-203" name="__codelineno-0-203"></a>
<a id="__codelineno-0-204" name="__codelineno-0-204"></a>    <span class="k">def</span> <span class="nf">__wrapped__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-205" name="__codelineno-0-205"></a>        <span class="k">pass</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h3 id="danling.registry.registry.Registry.build" class="doc doc-heading">
<code class="highlight language-python"><span class="n">build</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#danling.registry.registry.Registry.build" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Build a component.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>name</code></td>
          <td>
                <code>str</code>
          </td>
          <td><p>The name of the component.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>*args</code></td>
          <td>
          </td>
          <td><p>The arguments to pass to the component.</p></td>
          <td>
                <code>()</code>
          </td>
        </tr>
        <tr>
          <td><code>**kwargs</code></td>
          <td>
          </td>
          <td><p>The keyword arguments to pass to the component.</p></td>
          <td>
                <code>{}</code>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>component</code></td>          <td>
                <code><span title="typing.Callable">Callable</span></code>
          </td>
          <td></td>
        </tr>
    </tbody>
  </table>

  <p><strong>Raises:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>KeyError</code>
          </td>
          <td><p>If the component is not registered.</p></td>
        </tr>
    </tbody>
  </table>

<p><strong>Examples:</strong></p>
    <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-0-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-0-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-0-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-0-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-0-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-0-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-0-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-0-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-0-10">10</a></span>
<span class="normal"><a href="#__codelineno-0-11">11</a></span>
<span class="normal"><a href="#__codelineno-0-12">12</a></span>
<span class="normal"><a href="#__codelineno-0-13">13</a></span>
<span class="normal"><a href="#__codelineno-0-14">14</a></span>
<span class="normal"><a href="#__codelineno-0-15">15</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">registry</span> <span class="o">=</span> <span class="n">Registry</span><span class="p">(</span><span class="s2">&quot;test&quot;</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="nd">@registry</span><span class="o">.</span><span class="n">register</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="o">...</span> <span class="k">class</span> <span class="nc">Module</span><span class="p">:</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="o">...</span>     <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="o">...</span>         <span class="bp">self</span><span class="o">.</span><span class="n">a</span> <span class="o">=</span> <span class="n">a</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="o">...</span>         <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">b</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">config</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;module&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;Module&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}}</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="o">&gt;&gt;&gt;</span> <span class="c1"># registry.register(Module)</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">module</span> <span class="o">=</span> <span class="n">registry</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;module&quot;</span><span class="p">])</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="o">&gt;&gt;&gt;</span> <span class="nb">type</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="o">&lt;</span><span class="k">class</span> <span class="err">&#39;</span><span class="nc">danling</span><span class="o">.</span><span class="n">registry</span><span class="o">.</span><span class="n">registry</span><span class="o">.</span><span class="n">Module</span><span class="s1">&#39;&gt;</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">module</span><span class="o">.</span><span class="n">a</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a><span class="mi">1</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">module</span><span class="o">.</span><span class="n">b</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a><span class="mi">2</span>
</code></pre></div></td></tr></table></div>

      <details class="quote">
        <summary>Source code in <code>danling/registry/registry.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span>
<span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-156" name="__codelineno-0-156"></a><span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a><span class="sd">    Build a component.</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a><span class="sd">    name: str</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a><span class="sd">        The name of the component.</span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a><span class="sd">    *args</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a><span class="sd">        The arguments to pass to the component.</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a><span class="sd">    **kwargs</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a><span class="sd">        The keyword arguments to pass to the component.</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a><span class="sd">    -------</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a><span class="sd">    component: Callable</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a><span class="sd">    Raises</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a><span class="sd">    ------</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a><span class="sd">    KeyError</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a><span class="sd">        If the component is not registered.</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a><span class="sd">    Examples</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a><span class="sd">    --------</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a><span class="sd">    &gt;&gt;&gt; registry = Registry(&quot;test&quot;)</span>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a><span class="sd">    &gt;&gt;&gt; @registry.register</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a><span class="sd">    ... class Module:</span>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a><span class="sd">    ...     def __init__(self, a, b):</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a><span class="sd">    ...         self.a = a</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a><span class="sd">    ...         self.b = b</span>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a><span class="sd">    &gt;&gt;&gt; config = {&quot;module&quot;: {&quot;name&quot;: &quot;Module&quot;, &quot;a&quot;: 1, &quot;b&quot;: 2}}</span>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a><span class="sd">    &gt;&gt;&gt; # registry.register(Module)</span>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a><span class="sd">    &gt;&gt;&gt; module = registry.build(config[&quot;module&quot;])</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a><span class="sd">    &gt;&gt;&gt; type(module)</span>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a><span class="sd">    &lt;class &#39;danling.registry.registry.Module&#39;&gt;</span>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a><span class="sd">    &gt;&gt;&gt; module.a</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a><span class="sd">    1</span>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a><span class="sd">    &gt;&gt;&gt; module.b</span>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a><span class="sd">    2</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a><span class="sd">    ```</span>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-199" name="__codelineno-0-199"></a>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a>    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">args</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">kwargs</span><span class="p">:</span>
<a id="__codelineno-0-201" name="__codelineno-0-201"></a>        <span class="n">name</span><span class="p">,</span> <span class="n">kwargs</span> <span class="o">=</span> <span class="n">name</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;name&quot;</span><span class="p">),</span> <span class="n">name</span>  <span class="c1"># type: ignore</span>
<a id="__codelineno-0-202" name="__codelineno-0-202"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">name</span><span class="p">)(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="danling.registry.registry.Registry.lookup" class="doc doc-heading">
<code class="highlight language-python"><span class="n">lookup</span><span class="p">(</span><span class="n">name</span><span class="p">)</span></code>

<a href="#danling.registry.registry.Registry.lookup" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Lookup for a component.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>name</code></td>
          <td>
                <code>str</code>
          </td>
          <td><p>The name of the component.</p></td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>value</code></td>          <td>
                <code><span title="typing.Any">Any</span></code>
          </td>
          <td></td>
        </tr>
    </tbody>
  </table>

  <p><strong>Raises:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>KeyError</code>
          </td>
          <td><p>If the component is not registered.</p></td>
        </tr>
    </tbody>
  </table>

<p><strong>Examples:</strong></p>
    <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1">1</a></span>
<span class="normal"><a href="#__codelineno-0-2">2</a></span>
<span class="normal"><a href="#__codelineno-0-3">3</a></span>
<span class="normal"><a href="#__codelineno-0-4">4</a></span>
<span class="normal"><a href="#__codelineno-0-5">5</a></span>
<span class="normal"><a href="#__codelineno-0-6">6</a></span>
<span class="normal"><a href="#__codelineno-0-7">7</a></span>
<span class="normal"><a href="#__codelineno-0-8">8</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">registry</span> <span class="o">=</span> <span class="n">Registry</span><span class="p">(</span><span class="s2">&quot;test&quot;</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="nd">@registry</span><span class="o">.</span><span class="n">register</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="o">...</span> <span class="k">class</span> <span class="nc">Module</span><span class="p">:</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="o">...</span>     <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="o">...</span>         <span class="bp">self</span><span class="o">.</span><span class="n">a</span> <span class="o">=</span> <span class="n">a</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="o">...</span>         <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">b</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">registry</span><span class="o">.</span><span class="n">lookup</span><span class="p">(</span><span class="s2">&quot;Module&quot;</span><span class="p">)</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="o">&lt;</span><span class="k">class</span> <span class="err">&#39;</span><span class="nc">danling</span><span class="o">.</span><span class="n">registry</span><span class="o">.</span><span class="n">registry</span><span class="o">.</span><span class="n">Module</span><span class="s1">&#39;&gt;</span>
</code></pre></div></td></tr></table></div>

      <details class="quote">
        <summary>Source code in <code>danling/registry/registry.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-121" name="__codelineno-0-121"></a><span class="k">def</span> <span class="nf">lookup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a><span class="sd">    Lookup for a component.</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a><span class="sd">    name: str</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a><span class="sd">        The name of the component.</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a><span class="sd">    -------</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a><span class="sd">    value: Any</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a><span class="sd">    Raises</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a><span class="sd">    ------</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a><span class="sd">    KeyError</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a><span class="sd">        If the component is not registered.</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a><span class="sd">    Examples</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a><span class="sd">    --------</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a><span class="sd">    &gt;&gt;&gt; registry = Registry(&quot;test&quot;)</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a><span class="sd">    &gt;&gt;&gt; @registry.register</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a><span class="sd">    ... class Module:</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a><span class="sd">    ...     def __init__(self, a, b):</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a><span class="sd">    ...         self.a = a</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a><span class="sd">    ...         self.b = b</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a><span class="sd">    &gt;&gt;&gt; registry.lookup(&quot;Module&quot;)</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a><span class="sd">    &lt;class &#39;danling.registry.registry.Module&#39;&gt;</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a><span class="sd">    ```</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="danling.registry.registry.Registry.register" class="doc doc-heading">
<code class="highlight language-python"><span class="n">register</span><span class="p">(</span><span class="n">component</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#danling.registry.registry.Registry.register" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Register a new component</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>component</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[<span title="typing.Callable">Callable</span>]</code>
          </td>
          <td><p>The component to register.</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>name</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[str]</code>
          </td>
          <td><p>The name of the component.</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>component</code></td>          <td>
                <code><span title="typing.Callable">Callable</span></code>
          </td>
          <td><p>The registered component.</p></td>
        </tr>
    </tbody>
  </table>

  <p><strong>Raises:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>ValueError</code>
          </td>
          <td><p>If the component with the same name already exists and <code>Registry.override=False</code>.</p></td>
        </tr>
    </tbody>
  </table>

<p><strong>Examples:</strong></p>
    <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-0-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-0-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-0-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-0-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-0-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-0-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-0-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-0-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-0-10">10</a></span>
<span class="normal"><a href="#__codelineno-0-11">11</a></span>
<span class="normal"><a href="#__codelineno-0-12">12</a></span>
<span class="normal"><a href="#__codelineno-0-13">13</a></span>
<span class="normal"><a href="#__codelineno-0-14">14</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">registry</span> <span class="o">=</span> <span class="n">Registry</span><span class="p">(</span><span class="s2">&quot;test&quot;</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="nd">@registry</span><span class="o">.</span><span class="n">register</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="o">...</span> <span class="nd">@registry</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;Module1&quot;</span><span class="p">)</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="o">...</span> <span class="k">class</span> <span class="nc">Module</span><span class="p">:</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="o">...</span>     <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="o">...</span>         <span class="bp">self</span><span class="o">.</span><span class="n">a</span> <span class="o">=</span> <span class="n">a</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="o">...</span>         <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">b</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">module</span> <span class="o">=</span> <span class="n">registry</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="n">Module</span><span class="p">,</span> <span class="s2">&quot;Module2&quot;</span><span class="p">)</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">registry</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="n">Registry</span><span class="p">(</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>  <span class="p">(</span><span class="n">Module1</span><span class="p">):</span> <span class="o">&lt;</span><span class="k">class</span> <span class="err">&#39;</span><span class="nc">danling</span><span class="o">.</span><span class="n">registry</span><span class="o">.</span><span class="n">registry</span><span class="o">.</span><span class="n">Module</span><span class="s1">&#39;&gt;</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>  <span class="p">(</span><span class="n">Module</span><span class="p">):</span> <span class="o">&lt;</span><span class="k">class</span> <span class="err">&#39;</span><span class="nc">danling</span><span class="o">.</span><span class="n">registry</span><span class="o">.</span><span class="n">registry</span><span class="o">.</span><span class="n">Module</span><span class="s1">&#39;&gt;</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>  <span class="p">(</span><span class="n">Module2</span><span class="p">):</span> <span class="o">&lt;</span><span class="k">class</span> <span class="err">&#39;</span><span class="nc">danling</span><span class="o">.</span><span class="n">registry</span><span class="o">.</span><span class="n">registry</span><span class="o">.</span><span class="n">Module</span><span class="s1">&#39;&gt;</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a><span class="p">)</span>
</code></pre></div></td></tr></table></div>

      <details class="quote">
        <summary>Source code in <code>danling/registry/registry.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-0-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-0-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-0-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-0-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-0-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-0-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-0-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-0-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-0-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-0-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-0-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-0-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-0-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-58" name="__codelineno-0-58"></a><span class="k">def</span> <span class="nf">register</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">component</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">:</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="sd">    Register a new component</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a><span class="sd">    component: Optional[Callable] = None</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a><span class="sd">        The component to register.</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a><span class="sd">    name: Optional[str] = component.__name__</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a><span class="sd">        The name of the component.</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a><span class="sd">    -------</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a><span class="sd">    component: Callable</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a><span class="sd">        The registered component.</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a><span class="sd">    Raises</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a><span class="sd">    ------</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a><span class="sd">    ValueError</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a><span class="sd">        If the component with the same name already exists and `Registry.override=False`.</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a><span class="sd">    Examples</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a><span class="sd">    --------</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a><span class="sd">    ```python</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a><span class="sd">    &gt;&gt;&gt; registry = Registry(&quot;test&quot;)</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a><span class="sd">    &gt;&gt;&gt; @registry.register</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a><span class="sd">    ... @registry.register(&quot;Module1&quot;)</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a><span class="sd">    ... class Module:</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a><span class="sd">    ...     def __init__(self, a, b):</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a><span class="sd">    ...         self.a = a</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a><span class="sd">    ...         self.b = b</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a><span class="sd">    &gt;&gt;&gt; module = registry.register(Module, &quot;Module2&quot;)</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a><span class="sd">    &gt;&gt;&gt; registry</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a><span class="sd">    Registry(</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a><span class="sd">      (Module1): &lt;class &#39;danling.registry.registry.Module&#39;&gt;</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a><span class="sd">      (Module): &lt;class &#39;danling.registry.registry.Module&#39;&gt;</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a><span class="sd">      (Module2): &lt;class &#39;danling.registry.registry.Module&#39;&gt;</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a><span class="sd">    )</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a><span class="sd">    ```</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">override</span><span class="p">:</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Component with name </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> already exists&quot;</span><span class="p">)</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>    <span class="c1"># Registry.register()</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>    <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">component</span><span class="p">)</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>    <span class="c1"># @Registry.register()</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>    <span class="nd">@wraps</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">register</span><span class="p">)</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>    <span class="k">def</span> <span class="nf">register</span><span class="p">(</span><span class="n">component</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>        <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>            <span class="n">name</span> <span class="o">=</span> <span class="n">component</span><span class="o">.</span><span class="vm">__name__</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">component</span><span class="p">)</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>        <span class="k">return</span> <span class="n">component</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>    <span class="c1"># @Registry.register</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>    <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="n">component</span><span class="p">)</span> <span class="ow">and</span> <span class="n">name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>        <span class="k">return</span> <span class="n">register</span><span class="p">(</span><span class="n">component</span><span class="p">)</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>    <span class="k">return</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">register</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">component</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="danling.SelfAttention" class="doc doc-heading">
        <code>SelfAttention</code>


<a href="#danling.SelfAttention" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
      <p class="doc doc-class-bases">
        Bases: <code><span title="torch.nn">nn</span>.<span title="torch.nn.Module">Module</span></code></p>

  
      <p>Allows the model to jointly attend to information
from different representation subspaces.
See <code>Attention Is All You Need &lt;https://arxiv.org/abs/1706.03762&gt;</code>_
.. math::
    \text{MultiHead}(Q, K, V) = \text{Concat}(head_1,\dots,head_h)W^O
where :math:<code>head_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)</code>.
Args:
    embed_dim: total dimension of the model.
    num_heads: parallel attention heads.
    dropout: a Dropout layer on attn_output_weights. Default: 0.0.
    bias: add bias as module parameter. Default: True.
    add_bias_kv: add bias to the key and value sequences at dim=0.
    add_zero_attn: add a new batch of zeros to the key and
                   value sequences at dim=1.
    k_dim: total number of features in key. Default: None.
    v_dim: total number of features in value. Default: None.
    batch_first: If <code>False</code>, then the input and output tensors are provided
        as (seq, batch, feature). Default: <code>True</code> (batch, seq, feature).
Note that if :attr:<code>k_dim</code> and :attr:<code>v_dim</code> are None, they will be set
to :attr:<code>embed_dim</code> such that query, key, and value have the same
number of features.
Examples::
    &gt;&gt;&gt; multihead_attn = dl.models.SelfAttention(embed_dim, num_heads)
    &gt;&gt;&gt; attn_output, attn_output_weights = multihead_attn(query, key, value)</p>


        <details class="quote">
          <summary>Source code in <code>danling/models/transformer/attention/self_attention.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-9">  9</a></span>
<span class="normal"><a href="#__codelineno-0-10"> 10</a></span>
<span class="normal"><a href="#__codelineno-0-11"> 11</a></span>
<span class="normal"><a href="#__codelineno-0-12"> 12</a></span>
<span class="normal"><a href="#__codelineno-0-13"> 13</a></span>
<span class="normal"><a href="#__codelineno-0-14"> 14</a></span>
<span class="normal"><a href="#__codelineno-0-15"> 15</a></span>
<span class="normal"><a href="#__codelineno-0-16"> 16</a></span>
<span class="normal"><a href="#__codelineno-0-17"> 17</a></span>
<span class="normal"><a href="#__codelineno-0-18"> 18</a></span>
<span class="normal"><a href="#__codelineno-0-19"> 19</a></span>
<span class="normal"><a href="#__codelineno-0-20"> 20</a></span>
<span class="normal"><a href="#__codelineno-0-21"> 21</a></span>
<span class="normal"><a href="#__codelineno-0-22"> 22</a></span>
<span class="normal"><a href="#__codelineno-0-23"> 23</a></span>
<span class="normal"><a href="#__codelineno-0-24"> 24</a></span>
<span class="normal"><a href="#__codelineno-0-25"> 25</a></span>
<span class="normal"><a href="#__codelineno-0-26"> 26</a></span>
<span class="normal"><a href="#__codelineno-0-27"> 27</a></span>
<span class="normal"><a href="#__codelineno-0-28"> 28</a></span>
<span class="normal"><a href="#__codelineno-0-29"> 29</a></span>
<span class="normal"><a href="#__codelineno-0-30"> 30</a></span>
<span class="normal"><a href="#__codelineno-0-31"> 31</a></span>
<span class="normal"><a href="#__codelineno-0-32"> 32</a></span>
<span class="normal"><a href="#__codelineno-0-33"> 33</a></span>
<span class="normal"><a href="#__codelineno-0-34"> 34</a></span>
<span class="normal"><a href="#__codelineno-0-35"> 35</a></span>
<span class="normal"><a href="#__codelineno-0-36"> 36</a></span>
<span class="normal"><a href="#__codelineno-0-37"> 37</a></span>
<span class="normal"><a href="#__codelineno-0-38"> 38</a></span>
<span class="normal"><a href="#__codelineno-0-39"> 39</a></span>
<span class="normal"><a href="#__codelineno-0-40"> 40</a></span>
<span class="normal"><a href="#__codelineno-0-41"> 41</a></span>
<span class="normal"><a href="#__codelineno-0-42"> 42</a></span>
<span class="normal"><a href="#__codelineno-0-43"> 43</a></span>
<span class="normal"><a href="#__codelineno-0-44"> 44</a></span>
<span class="normal"><a href="#__codelineno-0-45"> 45</a></span>
<span class="normal"><a href="#__codelineno-0-46"> 46</a></span>
<span class="normal"><a href="#__codelineno-0-47"> 47</a></span>
<span class="normal"><a href="#__codelineno-0-48"> 48</a></span>
<span class="normal"><a href="#__codelineno-0-49"> 49</a></span>
<span class="normal"><a href="#__codelineno-0-50"> 50</a></span>
<span class="normal"><a href="#__codelineno-0-51"> 51</a></span>
<span class="normal"><a href="#__codelineno-0-52"> 52</a></span>
<span class="normal"><a href="#__codelineno-0-53"> 53</a></span>
<span class="normal"><a href="#__codelineno-0-54"> 54</a></span>
<span class="normal"><a href="#__codelineno-0-55"> 55</a></span>
<span class="normal"><a href="#__codelineno-0-56"> 56</a></span>
<span class="normal"><a href="#__codelineno-0-57"> 57</a></span>
<span class="normal"><a href="#__codelineno-0-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-0-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-0-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-0-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-0-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-0-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-0-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-0-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-0-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-0-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-0-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-0-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-0-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-0-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span>
<span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span>
<span class="normal"><a href="#__codelineno-0-203">203</a></span>
<span class="normal"><a href="#__codelineno-0-204">204</a></span>
<span class="normal"><a href="#__codelineno-0-205">205</a></span>
<span class="normal"><a href="#__codelineno-0-206">206</a></span>
<span class="normal"><a href="#__codelineno-0-207">207</a></span>
<span class="normal"><a href="#__codelineno-0-208">208</a></span>
<span class="normal"><a href="#__codelineno-0-209">209</a></span>
<span class="normal"><a href="#__codelineno-0-210">210</a></span>
<span class="normal"><a href="#__codelineno-0-211">211</a></span>
<span class="normal"><a href="#__codelineno-0-212">212</a></span>
<span class="normal"><a href="#__codelineno-0-213">213</a></span>
<span class="normal"><a href="#__codelineno-0-214">214</a></span>
<span class="normal"><a href="#__codelineno-0-215">215</a></span>
<span class="normal"><a href="#__codelineno-0-216">216</a></span>
<span class="normal"><a href="#__codelineno-0-217">217</a></span>
<span class="normal"><a href="#__codelineno-0-218">218</a></span>
<span class="normal"><a href="#__codelineno-0-219">219</a></span>
<span class="normal"><a href="#__codelineno-0-220">220</a></span>
<span class="normal"><a href="#__codelineno-0-221">221</a></span>
<span class="normal"><a href="#__codelineno-0-222">222</a></span>
<span class="normal"><a href="#__codelineno-0-223">223</a></span>
<span class="normal"><a href="#__codelineno-0-224">224</a></span>
<span class="normal"><a href="#__codelineno-0-225">225</a></span>
<span class="normal"><a href="#__codelineno-0-226">226</a></span>
<span class="normal"><a href="#__codelineno-0-227">227</a></span>
<span class="normal"><a href="#__codelineno-0-228">228</a></span>
<span class="normal"><a href="#__codelineno-0-229">229</a></span>
<span class="normal"><a href="#__codelineno-0-230">230</a></span>
<span class="normal"><a href="#__codelineno-0-231">231</a></span>
<span class="normal"><a href="#__codelineno-0-232">232</a></span>
<span class="normal"><a href="#__codelineno-0-233">233</a></span>
<span class="normal"><a href="#__codelineno-0-234">234</a></span>
<span class="normal"><a href="#__codelineno-0-235">235</a></span>
<span class="normal"><a href="#__codelineno-0-236">236</a></span>
<span class="normal"><a href="#__codelineno-0-237">237</a></span>
<span class="normal"><a href="#__codelineno-0-238">238</a></span>
<span class="normal"><a href="#__codelineno-0-239">239</a></span>
<span class="normal"><a href="#__codelineno-0-240">240</a></span>
<span class="normal"><a href="#__codelineno-0-241">241</a></span>
<span class="normal"><a href="#__codelineno-0-242">242</a></span>
<span class="normal"><a href="#__codelineno-0-243">243</a></span>
<span class="normal"><a href="#__codelineno-0-244">244</a></span>
<span class="normal"><a href="#__codelineno-0-245">245</a></span>
<span class="normal"><a href="#__codelineno-0-246">246</a></span>
<span class="normal"><a href="#__codelineno-0-247">247</a></span>
<span class="normal"><a href="#__codelineno-0-248">248</a></span>
<span class="normal"><a href="#__codelineno-0-249">249</a></span>
<span class="normal"><a href="#__codelineno-0-250">250</a></span>
<span class="normal"><a href="#__codelineno-0-251">251</a></span>
<span class="normal"><a href="#__codelineno-0-252">252</a></span>
<span class="normal"><a href="#__codelineno-0-253">253</a></span>
<span class="normal"><a href="#__codelineno-0-254">254</a></span>
<span class="normal"><a href="#__codelineno-0-255">255</a></span>
<span class="normal"><a href="#__codelineno-0-256">256</a></span>
<span class="normal"><a href="#__codelineno-0-257">257</a></span>
<span class="normal"><a href="#__codelineno-0-258">258</a></span>
<span class="normal"><a href="#__codelineno-0-259">259</a></span>
<span class="normal"><a href="#__codelineno-0-260">260</a></span>
<span class="normal"><a href="#__codelineno-0-261">261</a></span>
<span class="normal"><a href="#__codelineno-0-262">262</a></span>
<span class="normal"><a href="#__codelineno-0-263">263</a></span>
<span class="normal"><a href="#__codelineno-0-264">264</a></span>
<span class="normal"><a href="#__codelineno-0-265">265</a></span>
<span class="normal"><a href="#__codelineno-0-266">266</a></span>
<span class="normal"><a href="#__codelineno-0-267">267</a></span>
<span class="normal"><a href="#__codelineno-0-268">268</a></span>
<span class="normal"><a href="#__codelineno-0-269">269</a></span>
<span class="normal"><a href="#__codelineno-0-270">270</a></span>
<span class="normal"><a href="#__codelineno-0-271">271</a></span>
<span class="normal"><a href="#__codelineno-0-272">272</a></span>
<span class="normal"><a href="#__codelineno-0-273">273</a></span>
<span class="normal"><a href="#__codelineno-0-274">274</a></span>
<span class="normal"><a href="#__codelineno-0-275">275</a></span>
<span class="normal"><a href="#__codelineno-0-276">276</a></span>
<span class="normal"><a href="#__codelineno-0-277">277</a></span>
<span class="normal"><a href="#__codelineno-0-278">278</a></span>
<span class="normal"><a href="#__codelineno-0-279">279</a></span>
<span class="normal"><a href="#__codelineno-0-280">280</a></span>
<span class="normal"><a href="#__codelineno-0-281">281</a></span>
<span class="normal"><a href="#__codelineno-0-282">282</a></span>
<span class="normal"><a href="#__codelineno-0-283">283</a></span>
<span class="normal"><a href="#__codelineno-0-284">284</a></span>
<span class="normal"><a href="#__codelineno-0-285">285</a></span>
<span class="normal"><a href="#__codelineno-0-286">286</a></span>
<span class="normal"><a href="#__codelineno-0-287">287</a></span>
<span class="normal"><a href="#__codelineno-0-288">288</a></span>
<span class="normal"><a href="#__codelineno-0-289">289</a></span>
<span class="normal"><a href="#__codelineno-0-290">290</a></span>
<span class="normal"><a href="#__codelineno-0-291">291</a></span>
<span class="normal"><a href="#__codelineno-0-292">292</a></span>
<span class="normal"><a href="#__codelineno-0-293">293</a></span>
<span class="normal"><a href="#__codelineno-0-294">294</a></span>
<span class="normal"><a href="#__codelineno-0-295">295</a></span>
<span class="normal"><a href="#__codelineno-0-296">296</a></span>
<span class="normal"><a href="#__codelineno-0-297">297</a></span>
<span class="normal"><a href="#__codelineno-0-298">298</a></span>
<span class="normal"><a href="#__codelineno-0-299">299</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="k">class</span> <span class="nc">SelfAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Allows the model to jointly attend to information</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">    from different representation subspaces.</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="sd">    See `Attention Is All You Need &lt;https://arxiv.org/abs/1706.03762&gt;`_</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a><span class="sd">    .. math::</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a><span class="sd">        \text{MultiHead}(Q, K, V) = \text{Concat}(head_1,\dots,head_h)W^O</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a><span class="sd">    where :math:`head_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)`.</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a><span class="sd">        embed_dim: total dimension of the model.</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a><span class="sd">        num_heads: parallel attention heads.</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a><span class="sd">        dropout: a Dropout layer on attn_output_weights. Default: 0.0.</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a><span class="sd">        bias: add bias as module parameter. Default: True.</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a><span class="sd">        add_bias_kv: add bias to the key and value sequences at dim=0.</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a><span class="sd">        add_zero_attn: add a new batch of zeros to the key and</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a><span class="sd">                       value sequences at dim=1.</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a><span class="sd">        k_dim: total number of features in key. Default: None.</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a><span class="sd">        v_dim: total number of features in value. Default: None.</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a><span class="sd">        batch_first: If ``False``, then the input and output tensors are provided</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a><span class="sd">            as (seq, batch, feature). Default: ``True`` (batch, seq, feature).</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a><span class="sd">    Note that if :attr:`k_dim` and :attr:`v_dim` are None, they will be set</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a><span class="sd">    to :attr:`embed_dim` such that query, key, and value have the same</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a><span class="sd">    number of features.</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="sd">    Examples::</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a><span class="sd">        &gt;&gt;&gt; multihead_attn = dl.models.SelfAttention(embed_dim, num_heads)</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a><span class="sd">        &gt;&gt;&gt; attn_output, attn_output_weights = multihead_attn(query, key, value)</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a>    <span class="n">__constants__</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;batch_first&quot;</span><span class="p">]</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>        <span class="n">embed_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a>        <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>        <span class="n">attn_dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a>        <span class="n">scale_factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a>        <span class="n">bias</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>        <span class="n">batch_first</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a>        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>        <span class="nb">super</span><span class="p">(</span><span class="n">SelfAttention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span> <span class="o">=</span> <span class="n">embed_dim</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">scale_factor</span> <span class="o">=</span> <span class="n">scale_factor</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">batch_first</span> <span class="o">=</span> <span class="n">batch_first</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">scaling</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_factor</span><span class="p">)</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">:</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;embed_dim </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="si">}</span><span class="s2"> not divisible by num_heads </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_dim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">attn_dropout</span><span class="p">)</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">out_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_reset_parameters</span><span class="p">()</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a>    <span class="k">def</span> <span class="nf">_reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a>        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>        <span class="n">query</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>        <span class="n">key</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>        <span class="n">value</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>        <span class="n">attn_bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>        <span class="n">attn_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>        <span class="n">key_padding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>        <span class="n">need_weights</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]]:</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a><span class="sd">            query, key, value: map a query and a set of key-value pairs to an output.</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a><span class="sd">                See &quot;Attention Is All You Need&quot; for more details.</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a><span class="sd">            attn_bias: 2D or 3D mask that add bias to attention output weights. Used for relative positional embedding.</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a><span class="sd">                A 2D bias will be broadcasted for all the batches while a 3D mask allows to specify a different mask for</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a><span class="sd">                the entries of each batch.</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a><span class="sd">            attn_mask: 2D or 3D mask that prevents attention to certain positions. A 2D mask will be broadcasted for all</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a><span class="sd">                the batches while a 3D mask allows to specify a different mask for the entries of each batch.</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a><span class="sd">            key_padding_mask: if provided, specified padding elements in the key will</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a><span class="sd">                be ignored by the attention. When given a binary mask and a value is True,</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a><span class="sd">                the corresponding value on the attention layer will be ignored. When given</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a><span class="sd">                a byte mask and a value is non-zero, the corresponding value on the attention</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a><span class="sd">                layer will be ignored</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a><span class="sd">            need_weights: output attn_output_weights.</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a><span class="sd">        Shapes for inputs:</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a><span class="sd">            - query: :math:`(L, N, E)` where L is the target sequence length, N is the batch size, E is</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a><span class="sd">                the embedding dimension. :math:`(N, L, E)` if ``batch_first`` is ``True``.</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a><span class="sd">            - key: :math:`(S, N, E)`, where S is the source sequence length, N is the batch size, E is</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a><span class="sd">                the embedding dimension. :math:`(N, S, E)` if ``batch_first`` is ``True``.</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a><span class="sd">            - value: :math:`(S, N, E)` where S is the source sequence length, N is the batch size, E is</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a><span class="sd">                the embedding dimension. :math:`(N, S, E)` if ``batch_first`` is ``True``.</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a><span class="sd">            - attn_bias: if a 2D mask: :math:`(L, S)` where L is the target sequence length, S is the</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a><span class="sd">                source sequence length.</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a><span class="sd">                If a 3D mask: :math:`(N\cdot\text{num\_heads}, L, S)` where N is the batch size, L is the target sequence</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a><span class="sd">                length, S is the source sequence length. ``attn_bias`` allows to pass pos embed directly into attention</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a><span class="sd">                If a ByteTensor is provided, the non-zero positions are not allowed to attend while the zero positions will</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a><span class="sd">                be unchanged. If a BoolTensor is provided, positions with ``True`` is not allowed to attend while ``False``</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a><span class="sd">                values will be unchanged. If a FloatTensor is provided, it will be added to the attention weight.</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a><span class="sd">            - attn_mask: if a 2D mask: :math:`(L, S)` where L is the target sequence length, S is the</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a><span class="sd">                source sequence length.</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a><span class="sd">                If a 3D mask: :math:`(N\cdot\text{num\_heads}, L, S)` where N is the batch size, L is the target sequence</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a><span class="sd">                length, S is the source sequence length. ``attn_mask`` ensure that position i is allowed to attend</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a><span class="sd">                the unmasked positions. If a ByteTensor is provided, the non-zero positions are not allowed to attend</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a><span class="sd">                while the zero positions will be unchanged. If a BoolTensor is provided, positions with ``True``</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a><span class="sd">                is not allowed to attend while ``False`` values will be unchanged. If a FloatTensor</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a><span class="sd">                is provided, it will be added to the attention weight.</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a><span class="sd">            - key_padding_mask: :math:`(N, S)` where N is the batch size, S is the source sequence length.</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a><span class="sd">                If a ByteTensor is provided, the non-zero positions will be ignored while the position</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a><span class="sd">                with the zero positions will be unchanged. If a BoolTensor is provided, the positions with the</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a><span class="sd">                value of ``True`` will be ignored while the position with the value of ``False`` will be unchanged.</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a><span class="sd">        Outputs:</span>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a><span class="sd">            - attn_output: :math:`(L, N, E)` where L is the target sequence length, N is the batch size,</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a><span class="sd">                E is the embedding dimension. :math:`(N, L, E)` if ``batch_first`` is ``True``.</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a><span class="sd">            - attn_output_weights: :math:`(N, L, S)` where N is the batch size,</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a><span class="sd">                L is the target sequence length, S is the source sequence length.</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_first</span><span class="p">:</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a>            <span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)]</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>        <span class="c1"># set up shape vars</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a>        <span class="n">target_len</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">embed_dim</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a>        <span class="n">source_len</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">key</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]:</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;key&#39;s sequence and batch dims </span><span class="si">{</span><span class="n">key</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="s2"> do not match value&#39;s </span><span class="si">{</span><span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>        <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_projection</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>        <span class="c1"># prep attention mask</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>        <span class="k">if</span> <span class="n">attn_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>            <span class="k">if</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">:</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>                    <span class="s2">&quot;attn_mask is of type uint8. This type is deprecated. Please use bool or float tensors instead.&quot;</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>                <span class="p">)</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>                <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a>            <span class="k">elif</span> <span class="ow">not</span> <span class="p">(</span><span class="n">attn_mask</span><span class="o">.</span><span class="n">is_floating_point</span><span class="p">()</span> <span class="ow">or</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">):</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;attn_mask should have type float or bool, but got </span><span class="si">{</span><span class="n">attn_mask</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a>            <span class="c1"># ensure attn_mask&#39;s dim is 3</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>            <span class="k">if</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>                <span class="n">correct_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">target_len</span><span class="p">,</span> <span class="n">source_len</span><span class="p">)</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a>                <span class="k">if</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">correct_shape</span><span class="p">:</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a>                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;attn_mask should have shape </span><span class="si">{</span><span class="n">correct_shape</span><span class="si">}</span><span class="s2">, but got </span><span class="si">{</span><span class="n">attn_mask</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a>                <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a>            <span class="k">elif</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a>                <span class="n">correct_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">target_len</span><span class="p">,</span> <span class="n">source_len</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a>                <span class="k">if</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">correct_shape</span><span class="p">:</span>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a>                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;attn_mask should have shape </span><span class="si">{</span><span class="n">correct_shape</span><span class="si">}</span><span class="s2">, but got </span><span class="si">{</span><span class="n">attn_mask</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;attn_mask should have dimension 2 or 3, bug got </span><span class="si">{</span><span class="n">attn_mask</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a>        <span class="c1"># prep key padding mask</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a>        <span class="k">if</span> <span class="n">key_padding_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">key_padding_mask</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">:</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a>            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a>                <span class="s2">&quot;key_padding_mask is of type uint8. This type is deprecated. Please use bool or float tensors instead.&quot;</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a>            <span class="p">)</span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a>            <span class="n">key_padding_mask</span> <span class="o">=</span> <span class="n">key_padding_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a>        <span class="c1"># reshape q, k, v for multihead attention and make em batch first</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a>        <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">target_len</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a>        <span class="n">k</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a>        <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a>        <span class="c1"># merge key padding and attention masks</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a>        <span class="k">if</span> <span class="n">key_padding_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a>            <span class="k">if</span> <span class="n">key_padding_mask</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">source_len</span><span class="p">):</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a>                    <span class="sa">f</span><span class="s2">&quot;key_padding_mask should have shape </span><span class="si">{</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">source_len</span><span class="p">)</span><span class="si">}</span><span class="s2">, but got </span><span class="si">{</span><span class="n">key_padding_mask</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a>                <span class="p">)</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a>            <span class="n">key_padding_mask</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a>                <span class="n">key_padding_mask</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">source_len</span><span class="p">)</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a>                <span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a>                <span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">source_len</span><span class="p">)</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a>            <span class="p">)</span>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a>            <span class="k">if</span> <span class="n">attn_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a>                <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">key_padding_mask</span>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a>            <span class="k">elif</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">:</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a>                <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">logical_or</span><span class="p">(</span><span class="n">key_padding_mask</span><span class="p">)</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a>                <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">key_padding_mask</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;-inf&quot;</span><span class="p">))</span>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>        <span class="c1"># convert mask to float</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a>        <span class="k">if</span> <span class="n">attn_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">:</span>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a>            <span class="n">new_attn_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">attn_mask</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a>            <span class="n">new_attn_mask</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">attn_mask</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;-inf&quot;</span><span class="p">))</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a>            <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">new_attn_mask</span>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a>        <span class="c1"># (deep breath) calculate attention and out projection</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a>        <span class="n">attn_output</span><span class="p">,</span> <span class="n">attn_output_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">attn_bias</span><span class="p">,</span> <span class="n">attn_mask</span><span class="p">)</span>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a>        <span class="n">attn_output</span> <span class="o">=</span> <span class="n">attn_output</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">target_len</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">)</span>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a>        <span class="n">attn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_projection</span><span class="p">(</span><span class="n">attn_output</span><span class="p">)</span>
<a id="__codelineno-0-199" name="__codelineno-0-199"></a>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a>        <span class="c1"># attn_output_weights is set to torch.empty(0, requires_grad=False) to avoid errors in DDP</span>
<a id="__codelineno-0-201" name="__codelineno-0-201"></a>        <span class="n">attn_output_weights</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-202" name="__codelineno-0-202"></a>            <span class="n">attn_output_weights</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">target_len</span><span class="p">,</span> <span class="n">source_len</span><span class="p">)</span>
<a id="__codelineno-0-203" name="__codelineno-0-203"></a>            <span class="k">if</span> <span class="n">need_weights</span>
<a id="__codelineno-0-204" name="__codelineno-0-204"></a>            <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-0-205" name="__codelineno-0-205"></a>        <span class="p">)</span>
<a id="__codelineno-0-206" name="__codelineno-0-206"></a>
<a id="__codelineno-0-207" name="__codelineno-0-207"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_first</span><span class="p">:</span>
<a id="__codelineno-0-208" name="__codelineno-0-208"></a>            <span class="k">return</span> <span class="n">attn_output</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">attn_output_weights</span>
<a id="__codelineno-0-209" name="__codelineno-0-209"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-210" name="__codelineno-0-210"></a>            <span class="k">return</span> <span class="n">attn_output</span><span class="p">,</span> <span class="n">attn_output_weights</span>
<a id="__codelineno-0-211" name="__codelineno-0-211"></a>
<a id="__codelineno-0-212" name="__codelineno-0-212"></a>    <span class="k">def</span> <span class="nf">in_projection</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">v</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-213" name="__codelineno-0-213"></a>        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-214" name="__codelineno-0-214"></a><span class="sd">        Performs the in-projection step of the attention operation, using packed weights.</span>
<a id="__codelineno-0-215" name="__codelineno-0-215"></a><span class="sd">        Output is a triple containing projection tensors for query, key and value.</span>
<a id="__codelineno-0-216" name="__codelineno-0-216"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-217" name="__codelineno-0-217"></a><span class="sd">            q, k, v: query, key and value tensors to be projected. For self-attention,</span>
<a id="__codelineno-0-218" name="__codelineno-0-218"></a><span class="sd">                these are typically the same tensor; for encoder-decoder attention,</span>
<a id="__codelineno-0-219" name="__codelineno-0-219"></a><span class="sd">                k and v are typically the same tensor. (We take advantage of these</span>
<a id="__codelineno-0-220" name="__codelineno-0-220"></a><span class="sd">                identities for performance if they are present.) Regardless, q, k and v</span>
<a id="__codelineno-0-221" name="__codelineno-0-221"></a><span class="sd">                must share a common embedding dimension; otherwise their shapes may vary.</span>
<a id="__codelineno-0-222" name="__codelineno-0-222"></a><span class="sd">        Shape:</span>
<a id="__codelineno-0-223" name="__codelineno-0-223"></a><span class="sd">            Inputs:</span>
<a id="__codelineno-0-224" name="__codelineno-0-224"></a><span class="sd">            - q: :math:`(..., E)` where E is the embedding dimension</span>
<a id="__codelineno-0-225" name="__codelineno-0-225"></a><span class="sd">            - k: :math:`(..., E)` where E is the embedding dimension</span>
<a id="__codelineno-0-226" name="__codelineno-0-226"></a><span class="sd">            - v: :math:`(..., E)` where E is the embedding dimension</span>
<a id="__codelineno-0-227" name="__codelineno-0-227"></a><span class="sd">            Output:</span>
<a id="__codelineno-0-228" name="__codelineno-0-228"></a><span class="sd">            - in output list :math:`[q&#39;, k&#39;, v&#39;]`, each output tensor will have the</span>
<a id="__codelineno-0-229" name="__codelineno-0-229"></a><span class="sd">                same shape as the corresponding input tensor.</span>
<a id="__codelineno-0-230" name="__codelineno-0-230"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-231" name="__codelineno-0-231"></a>        <span class="k">if</span> <span class="n">k</span> <span class="ow">is</span> <span class="n">v</span><span class="p">:</span>
<a id="__codelineno-0-232" name="__codelineno-0-232"></a>            <span class="c1"># self-attention</span>
<a id="__codelineno-0-233" name="__codelineno-0-233"></a>            <span class="k">if</span> <span class="n">q</span> <span class="ow">is</span> <span class="n">k</span><span class="p">:</span>
<a id="__codelineno-0-234" name="__codelineno-0-234"></a>                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="p">(</span><span class="n">q</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_dim</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-235" name="__codelineno-0-235"></a>            <span class="c1"># encoder-decoder attention</span>
<a id="__codelineno-0-236" name="__codelineno-0-236"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-237" name="__codelineno-0-237"></a>                <span class="n">w_q</span><span class="p">,</span> <span class="n">w_kv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">split</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_dim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_dim</span><span class="p">])</span>
<a id="__codelineno-0-238" name="__codelineno-0-238"></a>                <span class="n">b_q</span><span class="p">,</span> <span class="n">b_kv</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-239" name="__codelineno-0-239"></a>                    <span class="kc">None</span>
<a id="__codelineno-0-240" name="__codelineno-0-240"></a>                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="kc">None</span>
<a id="__codelineno-0-241" name="__codelineno-0-241"></a>                    <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">split</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_dim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_dim</span><span class="p">])</span>
<a id="__codelineno-0-242" name="__codelineno-0-242"></a>                <span class="p">)</span>
<a id="__codelineno-0-243" name="__codelineno-0-243"></a>                <span class="k">return</span> <span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">w_q</span><span class="p">,</span> <span class="n">b_q</span><span class="p">),)</span> <span class="o">+</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">w_kv</span><span class="p">,</span> <span class="n">b_kv</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">k_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_dim</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-244" name="__codelineno-0-244"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-245" name="__codelineno-0-245"></a>            <span class="n">w_q</span><span class="p">,</span> <span class="n">w_k</span><span class="p">,</span> <span class="n">w_v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">split</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_dim</span><span class="p">])</span>
<a id="__codelineno-0-246" name="__codelineno-0-246"></a>            <span class="n">b_q</span><span class="p">,</span> <span class="n">b_k</span><span class="p">,</span> <span class="n">b_v</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-247" name="__codelineno-0-247"></a>                <span class="kc">None</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">split</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_dim</span><span class="p">])</span>
<a id="__codelineno-0-248" name="__codelineno-0-248"></a>            <span class="p">)</span>
<a id="__codelineno-0-249" name="__codelineno-0-249"></a>            <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">w_q</span><span class="p">,</span> <span class="n">b_q</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">w_k</span><span class="p">,</span> <span class="n">b_k</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">w_v</span><span class="p">,</span> <span class="n">b_v</span><span class="p">)</span>
<a id="__codelineno-0-250" name="__codelineno-0-250"></a>
<a id="__codelineno-0-251" name="__codelineno-0-251"></a>    <span class="k">def</span> <span class="nf">attention</span><span class="p">(</span>
<a id="__codelineno-0-252" name="__codelineno-0-252"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-253" name="__codelineno-0-253"></a>        <span class="n">q</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-254" name="__codelineno-0-254"></a>        <span class="n">k</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-255" name="__codelineno-0-255"></a>        <span class="n">v</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-256" name="__codelineno-0-256"></a>        <span class="n">attn_bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-257" name="__codelineno-0-257"></a>        <span class="n">attn_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-258" name="__codelineno-0-258"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-259" name="__codelineno-0-259"></a>        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-260" name="__codelineno-0-260"></a><span class="sd">        Computes scaled dot product attention on query, key and value tensors, using</span>
<a id="__codelineno-0-261" name="__codelineno-0-261"></a><span class="sd">        an optional attention mask if passed, and applying dropout if a probability</span>
<a id="__codelineno-0-262" name="__codelineno-0-262"></a><span class="sd">        greater than 0.0 is specified.</span>
<a id="__codelineno-0-263" name="__codelineno-0-263"></a><span class="sd">        Returns a tensor pair containing attended values and attention weights.</span>
<a id="__codelineno-0-264" name="__codelineno-0-264"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-265" name="__codelineno-0-265"></a><span class="sd">            q, k, v: query, key and value tensors. See Shape section for shape details.</span>
<a id="__codelineno-0-266" name="__codelineno-0-266"></a><span class="sd">            attn_mask: optional tensor containing mask values to be added to calculated</span>
<a id="__codelineno-0-267" name="__codelineno-0-267"></a><span class="sd">                attention. May be 2D or 3D; see Shape section for details.</span>
<a id="__codelineno-0-268" name="__codelineno-0-268"></a><span class="sd">            attn_bias: optional tensor containing bias values to be added to calculated</span>
<a id="__codelineno-0-269" name="__codelineno-0-269"></a><span class="sd">                attention. Used for relative positional embedding. May be 2D or 3D; see</span>
<a id="__codelineno-0-270" name="__codelineno-0-270"></a><span class="sd">                Shape section for details.</span>
<a id="__codelineno-0-271" name="__codelineno-0-271"></a><span class="sd">        Shape:</span>
<a id="__codelineno-0-272" name="__codelineno-0-272"></a><span class="sd">            - q: :math:`(B, Nt, E)` where B is batch size, Nt is the target sequence length,</span>
<a id="__codelineno-0-273" name="__codelineno-0-273"></a><span class="sd">                and E is embedding dimension.</span>
<a id="__codelineno-0-274" name="__codelineno-0-274"></a><span class="sd">            - key: :math:`(B, Ns, E)` where B is batch size, Ns is the source sequence length,</span>
<a id="__codelineno-0-275" name="__codelineno-0-275"></a><span class="sd">                and E is embedding dimension.</span>
<a id="__codelineno-0-276" name="__codelineno-0-276"></a><span class="sd">            - value: :math:`(B, Ns, E)` where B is batch size, Ns is the source sequence length,</span>
<a id="__codelineno-0-277" name="__codelineno-0-277"></a><span class="sd">                and E is embedding dimension.</span>
<a id="__codelineno-0-278" name="__codelineno-0-278"></a><span class="sd">            - attn_bias: either a 3D tensor of shape :math:`(B, Nt, Ns)` or a 2D tensor of</span>
<a id="__codelineno-0-279" name="__codelineno-0-279"></a><span class="sd">                shape :math:`(Nt, Ns)`.</span>
<a id="__codelineno-0-280" name="__codelineno-0-280"></a><span class="sd">            - attn_mask: either a 3D tensor of shape :math:`(B, Nt, Ns)` or a 2D tensor of</span>
<a id="__codelineno-0-281" name="__codelineno-0-281"></a><span class="sd">                shape :math:`(Nt, Ns)`.</span>
<a id="__codelineno-0-282" name="__codelineno-0-282"></a><span class="sd">            - Output: attention values have shape :math:`(B, Nt, E)`; attention weights</span>
<a id="__codelineno-0-283" name="__codelineno-0-283"></a><span class="sd">                have shape :math:`(B, Nt, Ns)`</span>
<a id="__codelineno-0-284" name="__codelineno-0-284"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-285" name="__codelineno-0-285"></a>        <span class="n">q</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaling</span>
<a id="__codelineno-0-286" name="__codelineno-0-286"></a>        <span class="c1"># (B, Nt, E) x (B, E, Ns) -&gt; (B, Nt, Ns)</span>
<a id="__codelineno-0-287" name="__codelineno-0-287"></a>        <span class="n">attn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<a id="__codelineno-0-288" name="__codelineno-0-288"></a>        <span class="k">if</span> <span class="n">attn_bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-289" name="__codelineno-0-289"></a>            <span class="n">attn</span> <span class="o">+=</span> <span class="n">attn_bias</span>
<a id="__codelineno-0-290" name="__codelineno-0-290"></a>        <span class="k">if</span> <span class="n">attn_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-291" name="__codelineno-0-291"></a>            <span class="n">attn</span> <span class="o">+=</span> <span class="n">attn_mask</span>
<a id="__codelineno-0-292" name="__codelineno-0-292"></a>        <span class="n">attn</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attn</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-293" name="__codelineno-0-293"></a>        <span class="n">attn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">attn</span><span class="p">)</span>
<a id="__codelineno-0-294" name="__codelineno-0-294"></a>        <span class="c1"># (B, Nt, Ns) x (B, Ns, E) -&gt; (B, Nt, E)</span>
<a id="__codelineno-0-295" name="__codelineno-0-295"></a>        <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">attn</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
<a id="__codelineno-0-296" name="__codelineno-0-296"></a>        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">attn</span>
<a id="__codelineno-0-297" name="__codelineno-0-297"></a>
<a id="__codelineno-0-298" name="__codelineno-0-298"></a>    <span class="k">def</span> <span class="nf">out_projection</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attn_output</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-299" name="__codelineno-0-299"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_proj</span><span class="p">(</span><span class="n">attn_output</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h3 id="danling.models.transformer.attention.self_attention.SelfAttention.attention" class="doc doc-heading">
<code class="highlight language-python"><span class="n">attention</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">attn_bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attn_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#danling.models.transformer.attention.self_attention.SelfAttention.attention" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Computes scaled dot product attention on query, key and value tensors, using
an optional attention mask if passed, and applying dropout if a probability
greater than 0.0 is specified.
Returns a tensor pair containing attended values and attention weights.
Args:
    q, k, v: query, key and value tensors. See Shape section for shape details.
    attn_mask: optional tensor containing mask values to be added to calculated
        attention. May be 2D or 3D; see Shape section for details.
    attn_bias: optional tensor containing bias values to be added to calculated
        attention. Used for relative positional embedding. May be 2D or 3D; see
        Shape section for details.
Shape:
    - q: :math:<code>(B, Nt, E)</code> where B is batch size, Nt is the target sequence length,
        and E is embedding dimension.
    - key: :math:<code>(B, Ns, E)</code> where B is batch size, Ns is the source sequence length,
        and E is embedding dimension.
    - value: :math:<code>(B, Ns, E)</code> where B is batch size, Ns is the source sequence length,
        and E is embedding dimension.
    - attn_bias: either a 3D tensor of shape :math:<code>(B, Nt, Ns)</code> or a 2D tensor of
        shape :math:<code>(Nt, Ns)</code>.
    - attn_mask: either a 3D tensor of shape :math:<code>(B, Nt, Ns)</code> or a 2D tensor of
        shape :math:<code>(Nt, Ns)</code>.
    - Output: attention values have shape :math:<code>(B, Nt, E)</code>; attention weights
        have shape :math:<code>(B, Nt, Ns)</code></p>

      <details class="quote">
        <summary>Source code in <code>danling/models/transformer/attention/self_attention.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-251">251</a></span>
<span class="normal"><a href="#__codelineno-0-252">252</a></span>
<span class="normal"><a href="#__codelineno-0-253">253</a></span>
<span class="normal"><a href="#__codelineno-0-254">254</a></span>
<span class="normal"><a href="#__codelineno-0-255">255</a></span>
<span class="normal"><a href="#__codelineno-0-256">256</a></span>
<span class="normal"><a href="#__codelineno-0-257">257</a></span>
<span class="normal"><a href="#__codelineno-0-258">258</a></span>
<span class="normal"><a href="#__codelineno-0-259">259</a></span>
<span class="normal"><a href="#__codelineno-0-260">260</a></span>
<span class="normal"><a href="#__codelineno-0-261">261</a></span>
<span class="normal"><a href="#__codelineno-0-262">262</a></span>
<span class="normal"><a href="#__codelineno-0-263">263</a></span>
<span class="normal"><a href="#__codelineno-0-264">264</a></span>
<span class="normal"><a href="#__codelineno-0-265">265</a></span>
<span class="normal"><a href="#__codelineno-0-266">266</a></span>
<span class="normal"><a href="#__codelineno-0-267">267</a></span>
<span class="normal"><a href="#__codelineno-0-268">268</a></span>
<span class="normal"><a href="#__codelineno-0-269">269</a></span>
<span class="normal"><a href="#__codelineno-0-270">270</a></span>
<span class="normal"><a href="#__codelineno-0-271">271</a></span>
<span class="normal"><a href="#__codelineno-0-272">272</a></span>
<span class="normal"><a href="#__codelineno-0-273">273</a></span>
<span class="normal"><a href="#__codelineno-0-274">274</a></span>
<span class="normal"><a href="#__codelineno-0-275">275</a></span>
<span class="normal"><a href="#__codelineno-0-276">276</a></span>
<span class="normal"><a href="#__codelineno-0-277">277</a></span>
<span class="normal"><a href="#__codelineno-0-278">278</a></span>
<span class="normal"><a href="#__codelineno-0-279">279</a></span>
<span class="normal"><a href="#__codelineno-0-280">280</a></span>
<span class="normal"><a href="#__codelineno-0-281">281</a></span>
<span class="normal"><a href="#__codelineno-0-282">282</a></span>
<span class="normal"><a href="#__codelineno-0-283">283</a></span>
<span class="normal"><a href="#__codelineno-0-284">284</a></span>
<span class="normal"><a href="#__codelineno-0-285">285</a></span>
<span class="normal"><a href="#__codelineno-0-286">286</a></span>
<span class="normal"><a href="#__codelineno-0-287">287</a></span>
<span class="normal"><a href="#__codelineno-0-288">288</a></span>
<span class="normal"><a href="#__codelineno-0-289">289</a></span>
<span class="normal"><a href="#__codelineno-0-290">290</a></span>
<span class="normal"><a href="#__codelineno-0-291">291</a></span>
<span class="normal"><a href="#__codelineno-0-292">292</a></span>
<span class="normal"><a href="#__codelineno-0-293">293</a></span>
<span class="normal"><a href="#__codelineno-0-294">294</a></span>
<span class="normal"><a href="#__codelineno-0-295">295</a></span>
<span class="normal"><a href="#__codelineno-0-296">296</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-251" name="__codelineno-0-251"></a><span class="k">def</span> <span class="nf">attention</span><span class="p">(</span>
<a id="__codelineno-0-252" name="__codelineno-0-252"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-253" name="__codelineno-0-253"></a>    <span class="n">q</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-254" name="__codelineno-0-254"></a>    <span class="n">k</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-255" name="__codelineno-0-255"></a>    <span class="n">v</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-256" name="__codelineno-0-256"></a>    <span class="n">attn_bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-257" name="__codelineno-0-257"></a>    <span class="n">attn_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-258" name="__codelineno-0-258"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-259" name="__codelineno-0-259"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-260" name="__codelineno-0-260"></a><span class="sd">    Computes scaled dot product attention on query, key and value tensors, using</span>
<a id="__codelineno-0-261" name="__codelineno-0-261"></a><span class="sd">    an optional attention mask if passed, and applying dropout if a probability</span>
<a id="__codelineno-0-262" name="__codelineno-0-262"></a><span class="sd">    greater than 0.0 is specified.</span>
<a id="__codelineno-0-263" name="__codelineno-0-263"></a><span class="sd">    Returns a tensor pair containing attended values and attention weights.</span>
<a id="__codelineno-0-264" name="__codelineno-0-264"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-265" name="__codelineno-0-265"></a><span class="sd">        q, k, v: query, key and value tensors. See Shape section for shape details.</span>
<a id="__codelineno-0-266" name="__codelineno-0-266"></a><span class="sd">        attn_mask: optional tensor containing mask values to be added to calculated</span>
<a id="__codelineno-0-267" name="__codelineno-0-267"></a><span class="sd">            attention. May be 2D or 3D; see Shape section for details.</span>
<a id="__codelineno-0-268" name="__codelineno-0-268"></a><span class="sd">        attn_bias: optional tensor containing bias values to be added to calculated</span>
<a id="__codelineno-0-269" name="__codelineno-0-269"></a><span class="sd">            attention. Used for relative positional embedding. May be 2D or 3D; see</span>
<a id="__codelineno-0-270" name="__codelineno-0-270"></a><span class="sd">            Shape section for details.</span>
<a id="__codelineno-0-271" name="__codelineno-0-271"></a><span class="sd">    Shape:</span>
<a id="__codelineno-0-272" name="__codelineno-0-272"></a><span class="sd">        - q: :math:`(B, Nt, E)` where B is batch size, Nt is the target sequence length,</span>
<a id="__codelineno-0-273" name="__codelineno-0-273"></a><span class="sd">            and E is embedding dimension.</span>
<a id="__codelineno-0-274" name="__codelineno-0-274"></a><span class="sd">        - key: :math:`(B, Ns, E)` where B is batch size, Ns is the source sequence length,</span>
<a id="__codelineno-0-275" name="__codelineno-0-275"></a><span class="sd">            and E is embedding dimension.</span>
<a id="__codelineno-0-276" name="__codelineno-0-276"></a><span class="sd">        - value: :math:`(B, Ns, E)` where B is batch size, Ns is the source sequence length,</span>
<a id="__codelineno-0-277" name="__codelineno-0-277"></a><span class="sd">            and E is embedding dimension.</span>
<a id="__codelineno-0-278" name="__codelineno-0-278"></a><span class="sd">        - attn_bias: either a 3D tensor of shape :math:`(B, Nt, Ns)` or a 2D tensor of</span>
<a id="__codelineno-0-279" name="__codelineno-0-279"></a><span class="sd">            shape :math:`(Nt, Ns)`.</span>
<a id="__codelineno-0-280" name="__codelineno-0-280"></a><span class="sd">        - attn_mask: either a 3D tensor of shape :math:`(B, Nt, Ns)` or a 2D tensor of</span>
<a id="__codelineno-0-281" name="__codelineno-0-281"></a><span class="sd">            shape :math:`(Nt, Ns)`.</span>
<a id="__codelineno-0-282" name="__codelineno-0-282"></a><span class="sd">        - Output: attention values have shape :math:`(B, Nt, E)`; attention weights</span>
<a id="__codelineno-0-283" name="__codelineno-0-283"></a><span class="sd">            have shape :math:`(B, Nt, Ns)`</span>
<a id="__codelineno-0-284" name="__codelineno-0-284"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-285" name="__codelineno-0-285"></a>    <span class="n">q</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaling</span>
<a id="__codelineno-0-286" name="__codelineno-0-286"></a>    <span class="c1"># (B, Nt, E) x (B, E, Ns) -&gt; (B, Nt, Ns)</span>
<a id="__codelineno-0-287" name="__codelineno-0-287"></a>    <span class="n">attn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<a id="__codelineno-0-288" name="__codelineno-0-288"></a>    <span class="k">if</span> <span class="n">attn_bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-289" name="__codelineno-0-289"></a>        <span class="n">attn</span> <span class="o">+=</span> <span class="n">attn_bias</span>
<a id="__codelineno-0-290" name="__codelineno-0-290"></a>    <span class="k">if</span> <span class="n">attn_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-291" name="__codelineno-0-291"></a>        <span class="n">attn</span> <span class="o">+=</span> <span class="n">attn_mask</span>
<a id="__codelineno-0-292" name="__codelineno-0-292"></a>    <span class="n">attn</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attn</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-293" name="__codelineno-0-293"></a>    <span class="n">attn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">attn</span><span class="p">)</span>
<a id="__codelineno-0-294" name="__codelineno-0-294"></a>    <span class="c1"># (B, Nt, Ns) x (B, Ns, E) -&gt; (B, Nt, E)</span>
<a id="__codelineno-0-295" name="__codelineno-0-295"></a>    <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">attn</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
<a id="__codelineno-0-296" name="__codelineno-0-296"></a>    <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">attn</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="danling.models.transformer.attention.self_attention.SelfAttention.forward" class="doc doc-heading">
<code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">attn_bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attn_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">key_padding_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">need_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#danling.models.transformer.attention.self_attention.SelfAttention.forward" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Shapes for inputs:
    - query: :math:<code>(L, N, E)</code> where L is the target sequence length, N is the batch size, E is
        the embedding dimension. :math:<code>(N, L, E)</code> if <code>batch_first</code> is <code>True</code>.
    - key: :math:<code>(S, N, E)</code>, where S is the source sequence length, N is the batch size, E is
        the embedding dimension. :math:<code>(N, S, E)</code> if <code>batch_first</code> is <code>True</code>.
    - value: :math:<code>(S, N, E)</code> where S is the source sequence length, N is the batch size, E is
        the embedding dimension. :math:<code>(N, S, E)</code> if <code>batch_first</code> is <code>True</code>.
    - attn_bias: if a 2D mask: :math:<code>(L, S)</code> where L is the target sequence length, S is the
        source sequence length.
        If a 3D mask: :math:<code>(N\cdot\text{num\_heads}, L, S)</code> where N is the batch size, L is the target sequence
        length, S is the source sequence length. <code>attn_bias</code> allows to pass pos embed directly into attention
        If a ByteTensor is provided, the non-zero positions are not allowed to attend while the zero positions will
        be unchanged. If a BoolTensor is provided, positions with <code>True</code> is not allowed to attend while <code>False</code>
        values will be unchanged. If a FloatTensor is provided, it will be added to the attention weight.
    - attn_mask: if a 2D mask: :math:<code>(L, S)</code> where L is the target sequence length, S is the
        source sequence length.
        If a 3D mask: :math:<code>(N\cdot\text{num\_heads}, L, S)</code> where N is the batch size, L is the target sequence
        length, S is the source sequence length. <code>attn_mask</code> ensure that position i is allowed to attend
        the unmasked positions. If a ByteTensor is provided, the non-zero positions are not allowed to attend
        while the zero positions will be unchanged. If a BoolTensor is provided, positions with <code>True</code>
        is not allowed to attend while <code>False</code> values will be unchanged. If a FloatTensor
        is provided, it will be added to the attention weight.
    - key_padding_mask: :math:<code>(N, S)</code> where N is the batch size, S is the source sequence length.
        If a ByteTensor is provided, the non-zero positions will be ignored while the position
        with the zero positions will be unchanged. If a BoolTensor is provided, the positions with the
        value of <code>True</code> will be ignored while the position with the value of <code>False</code> will be unchanged.
Outputs:
    - attn_output: :math:<code>(L, N, E)</code> where L is the target sequence length, N is the batch size,
        E is the embedding dimension. :math:<code>(N, L, E)</code> if <code>batch_first</code> is <code>True</code>.
    - attn_output_weights: :math:<code>(N, L, S)</code> where N is the batch size,
        L is the target sequence length, S is the source sequence length.</p>

      <details class="quote">
        <summary>Source code in <code>danling/models/transformer/attention/self_attention.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-0-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-0-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span>
<span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span>
<span class="normal"><a href="#__codelineno-0-203">203</a></span>
<span class="normal"><a href="#__codelineno-0-204">204</a></span>
<span class="normal"><a href="#__codelineno-0-205">205</a></span>
<span class="normal"><a href="#__codelineno-0-206">206</a></span>
<span class="normal"><a href="#__codelineno-0-207">207</a></span>
<span class="normal"><a href="#__codelineno-0-208">208</a></span>
<span class="normal"><a href="#__codelineno-0-209">209</a></span>
<span class="normal"><a href="#__codelineno-0-210">210</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-69" name="__codelineno-0-69"></a><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>    <span class="n">query</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>    <span class="n">key</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>    <span class="n">value</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>    <span class="n">attn_bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>    <span class="n">attn_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>    <span class="n">key_padding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>    <span class="n">need_weights</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]]:</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a><span class="sd">        query, key, value: map a query and a set of key-value pairs to an output.</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a><span class="sd">            See &quot;Attention Is All You Need&quot; for more details.</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a><span class="sd">        attn_bias: 2D or 3D mask that add bias to attention output weights. Used for relative positional embedding.</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a><span class="sd">            A 2D bias will be broadcasted for all the batches while a 3D mask allows to specify a different mask for</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a><span class="sd">            the entries of each batch.</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a><span class="sd">        attn_mask: 2D or 3D mask that prevents attention to certain positions. A 2D mask will be broadcasted for all</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a><span class="sd">            the batches while a 3D mask allows to specify a different mask for the entries of each batch.</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a><span class="sd">        key_padding_mask: if provided, specified padding elements in the key will</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a><span class="sd">            be ignored by the attention. When given a binary mask and a value is True,</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a><span class="sd">            the corresponding value on the attention layer will be ignored. When given</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a><span class="sd">            a byte mask and a value is non-zero, the corresponding value on the attention</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a><span class="sd">            layer will be ignored</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a><span class="sd">        need_weights: output attn_output_weights.</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a><span class="sd">    Shapes for inputs:</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a><span class="sd">        - query: :math:`(L, N, E)` where L is the target sequence length, N is the batch size, E is</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a><span class="sd">            the embedding dimension. :math:`(N, L, E)` if ``batch_first`` is ``True``.</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a><span class="sd">        - key: :math:`(S, N, E)`, where S is the source sequence length, N is the batch size, E is</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a><span class="sd">            the embedding dimension. :math:`(N, S, E)` if ``batch_first`` is ``True``.</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a><span class="sd">        - value: :math:`(S, N, E)` where S is the source sequence length, N is the batch size, E is</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a><span class="sd">            the embedding dimension. :math:`(N, S, E)` if ``batch_first`` is ``True``.</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a><span class="sd">        - attn_bias: if a 2D mask: :math:`(L, S)` where L is the target sequence length, S is the</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a><span class="sd">            source sequence length.</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a><span class="sd">            If a 3D mask: :math:`(N\cdot\text{num\_heads}, L, S)` where N is the batch size, L is the target sequence</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a><span class="sd">            length, S is the source sequence length. ``attn_bias`` allows to pass pos embed directly into attention</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a><span class="sd">            If a ByteTensor is provided, the non-zero positions are not allowed to attend while the zero positions will</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a><span class="sd">            be unchanged. If a BoolTensor is provided, positions with ``True`` is not allowed to attend while ``False``</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a><span class="sd">            values will be unchanged. If a FloatTensor is provided, it will be added to the attention weight.</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a><span class="sd">        - attn_mask: if a 2D mask: :math:`(L, S)` where L is the target sequence length, S is the</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a><span class="sd">            source sequence length.</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a><span class="sd">            If a 3D mask: :math:`(N\cdot\text{num\_heads}, L, S)` where N is the batch size, L is the target sequence</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a><span class="sd">            length, S is the source sequence length. ``attn_mask`` ensure that position i is allowed to attend</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a><span class="sd">            the unmasked positions. If a ByteTensor is provided, the non-zero positions are not allowed to attend</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a><span class="sd">            while the zero positions will be unchanged. If a BoolTensor is provided, positions with ``True``</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a><span class="sd">            is not allowed to attend while ``False`` values will be unchanged. If a FloatTensor</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a><span class="sd">            is provided, it will be added to the attention weight.</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a><span class="sd">        - key_padding_mask: :math:`(N, S)` where N is the batch size, S is the source sequence length.</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a><span class="sd">            If a ByteTensor is provided, the non-zero positions will be ignored while the position</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a><span class="sd">            with the zero positions will be unchanged. If a BoolTensor is provided, the positions with the</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a><span class="sd">            value of ``True`` will be ignored while the position with the value of ``False`` will be unchanged.</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a><span class="sd">    Outputs:</span>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a><span class="sd">        - attn_output: :math:`(L, N, E)` where L is the target sequence length, N is the batch size,</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a><span class="sd">            E is the embedding dimension. :math:`(N, L, E)` if ``batch_first`` is ``True``.</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a><span class="sd">        - attn_output_weights: :math:`(N, L, S)` where N is the batch size,</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a><span class="sd">            L is the target sequence length, S is the source sequence length.</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_first</span><span class="p">:</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a>        <span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)]</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>    <span class="c1"># set up shape vars</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a>    <span class="n">target_len</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">embed_dim</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a>    <span class="n">source_len</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">key</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]:</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;key&#39;s sequence and batch dims </span><span class="si">{</span><span class="n">key</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="s2"> do not match value&#39;s </span><span class="si">{</span><span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>    <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_projection</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>    <span class="c1"># prep attention mask</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>    <span class="k">if</span> <span class="n">attn_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>        <span class="k">if</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">:</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>                <span class="s2">&quot;attn_mask is of type uint8. This type is deprecated. Please use bool or float tensors instead.&quot;</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>            <span class="p">)</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>            <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a>        <span class="k">elif</span> <span class="ow">not</span> <span class="p">(</span><span class="n">attn_mask</span><span class="o">.</span><span class="n">is_floating_point</span><span class="p">()</span> <span class="ow">or</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">):</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;attn_mask should have type float or bool, but got </span><span class="si">{</span><span class="n">attn_mask</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a>        <span class="c1"># ensure attn_mask&#39;s dim is 3</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>        <span class="k">if</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>            <span class="n">correct_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">target_len</span><span class="p">,</span> <span class="n">source_len</span><span class="p">)</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a>            <span class="k">if</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">correct_shape</span><span class="p">:</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;attn_mask should have shape </span><span class="si">{</span><span class="n">correct_shape</span><span class="si">}</span><span class="s2">, but got </span><span class="si">{</span><span class="n">attn_mask</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a>            <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a>        <span class="k">elif</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a>            <span class="n">correct_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">target_len</span><span class="p">,</span> <span class="n">source_len</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a>            <span class="k">if</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">correct_shape</span><span class="p">:</span>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;attn_mask should have shape </span><span class="si">{</span><span class="n">correct_shape</span><span class="si">}</span><span class="s2">, but got </span><span class="si">{</span><span class="n">attn_mask</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;attn_mask should have dimension 2 or 3, bug got </span><span class="si">{</span><span class="n">attn_mask</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a>    <span class="c1"># prep key padding mask</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a>    <span class="k">if</span> <span class="n">key_padding_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">key_padding_mask</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">:</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a>        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a>            <span class="s2">&quot;key_padding_mask is of type uint8. This type is deprecated. Please use bool or float tensors instead.&quot;</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a>        <span class="p">)</span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a>        <span class="n">key_padding_mask</span> <span class="o">=</span> <span class="n">key_padding_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a>    <span class="c1"># reshape q, k, v for multihead attention and make em batch first</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a>    <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">target_len</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a>    <span class="n">k</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a>    <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a>    <span class="c1"># merge key padding and attention masks</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a>    <span class="k">if</span> <span class="n">key_padding_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a>        <span class="k">if</span> <span class="n">key_padding_mask</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">source_len</span><span class="p">):</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a>                <span class="sa">f</span><span class="s2">&quot;key_padding_mask should have shape </span><span class="si">{</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">source_len</span><span class="p">)</span><span class="si">}</span><span class="s2">, but got </span><span class="si">{</span><span class="n">key_padding_mask</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a>            <span class="p">)</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a>        <span class="n">key_padding_mask</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a>            <span class="n">key_padding_mask</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">source_len</span><span class="p">)</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a>            <span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a>            <span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">source_len</span><span class="p">)</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a>        <span class="p">)</span>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a>        <span class="k">if</span> <span class="n">attn_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a>            <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">key_padding_mask</span>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a>        <span class="k">elif</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">:</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a>            <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">logical_or</span><span class="p">(</span><span class="n">key_padding_mask</span><span class="p">)</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a>            <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">key_padding_mask</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;-inf&quot;</span><span class="p">))</span>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>    <span class="c1"># convert mask to float</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a>    <span class="k">if</span> <span class="n">attn_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">:</span>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a>        <span class="n">new_attn_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">attn_mask</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a>        <span class="n">new_attn_mask</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">attn_mask</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;-inf&quot;</span><span class="p">))</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a>        <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">new_attn_mask</span>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a>    <span class="c1"># (deep breath) calculate attention and out projection</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a>    <span class="n">attn_output</span><span class="p">,</span> <span class="n">attn_output_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">attn_bias</span><span class="p">,</span> <span class="n">attn_mask</span><span class="p">)</span>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a>    <span class="n">attn_output</span> <span class="o">=</span> <span class="n">attn_output</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">target_len</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">)</span>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a>    <span class="n">attn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_projection</span><span class="p">(</span><span class="n">attn_output</span><span class="p">)</span>
<a id="__codelineno-0-199" name="__codelineno-0-199"></a>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a>    <span class="c1"># attn_output_weights is set to torch.empty(0, requires_grad=False) to avoid errors in DDP</span>
<a id="__codelineno-0-201" name="__codelineno-0-201"></a>    <span class="n">attn_output_weights</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-202" name="__codelineno-0-202"></a>        <span class="n">attn_output_weights</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">target_len</span><span class="p">,</span> <span class="n">source_len</span><span class="p">)</span>
<a id="__codelineno-0-203" name="__codelineno-0-203"></a>        <span class="k">if</span> <span class="n">need_weights</span>
<a id="__codelineno-0-204" name="__codelineno-0-204"></a>        <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-0-205" name="__codelineno-0-205"></a>    <span class="p">)</span>
<a id="__codelineno-0-206" name="__codelineno-0-206"></a>
<a id="__codelineno-0-207" name="__codelineno-0-207"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_first</span><span class="p">:</span>
<a id="__codelineno-0-208" name="__codelineno-0-208"></a>        <span class="k">return</span> <span class="n">attn_output</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">attn_output_weights</span>
<a id="__codelineno-0-209" name="__codelineno-0-209"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-210" name="__codelineno-0-210"></a>        <span class="k">return</span> <span class="n">attn_output</span><span class="p">,</span> <span class="n">attn_output_weights</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="danling.models.transformer.attention.self_attention.SelfAttention.in_projection" class="doc doc-heading">
<code class="highlight language-python"><span class="n">in_projection</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span></code>

<a href="#danling.models.transformer.attention.self_attention.SelfAttention.in_projection" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Performs the in-projection step of the attention operation, using packed weights.
Output is a triple containing projection tensors for query, key and value.
Args:
    q, k, v: query, key and value tensors to be projected. For self-attention,
        these are typically the same tensor; for encoder-decoder attention,
        k and v are typically the same tensor. (We take advantage of these
        identities for performance if they are present.) Regardless, q, k and v
        must share a common embedding dimension; otherwise their shapes may vary.
Shape:
    Inputs:
    - q: :math:<code>(..., E)</code> where E is the embedding dimension
    - k: :math:<code>(..., E)</code> where E is the embedding dimension
    - v: :math:<code>(..., E)</code> where E is the embedding dimension
    Output:
    - in output list :math:<code>[q', k', v']</code>, each output tensor will have the
        same shape as the corresponding input tensor.</p>

      <details class="quote">
        <summary>Source code in <code>danling/models/transformer/attention/self_attention.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-212">212</a></span>
<span class="normal"><a href="#__codelineno-0-213">213</a></span>
<span class="normal"><a href="#__codelineno-0-214">214</a></span>
<span class="normal"><a href="#__codelineno-0-215">215</a></span>
<span class="normal"><a href="#__codelineno-0-216">216</a></span>
<span class="normal"><a href="#__codelineno-0-217">217</a></span>
<span class="normal"><a href="#__codelineno-0-218">218</a></span>
<span class="normal"><a href="#__codelineno-0-219">219</a></span>
<span class="normal"><a href="#__codelineno-0-220">220</a></span>
<span class="normal"><a href="#__codelineno-0-221">221</a></span>
<span class="normal"><a href="#__codelineno-0-222">222</a></span>
<span class="normal"><a href="#__codelineno-0-223">223</a></span>
<span class="normal"><a href="#__codelineno-0-224">224</a></span>
<span class="normal"><a href="#__codelineno-0-225">225</a></span>
<span class="normal"><a href="#__codelineno-0-226">226</a></span>
<span class="normal"><a href="#__codelineno-0-227">227</a></span>
<span class="normal"><a href="#__codelineno-0-228">228</a></span>
<span class="normal"><a href="#__codelineno-0-229">229</a></span>
<span class="normal"><a href="#__codelineno-0-230">230</a></span>
<span class="normal"><a href="#__codelineno-0-231">231</a></span>
<span class="normal"><a href="#__codelineno-0-232">232</a></span>
<span class="normal"><a href="#__codelineno-0-233">233</a></span>
<span class="normal"><a href="#__codelineno-0-234">234</a></span>
<span class="normal"><a href="#__codelineno-0-235">235</a></span>
<span class="normal"><a href="#__codelineno-0-236">236</a></span>
<span class="normal"><a href="#__codelineno-0-237">237</a></span>
<span class="normal"><a href="#__codelineno-0-238">238</a></span>
<span class="normal"><a href="#__codelineno-0-239">239</a></span>
<span class="normal"><a href="#__codelineno-0-240">240</a></span>
<span class="normal"><a href="#__codelineno-0-241">241</a></span>
<span class="normal"><a href="#__codelineno-0-242">242</a></span>
<span class="normal"><a href="#__codelineno-0-243">243</a></span>
<span class="normal"><a href="#__codelineno-0-244">244</a></span>
<span class="normal"><a href="#__codelineno-0-245">245</a></span>
<span class="normal"><a href="#__codelineno-0-246">246</a></span>
<span class="normal"><a href="#__codelineno-0-247">247</a></span>
<span class="normal"><a href="#__codelineno-0-248">248</a></span>
<span class="normal"><a href="#__codelineno-0-249">249</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-212" name="__codelineno-0-212"></a><span class="k">def</span> <span class="nf">in_projection</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">v</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-213" name="__codelineno-0-213"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-214" name="__codelineno-0-214"></a><span class="sd">    Performs the in-projection step of the attention operation, using packed weights.</span>
<a id="__codelineno-0-215" name="__codelineno-0-215"></a><span class="sd">    Output is a triple containing projection tensors for query, key and value.</span>
<a id="__codelineno-0-216" name="__codelineno-0-216"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-217" name="__codelineno-0-217"></a><span class="sd">        q, k, v: query, key and value tensors to be projected. For self-attention,</span>
<a id="__codelineno-0-218" name="__codelineno-0-218"></a><span class="sd">            these are typically the same tensor; for encoder-decoder attention,</span>
<a id="__codelineno-0-219" name="__codelineno-0-219"></a><span class="sd">            k and v are typically the same tensor. (We take advantage of these</span>
<a id="__codelineno-0-220" name="__codelineno-0-220"></a><span class="sd">            identities for performance if they are present.) Regardless, q, k and v</span>
<a id="__codelineno-0-221" name="__codelineno-0-221"></a><span class="sd">            must share a common embedding dimension; otherwise their shapes may vary.</span>
<a id="__codelineno-0-222" name="__codelineno-0-222"></a><span class="sd">    Shape:</span>
<a id="__codelineno-0-223" name="__codelineno-0-223"></a><span class="sd">        Inputs:</span>
<a id="__codelineno-0-224" name="__codelineno-0-224"></a><span class="sd">        - q: :math:`(..., E)` where E is the embedding dimension</span>
<a id="__codelineno-0-225" name="__codelineno-0-225"></a><span class="sd">        - k: :math:`(..., E)` where E is the embedding dimension</span>
<a id="__codelineno-0-226" name="__codelineno-0-226"></a><span class="sd">        - v: :math:`(..., E)` where E is the embedding dimension</span>
<a id="__codelineno-0-227" name="__codelineno-0-227"></a><span class="sd">        Output:</span>
<a id="__codelineno-0-228" name="__codelineno-0-228"></a><span class="sd">        - in output list :math:`[q&#39;, k&#39;, v&#39;]`, each output tensor will have the</span>
<a id="__codelineno-0-229" name="__codelineno-0-229"></a><span class="sd">            same shape as the corresponding input tensor.</span>
<a id="__codelineno-0-230" name="__codelineno-0-230"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-231" name="__codelineno-0-231"></a>    <span class="k">if</span> <span class="n">k</span> <span class="ow">is</span> <span class="n">v</span><span class="p">:</span>
<a id="__codelineno-0-232" name="__codelineno-0-232"></a>        <span class="c1"># self-attention</span>
<a id="__codelineno-0-233" name="__codelineno-0-233"></a>        <span class="k">if</span> <span class="n">q</span> <span class="ow">is</span> <span class="n">k</span><span class="p">:</span>
<a id="__codelineno-0-234" name="__codelineno-0-234"></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="p">(</span><span class="n">q</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_dim</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-235" name="__codelineno-0-235"></a>        <span class="c1"># encoder-decoder attention</span>
<a id="__codelineno-0-236" name="__codelineno-0-236"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-237" name="__codelineno-0-237"></a>            <span class="n">w_q</span><span class="p">,</span> <span class="n">w_kv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">split</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_dim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_dim</span><span class="p">])</span>
<a id="__codelineno-0-238" name="__codelineno-0-238"></a>            <span class="n">b_q</span><span class="p">,</span> <span class="n">b_kv</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-239" name="__codelineno-0-239"></a>                <span class="kc">None</span>
<a id="__codelineno-0-240" name="__codelineno-0-240"></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="kc">None</span>
<a id="__codelineno-0-241" name="__codelineno-0-241"></a>                <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">split</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_dim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_dim</span><span class="p">])</span>
<a id="__codelineno-0-242" name="__codelineno-0-242"></a>            <span class="p">)</span>
<a id="__codelineno-0-243" name="__codelineno-0-243"></a>            <span class="k">return</span> <span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">w_q</span><span class="p">,</span> <span class="n">b_q</span><span class="p">),)</span> <span class="o">+</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">w_kv</span><span class="p">,</span> <span class="n">b_kv</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">k_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_dim</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-244" name="__codelineno-0-244"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-245" name="__codelineno-0-245"></a>        <span class="n">w_q</span><span class="p">,</span> <span class="n">w_k</span><span class="p">,</span> <span class="n">w_v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">split</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_dim</span><span class="p">])</span>
<a id="__codelineno-0-246" name="__codelineno-0-246"></a>        <span class="n">b_q</span><span class="p">,</span> <span class="n">b_k</span><span class="p">,</span> <span class="n">b_v</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-247" name="__codelineno-0-247"></a>            <span class="kc">None</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">split</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_dim</span><span class="p">])</span>
<a id="__codelineno-0-248" name="__codelineno-0-248"></a>        <span class="p">)</span>
<a id="__codelineno-0-249" name="__codelineno-0-249"></a>        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">w_q</span><span class="p">,</span> <span class="n">b_q</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">w_k</span><span class="p">,</span> <span class="n">b_k</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">w_v</span><span class="p">,</span> <span class="n">b_v</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="danling.TorchRunner" class="doc doc-heading">
        <code>TorchRunner</code>


<a href="#danling.TorchRunner" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
      <p class="doc doc-class-bases">
        Bases: <code><a class="autorefs autorefs-internal" title="danling.runner.base_runner.BaseRunner" href="../runner/base_runner/#danling.runner.BaseRunner">BaseRunner</a></code></p>

  
      <p>Set up everything for running a job.</p>

  <p><strong>Attributes:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>accelerator</code></td>
          <td>
                <code><span title="accelerate.Accelerator">Accelerator</span></code>
          </td>
          <td></td>
        </tr>
        <tr>
          <td><code>accelerate</code></td>
          <td>
                <code>Dict[str, Any] = {}</code>
          </td>
          <td></td>
        </tr>
    </tbody>
  </table>


        <details class="quote">
          <summary>Source code in <code>danling/runner/torch_runner.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-21"> 21</a></span>
<span class="normal"><a href="#__codelineno-0-22"> 22</a></span>
<span class="normal"><a href="#__codelineno-0-23"> 23</a></span>
<span class="normal"><a href="#__codelineno-0-24"> 24</a></span>
<span class="normal"><a href="#__codelineno-0-25"> 25</a></span>
<span class="normal"><a href="#__codelineno-0-26"> 26</a></span>
<span class="normal"><a href="#__codelineno-0-27"> 27</a></span>
<span class="normal"><a href="#__codelineno-0-28"> 28</a></span>
<span class="normal"><a href="#__codelineno-0-29"> 29</a></span>
<span class="normal"><a href="#__codelineno-0-30"> 30</a></span>
<span class="normal"><a href="#__codelineno-0-31"> 31</a></span>
<span class="normal"><a href="#__codelineno-0-32"> 32</a></span>
<span class="normal"><a href="#__codelineno-0-33"> 33</a></span>
<span class="normal"><a href="#__codelineno-0-34"> 34</a></span>
<span class="normal"><a href="#__codelineno-0-35"> 35</a></span>
<span class="normal"><a href="#__codelineno-0-36"> 36</a></span>
<span class="normal"><a href="#__codelineno-0-37"> 37</a></span>
<span class="normal"><a href="#__codelineno-0-38"> 38</a></span>
<span class="normal"><a href="#__codelineno-0-39"> 39</a></span>
<span class="normal"><a href="#__codelineno-0-40"> 40</a></span>
<span class="normal"><a href="#__codelineno-0-41"> 41</a></span>
<span class="normal"><a href="#__codelineno-0-42"> 42</a></span>
<span class="normal"><a href="#__codelineno-0-43"> 43</a></span>
<span class="normal"><a href="#__codelineno-0-44"> 44</a></span>
<span class="normal"><a href="#__codelineno-0-45"> 45</a></span>
<span class="normal"><a href="#__codelineno-0-46"> 46</a></span>
<span class="normal"><a href="#__codelineno-0-47"> 47</a></span>
<span class="normal"><a href="#__codelineno-0-48"> 48</a></span>
<span class="normal"><a href="#__codelineno-0-49"> 49</a></span>
<span class="normal"><a href="#__codelineno-0-50"> 50</a></span>
<span class="normal"><a href="#__codelineno-0-51"> 51</a></span>
<span class="normal"><a href="#__codelineno-0-52"> 52</a></span>
<span class="normal"><a href="#__codelineno-0-53"> 53</a></span>
<span class="normal"><a href="#__codelineno-0-54"> 54</a></span>
<span class="normal"><a href="#__codelineno-0-55"> 55</a></span>
<span class="normal"><a href="#__codelineno-0-56"> 56</a></span>
<span class="normal"><a href="#__codelineno-0-57"> 57</a></span>
<span class="normal"><a href="#__codelineno-0-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-0-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-0-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-0-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-0-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-0-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-0-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-0-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-0-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-0-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-0-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-0-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-0-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-0-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-21" name="__codelineno-0-21"></a><span class="k">class</span> <span class="nc">TorchRunner</span><span class="p">(</span><span class="n">BaseRunner</span><span class="p">):</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a><span class="sd">    Set up everything for running a job.</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a><span class="sd">    Attributes</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a><span class="sd">    accelerator: Accelerator</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a><span class="sd">    accelerate: Dict[str, Any] = {}</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a>    <span class="c1"># pylint: disable=R0902</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a>    <span class="n">accelerator</span><span class="p">:</span> <span class="n">Accelerator</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a>    <span class="n">accelerate</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">accelerate</span><span class="p">)</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a>    <span class="nd">@on_main_process</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>    <span class="k">def</span> <span class="nf">init_tensorboard</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a>        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a><span class="sd">        Set up Tensoraoard SummaryWriter.</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a>        <span class="kn">from</span> <span class="nn">torch.utils.tensorboard.writer</span> <span class="kn">import</span> <span class="n">SummaryWriter</span>  <span class="c1"># pylint: disable=C0415</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>        <span class="k">if</span> <span class="s2">&quot;log_dir&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>            <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;log_dir&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dir</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">writer</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>    <span class="k">def</span> <span class="nf">set_seed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a>        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="sd">        Set up random seed.</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="sd">        Parameters</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a><span class="sd">        ----------</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a><span class="sd">        bias: Optional[int] = self.rank</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a><span class="sd">            Make the seed different for each processes.</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="sd">            This avoids same data augmentation are applied on every processes.</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a><span class="sd">            Set to `False` to disable this feature.</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">distributed</span><span class="p">:</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a>            <span class="c1"># TODO: use broadcast_object instead.</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">())</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># pylint: disable=E1101</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>            <span class="p">)</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>        <span class="k">if</span> <span class="n">bias</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a>            <span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>        <span class="n">seed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">+</span> <span class="n">bias</span> <span class="k">if</span> <span class="n">bias</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>        <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>        <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>    <span class="k">def</span> <span class="nf">set_deterministic</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a><span class="sd">        Set up deterministic.</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>        <span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>        <span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">__version__</span> <span class="o">&gt;=</span> <span class="s2">&quot;1.8.0&quot;</span><span class="p">:</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">use_deterministic_algorithms</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>    <span class="k">def</span> <span class="nf">init_distributed</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a><span class="sd">        Set up distributed training.</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a><span class="sd">        Initialise process group and set up DDP variables.</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a><span class="sd">        .. deprecated:: 0.1.0</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a><span class="sd">            `init_distributed` is deprecated in favor of `Accelerator()`.</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a>        <span class="c1"># pylint: disable=W0201</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>        <span class="n">dist</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s2">&quot;nccl&quot;</span><span class="p">)</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">()</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">local_rank</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;LOCAL_RANK&quot;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">local_rank</span><span class="p">)</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">is_main_process</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">is_local_main_process</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_rank</span> <span class="o">==</span> <span class="mi">0</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>    <span class="nd">@catch</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">f</span><span class="p">:</span> <span class="n">File</span><span class="p">,</span> <span class="n">main_process_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">File</span><span class="p">:</span>  <span class="c1"># pylint: disable=C0103</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a><span class="sd">        Save object to a path or file.</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a><span class="sd">        Returns</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a><span class="sd">        -------</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a><span class="sd">        File</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>        <span class="k">if</span> <span class="n">main_process_only</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_main_process</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">on_main_process</span><span class="p">:</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>        <span class="k">return</span> <span class="n">f</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>    <span class="nd">@staticmethod</span>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a>    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="n">f</span><span class="p">:</span> <span class="n">File</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>  <span class="c1"># pylint: disable=C0103</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a><span class="sd">        Load object from a path or file.</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a><span class="sd">        Returns</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a><span class="sd">        -------</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a><span class="sd">        Any</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>    <span class="k">def</span> <span class="nf">world_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a><span class="sd">        Number of Processes.</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a><span class="sd">        Returns</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a><span class="sd">        -------</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a><span class="sd">        int</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">num_processes</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a>    <span class="k">def</span> <span class="nf">rank</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a>        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a><span class="sd">        Process index in all processes.</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a><span class="sd">        Returns</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a><span class="sd">        -------</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a><span class="sd">        int</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">process_index</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a>    <span class="nd">@property</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a>    <span class="k">def</span> <span class="nf">local_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a><span class="sd">        Process index in local processes.</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a><span class="sd">        Returns</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a><span class="sd">        -------</span>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a><span class="sd">        int</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">local_process_index</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h3 id="danling.runner.torch_runner.TorchRunner.init_distributed" class="doc doc-heading">
<code class="highlight language-python"><span class="n">init_distributed</span><span class="p">()</span></code>

<a href="#danling.runner.torch_runner.TorchRunner.init_distributed" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Set up distributed training.</p>
<p>Initialise process group and set up DDP variables.</p>
<p>.. deprecated:: 0.1.0
    <code>init_distributed</code> is deprecated in favor of <code>Accelerator()</code>.</p>

      <details class="quote">
        <summary>Source code in <code>danling/runner/torch_runner.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-87" name="__codelineno-0-87"></a><span class="k">def</span> <span class="nf">init_distributed</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a><span class="sd">    Set up distributed training.</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a><span class="sd">    Initialise process group and set up DDP variables.</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a><span class="sd">    .. deprecated:: 0.1.0</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a><span class="sd">        `init_distributed` is deprecated in favor of `Accelerator()`.</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a>    <span class="c1"># pylint: disable=W0201</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>    <span class="n">dist</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s2">&quot;nccl&quot;</span><span class="p">)</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">()</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">local_rank</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;LOCAL_RANK&quot;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">local_rank</span><span class="p">)</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">is_main_process</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">is_local_main_process</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_rank</span> <span class="o">==</span> <span class="mi">0</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="danling.runner.torch_runner.TorchRunner.init_tensorboard" class="doc doc-heading">
<code class="highlight language-python"><span class="n">init_tensorboard</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#danling.runner.torch_runner.TorchRunner.init_tensorboard" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Set up Tensoraoard SummaryWriter.</p>

      <details class="quote">
        <summary>Source code in <code>danling/runner/torch_runner.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-40">40</a></span>
<span class="normal"><a href="#__codelineno-0-41">41</a></span>
<span class="normal"><a href="#__codelineno-0-42">42</a></span>
<span class="normal"><a href="#__codelineno-0-43">43</a></span>
<span class="normal"><a href="#__codelineno-0-44">44</a></span>
<span class="normal"><a href="#__codelineno-0-45">45</a></span>
<span class="normal"><a href="#__codelineno-0-46">46</a></span>
<span class="normal"><a href="#__codelineno-0-47">47</a></span>
<span class="normal"><a href="#__codelineno-0-48">48</a></span>
<span class="normal"><a href="#__codelineno-0-49">49</a></span>
<span class="normal"><a href="#__codelineno-0-50">50</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-40" name="__codelineno-0-40"></a><span class="nd">@on_main_process</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a><span class="k">def</span> <span class="nf">init_tensorboard</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a><span class="sd">    Set up Tensoraoard SummaryWriter.</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a>    <span class="kn">from</span> <span class="nn">torch.utils.tensorboard.writer</span> <span class="kn">import</span> <span class="n">SummaryWriter</span>  <span class="c1"># pylint: disable=C0415</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>    <span class="k">if</span> <span class="s2">&quot;log_dir&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>        <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;log_dir&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dir</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">writer</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="danling.runner.torch_runner.TorchRunner.load" class="doc doc-heading">
<code class="highlight language-python"><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#danling.runner.torch_runner.TorchRunner.load" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Load object from a path or file.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><span title="typing.Any">Any</span></code>
          </td>
          <td></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>danling/runner/torch_runner.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-120" name="__codelineno-0-120"></a><span class="nd">@staticmethod</span>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a><span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="n">f</span><span class="p">:</span> <span class="n">File</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>  <span class="c1"># pylint: disable=C0103</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a><span class="sd">    Load object from a path or file.</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a><span class="sd">    -------</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a><span class="sd">    Any</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="danling.runner.torch_runner.TorchRunner.local_rank" class="doc doc-heading">
<code class="highlight language-python"><span class="n">local_rank</span><span class="p">()</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#danling.runner.torch_runner.TorchRunner.local_rank" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Process index in local processes.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>int</code>
          </td>
          <td></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>danling/runner/torch_runner.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-155" name="__codelineno-0-155"></a><span class="nd">@property</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a><span class="k">def</span> <span class="nf">local_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a><span class="sd">    Process index in local processes.</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a><span class="sd">    -------</span>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a><span class="sd">    int</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">local_process_index</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="danling.runner.torch_runner.TorchRunner.rank" class="doc doc-heading">
<code class="highlight language-python"><span class="n">rank</span><span class="p">()</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#danling.runner.torch_runner.TorchRunner.rank" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Process index in all processes.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>int</code>
          </td>
          <td></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>danling/runner/torch_runner.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-143" name="__codelineno-0-143"></a><span class="nd">@property</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a><span class="k">def</span> <span class="nf">rank</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a><span class="sd">    Process index in all processes.</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a><span class="sd">    -------</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a><span class="sd">    int</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">process_index</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="danling.runner.torch_runner.TorchRunner.save" class="doc doc-heading">
<code class="highlight language-python"><span class="n">save</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">main_process_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

<a href="#danling.runner.torch_runner.TorchRunner.save" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Save object to a path or file.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><span title="danling.typing.File">File</span></code>
          </td>
          <td></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>danling/runner/torch_runner.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-107" name="__codelineno-0-107"></a><span class="nd">@catch</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a><span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">f</span><span class="p">:</span> <span class="n">File</span><span class="p">,</span> <span class="n">main_process_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">File</span><span class="p">:</span>  <span class="c1"># pylint: disable=C0103</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a><span class="sd">    Save object to a path or file.</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a><span class="sd">    -------</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a><span class="sd">    File</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>    <span class="k">if</span> <span class="n">main_process_only</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_main_process</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">on_main_process</span><span class="p">:</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>    <span class="k">return</span> <span class="n">f</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="danling.runner.torch_runner.TorchRunner.set_deterministic" class="doc doc-heading">
<code class="highlight language-python"><span class="n">set_deterministic</span><span class="p">()</span></code>

<a href="#danling.runner.torch_runner.TorchRunner.set_deterministic" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Set up deterministic.</p>

      <details class="quote">
        <summary>Source code in <code>danling/runner/torch_runner.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-77">77</a></span>
<span class="normal"><a href="#__codelineno-0-78">78</a></span>
<span class="normal"><a href="#__codelineno-0-79">79</a></span>
<span class="normal"><a href="#__codelineno-0-80">80</a></span>
<span class="normal"><a href="#__codelineno-0-81">81</a></span>
<span class="normal"><a href="#__codelineno-0-82">82</a></span>
<span class="normal"><a href="#__codelineno-0-83">83</a></span>
<span class="normal"><a href="#__codelineno-0-84">84</a></span>
<span class="normal"><a href="#__codelineno-0-85">85</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-77" name="__codelineno-0-77"></a><span class="k">def</span> <span class="nf">set_deterministic</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a><span class="sd">    Set up deterministic.</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>    <span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>    <span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">__version__</span> <span class="o">&gt;=</span> <span class="s2">&quot;1.8.0&quot;</span><span class="p">:</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>        <span class="n">torch</span><span class="o">.</span><span class="n">use_deterministic_algorithms</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="danling.runner.torch_runner.TorchRunner.set_seed" class="doc doc-heading">
<code class="highlight language-python"><span class="n">set_seed</span><span class="p">(</span><span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#danling.runner.torch_runner.TorchRunner.set_seed" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Set up random seed.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>bias</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[int]</code>
          </td>
          <td><p>Make the seed different for each processes.
This avoids same data augmentation are applied on every processes.
Set to <code>False</code> to disable this feature.</p></td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>danling/runner/torch_runner.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-52">52</a></span>
<span class="normal"><a href="#__codelineno-0-53">53</a></span>
<span class="normal"><a href="#__codelineno-0-54">54</a></span>
<span class="normal"><a href="#__codelineno-0-55">55</a></span>
<span class="normal"><a href="#__codelineno-0-56">56</a></span>
<span class="normal"><a href="#__codelineno-0-57">57</a></span>
<span class="normal"><a href="#__codelineno-0-58">58</a></span>
<span class="normal"><a href="#__codelineno-0-59">59</a></span>
<span class="normal"><a href="#__codelineno-0-60">60</a></span>
<span class="normal"><a href="#__codelineno-0-61">61</a></span>
<span class="normal"><a href="#__codelineno-0-62">62</a></span>
<span class="normal"><a href="#__codelineno-0-63">63</a></span>
<span class="normal"><a href="#__codelineno-0-64">64</a></span>
<span class="normal"><a href="#__codelineno-0-65">65</a></span>
<span class="normal"><a href="#__codelineno-0-66">66</a></span>
<span class="normal"><a href="#__codelineno-0-67">67</a></span>
<span class="normal"><a href="#__codelineno-0-68">68</a></span>
<span class="normal"><a href="#__codelineno-0-69">69</a></span>
<span class="normal"><a href="#__codelineno-0-70">70</a></span>
<span class="normal"><a href="#__codelineno-0-71">71</a></span>
<span class="normal"><a href="#__codelineno-0-72">72</a></span>
<span class="normal"><a href="#__codelineno-0-73">73</a></span>
<span class="normal"><a href="#__codelineno-0-74">74</a></span>
<span class="normal"><a href="#__codelineno-0-75">75</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-52" name="__codelineno-0-52"></a><span class="k">def</span> <span class="nf">set_seed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="sd">    Set up random seed.</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a><span class="sd">    bias: Optional[int] = self.rank</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a><span class="sd">        Make the seed different for each processes.</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="sd">        This avoids same data augmentation are applied on every processes.</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a><span class="sd">        Set to `False` to disable this feature.</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">distributed</span><span class="p">:</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a>        <span class="c1"># TODO: use broadcast_object instead.</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">())</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># pylint: disable=E1101</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>        <span class="p">)</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>    <span class="k">if</span> <span class="n">bias</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a>        <span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>    <span class="n">seed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">+</span> <span class="n">bias</span> <span class="k">if</span> <span class="n">bias</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h3 id="danling.runner.torch_runner.TorchRunner.world_size" class="doc doc-heading">
<code class="highlight language-python"><span class="n">world_size</span><span class="p">()</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#danling.runner.torch_runner.TorchRunner.world_size" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Number of Processes.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code>int</code>
          </td>
          <td></td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>danling/runner/torch_runner.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-131" name="__codelineno-0-131"></a><span class="nd">@property</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a><span class="k">def</span> <span class="nf">world_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a><span class="sd">    Number of Processes.</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a><span class="sd">    -------</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a><span class="sd">    int</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">num_processes</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="danling.TransformerDecoder" class="doc doc-heading">
        <code>TransformerDecoder</code>


<a href="#danling.TransformerDecoder" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
      <p class="doc doc-class-bases">
        Bases: <code><span title="torch.nn">nn</span>.<span title="torch.nn.Module">Module</span></code></p>

  
      <p>TransformerDecoder is a stack of N decoder layers
Args:
    num_layers: the number of sub-decoder-layers in the decoder (required).
    layer: the sub-decoder-layer in the decoder (default=TransformerDecoderLayer).
    drop_layer: the drop layer rate (default=0.0).
Examples::
    &gt;&gt;&gt; transformer_decoder = dl.model.TransformerDecoder(num_layers=6)
    &gt;&gt;&gt; src = torch.rand(10, 32, 512)
    &gt;&gt;&gt; out = transformer_decoder(src)</p>


        <details class="quote">
          <summary>Source code in <code>danling/models/transformer/decoder.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span>
<span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span>
<span class="normal"><a href="#__codelineno-0-203">203</a></span>
<span class="normal"><a href="#__codelineno-0-204">204</a></span>
<span class="normal"><a href="#__codelineno-0-205">205</a></span>
<span class="normal"><a href="#__codelineno-0-206">206</a></span>
<span class="normal"><a href="#__codelineno-0-207">207</a></span>
<span class="normal"><a href="#__codelineno-0-208">208</a></span>
<span class="normal"><a href="#__codelineno-0-209">209</a></span>
<span class="normal"><a href="#__codelineno-0-210">210</a></span>
<span class="normal"><a href="#__codelineno-0-211">211</a></span>
<span class="normal"><a href="#__codelineno-0-212">212</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-147" name="__codelineno-0-147"></a><span class="k">class</span> <span class="nc">TransformerDecoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;TransformerDecoder is a stack of N decoder layers</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a><span class="sd">        num_layers: the number of sub-decoder-layers in the decoder (required).</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a><span class="sd">        layer: the sub-decoder-layer in the decoder (default=TransformerDecoderLayer).</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a><span class="sd">        drop_layer: the drop layer rate (default=0.0).</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a><span class="sd">    Examples::</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a><span class="sd">        &gt;&gt;&gt; transformer_decoder = dl.model.TransformerDecoder(num_layers=6)</span>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a><span class="sd">        &gt;&gt;&gt; src = torch.rand(10, 32, 512)</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a><span class="sd">        &gt;&gt;&gt; out = transformer_decoder(src)</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a>    <span class="n">__constants__</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;norm&quot;</span><span class="p">]</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer</span><span class="p">:</span> <span class="n">TransformerDecoderLayer</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">6</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([])</span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">layer</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">)])</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a>        <span class="n">tgt</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a>        <span class="n">mem</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a>        <span class="n">tgt_bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a>        <span class="n">tgt_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a>        <span class="n">tgt_key_padding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a>        <span class="n">mem_bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a>        <span class="n">mem_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a>        <span class="n">mem_key_padding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a>        <span class="n">need_weights</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a>        <span class="n">gradient_checkpoint</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a>        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Pass the input through the decoder layers in turn.</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a><span class="sd">            src: the sequence to the decoder (required).</span>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a><span class="sd">            attn_mask: the mask for the src sequence (optional).</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a><span class="sd">            key_padding_mask: the mask for the src keys per batch (optional).</span>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a><span class="sd">        Shape:</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a><span class="sd">            see the docs in Transformer class.</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a>        <span class="n">output</span> <span class="o">=</span> <span class="n">tgt</span>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a>        <span class="c1"># attn_weights is set to torch.empty(0, requires_grad=False) to avoid errors in DDP</span>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>        <span class="n">attn_weights</span> <span class="o">=</span> <span class="p">[]</span> <span class="k">if</span> <span class="n">need_weights</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a>        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a>            <span class="k">if</span> <span class="n">gradient_checkpoint</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a>                <span class="n">layer</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">layer</span><span class="p">)</span>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a>                <span class="n">need_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">need_weights</span><span class="p">)</span>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a>            <span class="n">output</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a>                <span class="n">output</span><span class="p">,</span>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a>                <span class="n">mem</span><span class="p">,</span>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a>                <span class="n">tgt_bias</span><span class="p">,</span>
<a id="__codelineno-0-199" name="__codelineno-0-199"></a>                <span class="n">tgt_mask</span><span class="p">,</span>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a>                <span class="n">tgt_key_padding_mask</span><span class="p">,</span>
<a id="__codelineno-0-201" name="__codelineno-0-201"></a>                <span class="n">mem_bias</span><span class="p">,</span>
<a id="__codelineno-0-202" name="__codelineno-0-202"></a>                <span class="n">mem_mask</span><span class="p">,</span>
<a id="__codelineno-0-203" name="__codelineno-0-203"></a>                <span class="n">mem_key_padding_mask</span><span class="p">,</span>
<a id="__codelineno-0-204" name="__codelineno-0-204"></a>                <span class="n">need_weights</span><span class="p">,</span>
<a id="__codelineno-0-205" name="__codelineno-0-205"></a>            <span class="p">)</span>
<a id="__codelineno-0-206" name="__codelineno-0-206"></a>            <span class="k">if</span> <span class="n">need_weights</span><span class="p">:</span>
<a id="__codelineno-0-207" name="__codelineno-0-207"></a>                <span class="n">attn_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
<a id="__codelineno-0-208" name="__codelineno-0-208"></a>
<a id="__codelineno-0-209" name="__codelineno-0-209"></a>        <span class="k">if</span> <span class="n">need_weights</span><span class="p">:</span>
<a id="__codelineno-0-210" name="__codelineno-0-210"></a>            <span class="n">attn_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">attn_weights</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>  <span class="c1"># type: ignore</span>
<a id="__codelineno-0-211" name="__codelineno-0-211"></a>
<a id="__codelineno-0-212" name="__codelineno-0-212"></a>        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">attn_weights</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h3 id="danling.models.transformer.decoder.TransformerDecoder.forward" class="doc doc-heading">
<code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">tgt</span><span class="p">,</span> <span class="n">mem</span><span class="p">,</span> <span class="n">tgt_bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tgt_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tgt_key_padding_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mem_bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mem_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mem_key_padding_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">need_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">gradient_checkpoint</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#danling.models.transformer.decoder.TransformerDecoder.forward" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Pass the input through the decoder layers in turn.
Args:
    src: the sequence to the decoder (required).
    attn_mask: the mask for the src sequence (optional).
    key_padding_mask: the mask for the src keys per batch (optional).
Shape:
    see the docs in Transformer class.</p>

      <details class="quote">
        <summary>Source code in <code>danling/models/transformer/decoder.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span>
<span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span>
<span class="normal"><a href="#__codelineno-0-203">203</a></span>
<span class="normal"><a href="#__codelineno-0-204">204</a></span>
<span class="normal"><a href="#__codelineno-0-205">205</a></span>
<span class="normal"><a href="#__codelineno-0-206">206</a></span>
<span class="normal"><a href="#__codelineno-0-207">207</a></span>
<span class="normal"><a href="#__codelineno-0-208">208</a></span>
<span class="normal"><a href="#__codelineno-0-209">209</a></span>
<span class="normal"><a href="#__codelineno-0-210">210</a></span>
<span class="normal"><a href="#__codelineno-0-211">211</a></span>
<span class="normal"><a href="#__codelineno-0-212">212</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-166" name="__codelineno-0-166"></a><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a>    <span class="n">tgt</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a>    <span class="n">mem</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a>    <span class="n">tgt_bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a>    <span class="n">tgt_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a>    <span class="n">tgt_key_padding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a>    <span class="n">mem_bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a>    <span class="n">mem_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a>    <span class="n">mem_key_padding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a>    <span class="n">need_weights</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a>    <span class="n">gradient_checkpoint</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Pass the input through the decoder layers in turn.</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a><span class="sd">        src: the sequence to the decoder (required).</span>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a><span class="sd">        attn_mask: the mask for the src sequence (optional).</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a><span class="sd">        key_padding_mask: the mask for the src keys per batch (optional).</span>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a><span class="sd">    Shape:</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a><span class="sd">        see the docs in Transformer class.</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a>    <span class="n">output</span> <span class="o">=</span> <span class="n">tgt</span>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a>    <span class="c1"># attn_weights is set to torch.empty(0, requires_grad=False) to avoid errors in DDP</span>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>    <span class="n">attn_weights</span> <span class="o">=</span> <span class="p">[]</span> <span class="k">if</span> <span class="n">need_weights</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a>    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a>        <span class="k">if</span> <span class="n">gradient_checkpoint</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a>            <span class="n">layer</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">layer</span><span class="p">)</span>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a>            <span class="n">need_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">need_weights</span><span class="p">)</span>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a>        <span class="n">output</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a>            <span class="n">output</span><span class="p">,</span>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a>            <span class="n">mem</span><span class="p">,</span>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a>            <span class="n">tgt_bias</span><span class="p">,</span>
<a id="__codelineno-0-199" name="__codelineno-0-199"></a>            <span class="n">tgt_mask</span><span class="p">,</span>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a>            <span class="n">tgt_key_padding_mask</span><span class="p">,</span>
<a id="__codelineno-0-201" name="__codelineno-0-201"></a>            <span class="n">mem_bias</span><span class="p">,</span>
<a id="__codelineno-0-202" name="__codelineno-0-202"></a>            <span class="n">mem_mask</span><span class="p">,</span>
<a id="__codelineno-0-203" name="__codelineno-0-203"></a>            <span class="n">mem_key_padding_mask</span><span class="p">,</span>
<a id="__codelineno-0-204" name="__codelineno-0-204"></a>            <span class="n">need_weights</span><span class="p">,</span>
<a id="__codelineno-0-205" name="__codelineno-0-205"></a>        <span class="p">)</span>
<a id="__codelineno-0-206" name="__codelineno-0-206"></a>        <span class="k">if</span> <span class="n">need_weights</span><span class="p">:</span>
<a id="__codelineno-0-207" name="__codelineno-0-207"></a>            <span class="n">attn_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
<a id="__codelineno-0-208" name="__codelineno-0-208"></a>
<a id="__codelineno-0-209" name="__codelineno-0-209"></a>    <span class="k">if</span> <span class="n">need_weights</span><span class="p">:</span>
<a id="__codelineno-0-210" name="__codelineno-0-210"></a>        <span class="n">attn_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">attn_weights</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>  <span class="c1"># type: ignore</span>
<a id="__codelineno-0-211" name="__codelineno-0-211"></a>
<a id="__codelineno-0-212" name="__codelineno-0-212"></a>    <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">attn_weights</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="danling.TransformerDecoderLayer" class="doc doc-heading">
        <code>TransformerDecoderLayer</code>


<a href="#danling.TransformerDecoderLayer" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
      <p class="doc doc-class-bases">
        Bases: <code><span title="torch.nn">nn</span>.<span title="torch.nn.Module">Module</span></code></p>

  
      <p>TransformerDecoderLayer is made up of self-attn and feedforward network.
This standard decoder layer is based on the paper &ldquo;Attention Is All You Need&rdquo;.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in
Neural Information Processing Systems, pages 6000-6010. Users may modify or implement
in a different way during application.
Args:
    embed_dim: the number of expected features in the input (required).
    num_heads: the number of heads in the multi head attention models (required).
    ffn_dim: the dimension of the feedforward network model (default=embed_dim*4).
    dropout: the dropout value (default=0.1).
    activation: the activation function of intermediate layer, relu or gelu (default=relu).
    layer_norm_eps: the eps value in layer normalization components (default=1e-5).
    batch_first: If <code>True</code>, then the input and output tensors are provided
        as (batch, seq, feature). Default: <code>False</code>.
    norm_first: if <code>True</code>, layer norm is done prior to attention and feedforward
        operations, respectivaly. Otherwise it&rsquo;s done after. Default: <code>False</code> (after).
Examples::
    &gt;&gt;&gt; decoder_layer = nn.TransformerDecoderLayer(embed_dim=512, num_heads=8)
    &gt;&gt;&gt; src = torch.rand(10, 32, 512)
    &gt;&gt;&gt; out = decoder_layer(src)
Alternatively, when <code>batch_first</code> is <code>True</code>:
    &gt;&gt;&gt; decoder_layer = nn.TransformerDecoderLayer(embed_dim=512, num_heads=8, batch_first=True)
    &gt;&gt;&gt; src = torch.rand(32, 10, 512)
    &gt;&gt;&gt; out = decoder_layer(src)</p>


        <details class="quote">
          <summary>Source code in <code>danling/models/transformer/decoder.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-12"> 12</a></span>
<span class="normal"><a href="#__codelineno-0-13"> 13</a></span>
<span class="normal"><a href="#__codelineno-0-14"> 14</a></span>
<span class="normal"><a href="#__codelineno-0-15"> 15</a></span>
<span class="normal"><a href="#__codelineno-0-16"> 16</a></span>
<span class="normal"><a href="#__codelineno-0-17"> 17</a></span>
<span class="normal"><a href="#__codelineno-0-18"> 18</a></span>
<span class="normal"><a href="#__codelineno-0-19"> 19</a></span>
<span class="normal"><a href="#__codelineno-0-20"> 20</a></span>
<span class="normal"><a href="#__codelineno-0-21"> 21</a></span>
<span class="normal"><a href="#__codelineno-0-22"> 22</a></span>
<span class="normal"><a href="#__codelineno-0-23"> 23</a></span>
<span class="normal"><a href="#__codelineno-0-24"> 24</a></span>
<span class="normal"><a href="#__codelineno-0-25"> 25</a></span>
<span class="normal"><a href="#__codelineno-0-26"> 26</a></span>
<span class="normal"><a href="#__codelineno-0-27"> 27</a></span>
<span class="normal"><a href="#__codelineno-0-28"> 28</a></span>
<span class="normal"><a href="#__codelineno-0-29"> 29</a></span>
<span class="normal"><a href="#__codelineno-0-30"> 30</a></span>
<span class="normal"><a href="#__codelineno-0-31"> 31</a></span>
<span class="normal"><a href="#__codelineno-0-32"> 32</a></span>
<span class="normal"><a href="#__codelineno-0-33"> 33</a></span>
<span class="normal"><a href="#__codelineno-0-34"> 34</a></span>
<span class="normal"><a href="#__codelineno-0-35"> 35</a></span>
<span class="normal"><a href="#__codelineno-0-36"> 36</a></span>
<span class="normal"><a href="#__codelineno-0-37"> 37</a></span>
<span class="normal"><a href="#__codelineno-0-38"> 38</a></span>
<span class="normal"><a href="#__codelineno-0-39"> 39</a></span>
<span class="normal"><a href="#__codelineno-0-40"> 40</a></span>
<span class="normal"><a href="#__codelineno-0-41"> 41</a></span>
<span class="normal"><a href="#__codelineno-0-42"> 42</a></span>
<span class="normal"><a href="#__codelineno-0-43"> 43</a></span>
<span class="normal"><a href="#__codelineno-0-44"> 44</a></span>
<span class="normal"><a href="#__codelineno-0-45"> 45</a></span>
<span class="normal"><a href="#__codelineno-0-46"> 46</a></span>
<span class="normal"><a href="#__codelineno-0-47"> 47</a></span>
<span class="normal"><a href="#__codelineno-0-48"> 48</a></span>
<span class="normal"><a href="#__codelineno-0-49"> 49</a></span>
<span class="normal"><a href="#__codelineno-0-50"> 50</a></span>
<span class="normal"><a href="#__codelineno-0-51"> 51</a></span>
<span class="normal"><a href="#__codelineno-0-52"> 52</a></span>
<span class="normal"><a href="#__codelineno-0-53"> 53</a></span>
<span class="normal"><a href="#__codelineno-0-54"> 54</a></span>
<span class="normal"><a href="#__codelineno-0-55"> 55</a></span>
<span class="normal"><a href="#__codelineno-0-56"> 56</a></span>
<span class="normal"><a href="#__codelineno-0-57"> 57</a></span>
<span class="normal"><a href="#__codelineno-0-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-0-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-0-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-0-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-0-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-0-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-0-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-0-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-0-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-0-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-0-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-0-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-0-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-0-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="k">class</span> <span class="nc">TransformerDecoderLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;TransformerDecoderLayer is made up of self-attn and feedforward network.</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a><span class="sd">    This standard decoder layer is based on the paper &quot;Attention Is All You Need&quot;.</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a><span class="sd">    Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a><span class="sd">    Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a><span class="sd">    Neural Information Processing Systems, pages 6000-6010. Users may modify or implement</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a><span class="sd">    in a different way during application.</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a><span class="sd">        embed_dim: the number of expected features in the input (required).</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a><span class="sd">        num_heads: the number of heads in the multi head attention models (required).</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a><span class="sd">        ffn_dim: the dimension of the feedforward network model (default=embed_dim*4).</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a><span class="sd">        dropout: the dropout value (default=0.1).</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a><span class="sd">        activation: the activation function of intermediate layer, relu or gelu (default=relu).</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a><span class="sd">        layer_norm_eps: the eps value in layer normalization components (default=1e-5).</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a><span class="sd">        batch_first: If ``True``, then the input and output tensors are provided</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a><span class="sd">            as (batch, seq, feature). Default: ``False``.</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a><span class="sd">        norm_first: if ``True``, layer norm is done prior to attention and feedforward</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a><span class="sd">            operations, respectivaly. Otherwise it&#39;s done after. Default: ``False`` (after).</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a><span class="sd">    Examples::</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="sd">        &gt;&gt;&gt; decoder_layer = nn.TransformerDecoderLayer(embed_dim=512, num_heads=8)</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a><span class="sd">        &gt;&gt;&gt; src = torch.rand(10, 32, 512)</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a><span class="sd">        &gt;&gt;&gt; out = decoder_layer(src)</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a><span class="sd">    Alternatively, when ``batch_first`` is ``True``:</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a><span class="sd">        &gt;&gt;&gt; decoder_layer = nn.TransformerDecoderLayer(embed_dim=512, num_heads=8, batch_first=True)</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a><span class="sd">        &gt;&gt;&gt; src = torch.rand(32, 10, 512)</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a><span class="sd">        &gt;&gt;&gt; out = decoder_layer(src)</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>    <span class="n">__constants__</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;batch_first&quot;</span><span class="p">,</span> <span class="s2">&quot;norm_first&quot;</span><span class="p">]</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a>        <span class="n">embed_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>        <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a>        <span class="n">ffn_dim</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>        <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>        <span class="n">attn_dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>        <span class="n">ffn_dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a>        <span class="n">activation</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;GELU&quot;</span><span class="p">,</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a>        <span class="n">layer_norm_eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">,</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a>        <span class="n">scale_factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>        <span class="n">bias</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a>        <span class="n">add_bias_kv</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a>        <span class="n">add_zero_attn</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>        <span class="n">batch_first</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a>        <span class="n">norm_first</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a>        <span class="n">Attention</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">,</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a>        <span class="n">FeedForwardNetwork</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">FullyConnectedNetwork</span><span class="p">,</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a>        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a>        <span class="k">if</span> <span class="n">ffn_dim</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a>            <span class="n">ffn_dim</span> <span class="o">=</span> <span class="n">embed_dim</span> <span class="o">*</span> <span class="mi">4</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">norm_first</span> <span class="o">=</span> <span class="n">norm_first</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span> <span class="o">=</span> <span class="n">Attention</span><span class="p">(</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a>            <span class="n">embed_dim</span><span class="p">,</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a>            <span class="n">num_heads</span><span class="p">,</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>            <span class="n">attn_dropout</span><span class="o">=</span><span class="n">attn_dropout</span><span class="p">,</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>            <span class="n">scale_factor</span><span class="o">=</span><span class="n">scale_factor</span><span class="p">,</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a>            <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>            <span class="n">add_bias_kv</span><span class="o">=</span><span class="n">add_bias_kv</span><span class="p">,</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>            <span class="n">add_zero_attn</span><span class="o">=</span><span class="n">add_zero_attn</span><span class="p">,</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>            <span class="n">batch_first</span><span class="o">=</span><span class="n">batch_first</span><span class="p">,</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>            <span class="o">**</span><span class="n">kwargs</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>        <span class="p">)</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cross_attn</span> <span class="o">=</span> <span class="n">Attention</span><span class="p">(</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>            <span class="n">embed_dim</span><span class="p">,</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>            <span class="n">num_heads</span><span class="p">,</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>            <span class="n">attn_dropout</span><span class="o">=</span><span class="n">attn_dropout</span><span class="p">,</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a>            <span class="n">scale_factor</span><span class="o">=</span><span class="n">scale_factor</span><span class="p">,</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>            <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>            <span class="n">add_bias_kv</span><span class="o">=</span><span class="n">add_bias_kv</span><span class="p">,</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>            <span class="n">add_zero_attn</span><span class="o">=</span><span class="n">add_zero_attn</span><span class="p">,</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>            <span class="n">batch_first</span><span class="o">=</span><span class="n">batch_first</span><span class="p">,</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>            <span class="o">**</span><span class="n">kwargs</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>        <span class="p">)</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="n">layer_norm_eps</span><span class="p">)</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span> <span class="o">=</span> <span class="n">FeedForwardNetwork</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">ffn_dim</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span> <span class="n">ffn_dropout</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="n">layer_norm_eps</span><span class="p">)</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a>        <span class="n">tgt</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a>        <span class="n">mem</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a>        <span class="n">tgt_bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a>        <span class="n">tgt_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>        <span class="n">tgt_key_padding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>        <span class="n">mem_bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>        <span class="n">mem_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>        <span class="n">mem_key_padding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>        <span class="n">need_weights</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Pass the input through the decoder layer.</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a><span class="sd">            src: the sequence to the decoder layer (required).</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a><span class="sd">            attn_mask: the mask for the src sequence (optional).</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a><span class="sd">            key_padding_mask: the mask for the src keys per batch (optional).</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a><span class="sd">        Shape:</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a><span class="sd">            see the docs in Transformer class.</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_first</span><span class="p">:</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>            <span class="n">tgt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">tgt</span><span class="p">)</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>        <span class="n">self_attn</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span><span class="p">(</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>            <span class="n">tgt</span><span class="p">,</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>            <span class="n">tgt</span><span class="p">,</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>            <span class="n">tgt</span><span class="p">,</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>            <span class="n">attn_bias</span><span class="o">=</span><span class="n">tgt_bias</span><span class="p">,</span>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a>            <span class="n">attn_mask</span><span class="o">=</span><span class="n">tgt_mask</span><span class="p">,</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>            <span class="n">key_padding_mask</span><span class="o">=</span><span class="n">tgt_key_padding_mask</span><span class="p">,</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a>            <span class="n">need_weights</span><span class="o">=</span><span class="n">need_weights</span><span class="p">,</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>        <span class="p">)</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a>        <span class="n">self_attn</span> <span class="o">=</span> <span class="n">tgt</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">self_attn</span><span class="p">)</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a>        <span class="n">cross_attn</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_attn</span><span class="p">(</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a>            <span class="n">self_attn</span><span class="p">,</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a>            <span class="n">mem</span><span class="p">,</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>            <span class="n">mem</span><span class="p">,</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a>            <span class="n">attn_bias</span><span class="o">=</span><span class="n">mem_bias</span><span class="p">,</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a>            <span class="n">attn_mask</span><span class="o">=</span><span class="n">mem_mask</span><span class="p">,</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>            <span class="n">key_padding_mask</span><span class="o">=</span><span class="n">mem_key_padding_mask</span><span class="p">,</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>            <span class="n">need_weights</span><span class="o">=</span><span class="n">need_weights</span><span class="p">,</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a>        <span class="p">)</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>        <span class="n">cross_attn</span> <span class="o">=</span> <span class="n">self_attn</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">cross_attn</span><span class="p">)</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>        <span class="n">attn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">cross_attn</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_first</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">cross_attn</span><span class="p">)</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>        <span class="n">ffn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span><span class="p">(</span><span class="n">attn</span><span class="p">)</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>        <span class="n">ffn</span> <span class="o">=</span> <span class="n">attn</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">ffn</span><span class="p">)</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_first</span><span class="p">:</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>            <span class="n">ffn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">ffn</span><span class="p">)</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a>        <span class="k">return</span> <span class="n">ffn</span><span class="p">,</span> <span class="n">weights</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h3 id="danling.models.transformer.decoder.TransformerDecoderLayer.forward" class="doc doc-heading">
<code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">tgt</span><span class="p">,</span> <span class="n">mem</span><span class="p">,</span> <span class="n">tgt_bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tgt_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tgt_key_padding_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mem_bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mem_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mem_key_padding_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">need_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#danling.models.transformer.decoder.TransformerDecoderLayer.forward" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Pass the input through the decoder layer.
Args:
    src: the sequence to the decoder layer (required).
    attn_mask: the mask for the src sequence (optional).
    key_padding_mask: the mask for the src keys per batch (optional).
Shape:
    see the docs in Transformer class.</p>

      <details class="quote">
        <summary>Source code in <code>danling/models/transformer/decoder.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-92" name="__codelineno-0-92"></a><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a>    <span class="n">tgt</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a>    <span class="n">mem</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a>    <span class="n">tgt_bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a>    <span class="n">tgt_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>    <span class="n">tgt_key_padding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>    <span class="n">mem_bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>    <span class="n">mem_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>    <span class="n">mem_key_padding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>    <span class="n">need_weights</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Pass the input through the decoder layer.</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a><span class="sd">        src: the sequence to the decoder layer (required).</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a><span class="sd">        attn_mask: the mask for the src sequence (optional).</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a><span class="sd">        key_padding_mask: the mask for the src keys per batch (optional).</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a><span class="sd">    Shape:</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a><span class="sd">        see the docs in Transformer class.</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_first</span><span class="p">:</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>        <span class="n">tgt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">tgt</span><span class="p">)</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>    <span class="n">self_attn</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span><span class="p">(</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>        <span class="n">tgt</span><span class="p">,</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>        <span class="n">tgt</span><span class="p">,</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>        <span class="n">tgt</span><span class="p">,</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>        <span class="n">attn_bias</span><span class="o">=</span><span class="n">tgt_bias</span><span class="p">,</span>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a>        <span class="n">attn_mask</span><span class="o">=</span><span class="n">tgt_mask</span><span class="p">,</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>        <span class="n">key_padding_mask</span><span class="o">=</span><span class="n">tgt_key_padding_mask</span><span class="p">,</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a>        <span class="n">need_weights</span><span class="o">=</span><span class="n">need_weights</span><span class="p">,</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>    <span class="p">)</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a>    <span class="n">self_attn</span> <span class="o">=</span> <span class="n">tgt</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">self_attn</span><span class="p">)</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a>    <span class="n">cross_attn</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_attn</span><span class="p">(</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a>        <span class="n">self_attn</span><span class="p">,</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a>        <span class="n">mem</span><span class="p">,</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>        <span class="n">mem</span><span class="p">,</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a>        <span class="n">attn_bias</span><span class="o">=</span><span class="n">mem_bias</span><span class="p">,</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a>        <span class="n">attn_mask</span><span class="o">=</span><span class="n">mem_mask</span><span class="p">,</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>        <span class="n">key_padding_mask</span><span class="o">=</span><span class="n">mem_key_padding_mask</span><span class="p">,</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>        <span class="n">need_weights</span><span class="o">=</span><span class="n">need_weights</span><span class="p">,</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a>    <span class="p">)</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>    <span class="n">cross_attn</span> <span class="o">=</span> <span class="n">self_attn</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">cross_attn</span><span class="p">)</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>    <span class="n">attn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">cross_attn</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_first</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">cross_attn</span><span class="p">)</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>    <span class="n">ffn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span><span class="p">(</span><span class="n">attn</span><span class="p">)</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>    <span class="n">ffn</span> <span class="o">=</span> <span class="n">attn</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">ffn</span><span class="p">)</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_first</span><span class="p">:</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>        <span class="n">ffn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">ffn</span><span class="p">)</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a>    <span class="k">return</span> <span class="n">ffn</span><span class="p">,</span> <span class="n">weights</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="danling.TransformerEncoder" class="doc doc-heading">
        <code>TransformerEncoder</code>


<a href="#danling.TransformerEncoder" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
      <p class="doc doc-class-bases">
        Bases: <code><span title="torch.nn">nn</span>.<span title="torch.nn.Module">Module</span></code></p>

  
      <p>TransformerEncoder is a stack of N encoder layers
Args:
    num_layers: the number of sub-encoder-layers in the encoder (required).
    layer: the sub-encoder-layer in the encoder (default=TransformerEncoderLayer).
    drop_layer: the drop layer rate (default=0.0).
Examples::
    &gt;&gt;&gt; transformer_encoder = dl.model.TransformerEncoder(num_layers=6)
    &gt;&gt;&gt; src = torch.rand(10, 32, 512)
    &gt;&gt;&gt; out = transformer_encoder(src)</p>


        <details class="quote">
          <summary>Source code in <code>danling/models/transformer/encoder.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-122" name="__codelineno-0-122"></a><span class="k">class</span> <span class="nc">TransformerEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;TransformerEncoder is a stack of N encoder layers</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a><span class="sd">        num_layers: the number of sub-encoder-layers in the encoder (required).</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a><span class="sd">        layer: the sub-encoder-layer in the encoder (default=TransformerEncoderLayer).</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a><span class="sd">        drop_layer: the drop layer rate (default=0.0).</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a><span class="sd">    Examples::</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a><span class="sd">        &gt;&gt;&gt; transformer_encoder = dl.model.TransformerEncoder(num_layers=6)</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a><span class="sd">        &gt;&gt;&gt; src = torch.rand(10, 32, 512)</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a><span class="sd">        &gt;&gt;&gt; out = transformer_encoder(src)</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>    <span class="n">__constants__</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;norm&quot;</span><span class="p">]</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer</span><span class="p">:</span> <span class="n">TransformerEncoderLayer</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">6</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([])</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">layer</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">)])</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>        <span class="n">src</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a>        <span class="n">attn_bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a>        <span class="n">attn_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a>        <span class="n">key_padding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>        <span class="n">need_weights</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>        <span class="n">gradient_checkpoint</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a>        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Pass the input through the encoder layers in turn.</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a><span class="sd">            src: the sequence to the encoder (required).</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a><span class="sd">            attn_mask: the mask for the src sequence (optional).</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a><span class="sd">            key_padding_mask: the mask for the src keys per batch (optional).</span>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a><span class="sd">        Shape:</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a><span class="sd">            see the docs in Transformer class.</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a>        <span class="n">output</span> <span class="o">=</span> <span class="n">src</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a>        <span class="c1"># attn_weights is set to torch.empty(0, requires_grad=False) to avoid errors in DDP</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a>        <span class="n">attn_weights</span> <span class="o">=</span> <span class="p">[]</span> <span class="k">if</span> <span class="n">need_weights</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a>        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a>            <span class="k">if</span> <span class="n">gradient_checkpoint</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a>                <span class="n">layer</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">layer</span><span class="p">)</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a>                <span class="n">need_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">need_weights</span><span class="p">)</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a>            <span class="n">output</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">attn_bias</span><span class="p">,</span> <span class="n">attn_mask</span><span class="p">,</span> <span class="n">key_padding_mask</span><span class="p">,</span> <span class="n">need_weights</span><span class="p">)</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a>            <span class="k">if</span> <span class="n">need_weights</span><span class="p">:</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a>                <span class="n">attn_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a>        <span class="k">if</span> <span class="n">need_weights</span><span class="p">:</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a>            <span class="n">attn_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">attn_weights</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>  <span class="c1"># type: ignore</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a>        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">attn_weights</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h3 id="danling.models.transformer.encoder.TransformerEncoder.forward" class="doc doc-heading">
<code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">attn_bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attn_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">key_padding_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">need_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">gradient_checkpoint</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#danling.models.transformer.encoder.TransformerEncoder.forward" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Pass the input through the encoder layers in turn.
Args:
    src: the sequence to the encoder (required).
    attn_mask: the mask for the src sequence (optional).
    key_padding_mask: the mask for the src keys per batch (optional).
Shape:
    see the docs in Transformer class.</p>

      <details class="quote">
        <summary>Source code in <code>danling/models/transformer/encoder.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-141" name="__codelineno-0-141"></a><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>    <span class="n">src</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a>    <span class="n">attn_bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a>    <span class="n">attn_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a>    <span class="n">key_padding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>    <span class="n">need_weights</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>    <span class="n">gradient_checkpoint</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Pass the input through the encoder layers in turn.</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a><span class="sd">        src: the sequence to the encoder (required).</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a><span class="sd">        attn_mask: the mask for the src sequence (optional).</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a><span class="sd">        key_padding_mask: the mask for the src keys per batch (optional).</span>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a><span class="sd">    Shape:</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a><span class="sd">        see the docs in Transformer class.</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a>    <span class="n">output</span> <span class="o">=</span> <span class="n">src</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a>    <span class="c1"># attn_weights is set to torch.empty(0, requires_grad=False) to avoid errors in DDP</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a>    <span class="n">attn_weights</span> <span class="o">=</span> <span class="p">[]</span> <span class="k">if</span> <span class="n">need_weights</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a>    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a>        <span class="k">if</span> <span class="n">gradient_checkpoint</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a>            <span class="n">layer</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">layer</span><span class="p">)</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a>            <span class="n">need_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">need_weights</span><span class="p">)</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a>        <span class="n">output</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">attn_bias</span><span class="p">,</span> <span class="n">attn_mask</span><span class="p">,</span> <span class="n">key_padding_mask</span><span class="p">,</span> <span class="n">need_weights</span><span class="p">)</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a>        <span class="k">if</span> <span class="n">need_weights</span><span class="p">:</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a>            <span class="n">attn_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a>    <span class="k">if</span> <span class="n">need_weights</span><span class="p">:</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a>        <span class="n">attn_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">attn_weights</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>  <span class="c1"># type: ignore</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a>    <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">attn_weights</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="danling.TransformerEncoderLayer" class="doc doc-heading">
        <code>TransformerEncoderLayer</code>


<a href="#danling.TransformerEncoderLayer" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
      <p class="doc doc-class-bases">
        Bases: <code><span title="torch.nn">nn</span>.<span title="torch.nn.Module">Module</span></code></p>

  
      <p>TransformerEncoderLayer is made up of self-attn and feedforward network.
This standard encoder layer is based on the paper &ldquo;Attention Is All You Need&rdquo;.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in
Neural Information Processing Systems, pages 6000-6010. Users may modify or implement
in a different way during application.
Args:
    embed_dim: the number of expected features in the input (required).
    num_heads: the number of heads in the multi head attention models (required).
    ffn_dim: the dimension of the feedforward network model (default=embed_dim*4).
    dropout: the dropout value (default=0.1).
    activation: the activation function of intermediate layer, relu or gelu (default=relu).
    layer_norm_eps: the eps value in layer normalization components (default=1e-5).
    batch_first: If <code>True</code>, then the input and output tensors are provided
        as (batch, seq, feature). Default: <code>False</code>.
    norm_first: if <code>True</code>, layer norm is done prior to attention and feedforward
        operations, respectivaly. Otherwise it&rsquo;s done after. Default: <code>False</code> (after).
Examples::
    &gt;&gt;&gt; encoder_layer = nn.TransformerEncoderLayer(embed_dim=512, num_heads=8)
    &gt;&gt;&gt; src = torch.rand(10, 32, 512)
    &gt;&gt;&gt; out = encoder_layer(src)
Alternatively, when <code>batch_first</code> is <code>True</code>:
    &gt;&gt;&gt; encoder_layer = nn.TransformerEncoderLayer(embed_dim=512, num_heads=8, batch_first=True)
    &gt;&gt;&gt; src = torch.rand(32, 10, 512)
    &gt;&gt;&gt; out = encoder_layer(src)</p>


        <details class="quote">
          <summary>Source code in <code>danling/models/transformer/encoder.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-12"> 12</a></span>
<span class="normal"><a href="#__codelineno-0-13"> 13</a></span>
<span class="normal"><a href="#__codelineno-0-14"> 14</a></span>
<span class="normal"><a href="#__codelineno-0-15"> 15</a></span>
<span class="normal"><a href="#__codelineno-0-16"> 16</a></span>
<span class="normal"><a href="#__codelineno-0-17"> 17</a></span>
<span class="normal"><a href="#__codelineno-0-18"> 18</a></span>
<span class="normal"><a href="#__codelineno-0-19"> 19</a></span>
<span class="normal"><a href="#__codelineno-0-20"> 20</a></span>
<span class="normal"><a href="#__codelineno-0-21"> 21</a></span>
<span class="normal"><a href="#__codelineno-0-22"> 22</a></span>
<span class="normal"><a href="#__codelineno-0-23"> 23</a></span>
<span class="normal"><a href="#__codelineno-0-24"> 24</a></span>
<span class="normal"><a href="#__codelineno-0-25"> 25</a></span>
<span class="normal"><a href="#__codelineno-0-26"> 26</a></span>
<span class="normal"><a href="#__codelineno-0-27"> 27</a></span>
<span class="normal"><a href="#__codelineno-0-28"> 28</a></span>
<span class="normal"><a href="#__codelineno-0-29"> 29</a></span>
<span class="normal"><a href="#__codelineno-0-30"> 30</a></span>
<span class="normal"><a href="#__codelineno-0-31"> 31</a></span>
<span class="normal"><a href="#__codelineno-0-32"> 32</a></span>
<span class="normal"><a href="#__codelineno-0-33"> 33</a></span>
<span class="normal"><a href="#__codelineno-0-34"> 34</a></span>
<span class="normal"><a href="#__codelineno-0-35"> 35</a></span>
<span class="normal"><a href="#__codelineno-0-36"> 36</a></span>
<span class="normal"><a href="#__codelineno-0-37"> 37</a></span>
<span class="normal"><a href="#__codelineno-0-38"> 38</a></span>
<span class="normal"><a href="#__codelineno-0-39"> 39</a></span>
<span class="normal"><a href="#__codelineno-0-40"> 40</a></span>
<span class="normal"><a href="#__codelineno-0-41"> 41</a></span>
<span class="normal"><a href="#__codelineno-0-42"> 42</a></span>
<span class="normal"><a href="#__codelineno-0-43"> 43</a></span>
<span class="normal"><a href="#__codelineno-0-44"> 44</a></span>
<span class="normal"><a href="#__codelineno-0-45"> 45</a></span>
<span class="normal"><a href="#__codelineno-0-46"> 46</a></span>
<span class="normal"><a href="#__codelineno-0-47"> 47</a></span>
<span class="normal"><a href="#__codelineno-0-48"> 48</a></span>
<span class="normal"><a href="#__codelineno-0-49"> 49</a></span>
<span class="normal"><a href="#__codelineno-0-50"> 50</a></span>
<span class="normal"><a href="#__codelineno-0-51"> 51</a></span>
<span class="normal"><a href="#__codelineno-0-52"> 52</a></span>
<span class="normal"><a href="#__codelineno-0-53"> 53</a></span>
<span class="normal"><a href="#__codelineno-0-54"> 54</a></span>
<span class="normal"><a href="#__codelineno-0-55"> 55</a></span>
<span class="normal"><a href="#__codelineno-0-56"> 56</a></span>
<span class="normal"><a href="#__codelineno-0-57"> 57</a></span>
<span class="normal"><a href="#__codelineno-0-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-0-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-0-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-0-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-0-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-0-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-0-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-0-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-0-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-0-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-0-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-0-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-0-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-0-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="k">class</span> <span class="nc">TransformerEncoderLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;TransformerEncoderLayer is made up of self-attn and feedforward network.</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a><span class="sd">    This standard encoder layer is based on the paper &quot;Attention Is All You Need&quot;.</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a><span class="sd">    Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a><span class="sd">    Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a><span class="sd">    Neural Information Processing Systems, pages 6000-6010. Users may modify or implement</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a><span class="sd">    in a different way during application.</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a><span class="sd">        embed_dim: the number of expected features in the input (required).</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a><span class="sd">        num_heads: the number of heads in the multi head attention models (required).</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a><span class="sd">        ffn_dim: the dimension of the feedforward network model (default=embed_dim*4).</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a><span class="sd">        dropout: the dropout value (default=0.1).</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a><span class="sd">        activation: the activation function of intermediate layer, relu or gelu (default=relu).</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a><span class="sd">        layer_norm_eps: the eps value in layer normalization components (default=1e-5).</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a><span class="sd">        batch_first: If ``True``, then the input and output tensors are provided</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a><span class="sd">            as (batch, seq, feature). Default: ``False``.</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a><span class="sd">        norm_first: if ``True``, layer norm is done prior to attention and feedforward</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a><span class="sd">            operations, respectivaly. Otherwise it&#39;s done after. Default: ``False`` (after).</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a><span class="sd">    Examples::</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="sd">        &gt;&gt;&gt; encoder_layer = nn.TransformerEncoderLayer(embed_dim=512, num_heads=8)</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a><span class="sd">        &gt;&gt;&gt; src = torch.rand(10, 32, 512)</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a><span class="sd">        &gt;&gt;&gt; out = encoder_layer(src)</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a><span class="sd">    Alternatively, when ``batch_first`` is ``True``:</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a><span class="sd">        &gt;&gt;&gt; encoder_layer = nn.TransformerEncoderLayer(embed_dim=512, num_heads=8, batch_first=True)</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a><span class="sd">        &gt;&gt;&gt; src = torch.rand(32, 10, 512)</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a><span class="sd">        &gt;&gt;&gt; out = encoder_layer(src)</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>    <span class="n">__constants__</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;batch_first&quot;</span><span class="p">,</span> <span class="s2">&quot;norm_first&quot;</span><span class="p">]</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a>        <span class="n">embed_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>        <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a>        <span class="n">ffn_dim</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>        <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>        <span class="n">attn_dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>        <span class="n">ffn_dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a>        <span class="n">activation</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;GELU&quot;</span><span class="p">,</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a>        <span class="n">layer_norm_eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">,</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a>        <span class="n">scale_factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>        <span class="n">bias</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a>        <span class="n">add_bias_kv</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a>        <span class="n">add_zero_attn</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>        <span class="n">batch_first</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a>        <span class="n">norm_first</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a>        <span class="n">Attention</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">,</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a>        <span class="n">FeedForwardNetwork</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">FullyConnectedNetwork</span><span class="p">,</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a>        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a>        <span class="k">if</span> <span class="n">ffn_dim</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a>            <span class="n">ffn_dim</span> <span class="o">=</span> <span class="n">embed_dim</span> <span class="o">*</span> <span class="mi">4</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">norm_first</span> <span class="o">=</span> <span class="n">norm_first</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">Attention</span><span class="p">(</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a>            <span class="n">embed_dim</span><span class="p">,</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a>            <span class="n">num_heads</span><span class="p">,</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>            <span class="n">attn_dropout</span><span class="o">=</span><span class="n">attn_dropout</span><span class="p">,</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>            <span class="n">scale_factor</span><span class="o">=</span><span class="n">scale_factor</span><span class="p">,</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a>            <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>            <span class="n">add_bias_kv</span><span class="o">=</span><span class="n">add_bias_kv</span><span class="p">,</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>            <span class="n">add_zero_attn</span><span class="o">=</span><span class="n">add_zero_attn</span><span class="p">,</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>            <span class="n">batch_first</span><span class="o">=</span><span class="n">batch_first</span><span class="p">,</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>            <span class="o">**</span><span class="n">kwargs</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>        <span class="p">)</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="n">layer_norm_eps</span><span class="p">)</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span> <span class="o">=</span> <span class="n">FeedForwardNetwork</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">ffn_dim</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span> <span class="n">ffn_dropout</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="n">layer_norm_eps</span><span class="p">)</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>        <span class="n">src</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>        <span class="n">attn_bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>        <span class="n">attn_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>        <span class="n">key_padding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>        <span class="n">need_weights</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Pass the input through the encoder layer.</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a><span class="sd">        Args:</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a><span class="sd">            src: the sequence to the encoder layer (required).</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a><span class="sd">            attn_mask: the mask for the src sequence (optional).</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a><span class="sd">            key_padding_mask: the mask for the src keys per batch (optional).</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a><span class="sd">        Shape:</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a><span class="sd">            see the docs in Transformer class.</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_first</span><span class="p">:</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>            <span class="n">src</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>        <span class="n">attn</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>            <span class="n">src</span><span class="p">,</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>            <span class="n">src</span><span class="p">,</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>            <span class="n">src</span><span class="p">,</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>            <span class="n">attn_bias</span><span class="o">=</span><span class="n">attn_bias</span><span class="p">,</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>            <span class="n">attn_mask</span><span class="o">=</span><span class="n">attn_mask</span><span class="p">,</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>            <span class="n">key_padding_mask</span><span class="o">=</span><span class="n">key_padding_mask</span><span class="p">,</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>            <span class="n">need_weights</span><span class="o">=</span><span class="n">need_weights</span><span class="p">,</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>        <span class="p">)</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>        <span class="n">attn</span> <span class="o">=</span> <span class="n">src</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">attn</span><span class="p">)</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>        <span class="n">attn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">attn</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_first</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">attn</span><span class="p">)</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>        <span class="n">ffn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span><span class="p">(</span><span class="n">attn</span><span class="p">)</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>        <span class="n">ffn</span> <span class="o">=</span> <span class="n">attn</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">ffn</span><span class="p">)</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_first</span><span class="p">:</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>            <span class="n">ffn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">ffn</span><span class="p">)</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>        <span class="k">return</span> <span class="n">ffn</span><span class="p">,</span> <span class="n">weights</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">









<div class="doc doc-object doc-function">



<h3 id="danling.models.transformer.encoder.TransformerEncoderLayer.forward" class="doc doc-heading">
<code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">attn_bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attn_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">key_padding_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">need_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#danling.models.transformer.encoder.TransformerEncoderLayer.forward" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Pass the input through the encoder layer.
Args:
    src: the sequence to the encoder layer (required).
    attn_mask: the mask for the src sequence (optional).
    key_padding_mask: the mask for the src keys per batch (optional).
Shape:
    see the docs in Transformer class.</p>

      <details class="quote">
        <summary>Source code in <code>danling/models/transformer/encoder.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-81" name="__codelineno-0-81"></a><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>    <span class="n">src</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>    <span class="n">attn_bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>    <span class="n">attn_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>    <span class="n">key_padding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>    <span class="n">need_weights</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Pass the input through the encoder layer.</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a><span class="sd">        src: the sequence to the encoder layer (required).</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a><span class="sd">        attn_mask: the mask for the src sequence (optional).</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a><span class="sd">        key_padding_mask: the mask for the src keys per batch (optional).</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a><span class="sd">    Shape:</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a><span class="sd">        see the docs in Transformer class.</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_first</span><span class="p">:</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>        <span class="n">src</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>    <span class="n">attn</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>        <span class="n">src</span><span class="p">,</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>        <span class="n">src</span><span class="p">,</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>        <span class="n">src</span><span class="p">,</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>        <span class="n">attn_bias</span><span class="o">=</span><span class="n">attn_bias</span><span class="p">,</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>        <span class="n">attn_mask</span><span class="o">=</span><span class="n">attn_mask</span><span class="p">,</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>        <span class="n">key_padding_mask</span><span class="o">=</span><span class="n">key_padding_mask</span><span class="p">,</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>        <span class="n">need_weights</span><span class="o">=</span><span class="n">need_weights</span><span class="p">,</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>    <span class="p">)</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>    <span class="n">attn</span> <span class="o">=</span> <span class="n">src</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">attn</span><span class="p">)</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>    <span class="n">attn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">attn</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_first</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">attn</span><span class="p">)</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>    <span class="n">ffn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span><span class="p">(</span><span class="n">attn</span><span class="p">)</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>    <span class="n">ffn</span> <span class="o">=</span> <span class="n">attn</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">ffn</span><span class="p">)</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_first</span><span class="p">:</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>        <span class="n">ffn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">ffn</span><span class="p">)</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>    <span class="k">return</span> <span class="n">ffn</span><span class="p">,</span> <span class="n">weights</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="danling.UnitedPositionEmbedding" class="doc doc-heading">
        <code>UnitedPositionEmbedding</code>


<a href="#danling.UnitedPositionEmbedding" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
      <p class="doc doc-class-bases">
        Bases: <code><span title="torch.nn">nn</span>.<span title="torch.nn.Module">Module</span></code></p>

  
      <p>United Position Embedding
See <code>Rethinking Positional Encoding in Language Pre-training &lt;https://arxiv.org/abs/2006.15595&gt;</code>_
.. math::
    \text{MultiHead}(Q, K, V) = \text{Concat}(head_1,\dots,head_h)W^O
where :math:<code>head_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)</code>.
Args:
    embed_dim: total dimension of the model.
    num_heads: parallel attention heads.
    dropout: a Dropout layer on attn_output_weights. Default: 0.0.
    bias: add bias as module parameter. Default: True.
    add_bias_kv: add bias to the key and value sequences at dim=0.
    add_zero_attn: add a new batch of zeros to the key and
                   value sequences at dim=1.
    k_dim: total number of features in key. Default: None.
    v_dim: total number of features in value. Default: None.
    batch_first: If <code>True</code>, then the input and output tensors are provided
        as (batch, seq, feature). Default: <code>False</code> (seq, batch, feature).
Note that if :attr:<code>k_dim</code> and :attr:<code>v_dim</code> are None, they will be set
to :attr:<code>embed_dim</code> such that query, key, and value have the same
number of features.
Examples::
    &gt;&gt;&gt; multihead_attn = nn.MultiheadAttention(embed_dim, num_heads)
    &gt;&gt;&gt; attn_output, attn_output_weights = multihead_attn(query, key, value)</p>


        <details class="quote">
          <summary>Source code in <code>danling/models/transformer/pos_embed/pos_embed.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-43"> 43</a></span>
<span class="normal"><a href="#__codelineno-0-44"> 44</a></span>
<span class="normal"><a href="#__codelineno-0-45"> 45</a></span>
<span class="normal"><a href="#__codelineno-0-46"> 46</a></span>
<span class="normal"><a href="#__codelineno-0-47"> 47</a></span>
<span class="normal"><a href="#__codelineno-0-48"> 48</a></span>
<span class="normal"><a href="#__codelineno-0-49"> 49</a></span>
<span class="normal"><a href="#__codelineno-0-50"> 50</a></span>
<span class="normal"><a href="#__codelineno-0-51"> 51</a></span>
<span class="normal"><a href="#__codelineno-0-52"> 52</a></span>
<span class="normal"><a href="#__codelineno-0-53"> 53</a></span>
<span class="normal"><a href="#__codelineno-0-54"> 54</a></span>
<span class="normal"><a href="#__codelineno-0-55"> 55</a></span>
<span class="normal"><a href="#__codelineno-0-56"> 56</a></span>
<span class="normal"><a href="#__codelineno-0-57"> 57</a></span>
<span class="normal"><a href="#__codelineno-0-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-0-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-0-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-0-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-0-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-0-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-0-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-0-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-0-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-0-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-0-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-0-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-0-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-0-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-43" name="__codelineno-0-43"></a><span class="k">class</span> <span class="nc">UnitedPositionEmbedding</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;United Position Embedding</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a><span class="sd">    See `Rethinking Positional Encoding in Language Pre-training &lt;https://arxiv.org/abs/2006.15595&gt;`_</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a><span class="sd">    .. math::</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a><span class="sd">        \text{MultiHead}(Q, K, V) = \text{Concat}(head_1,\dots,head_h)W^O</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a><span class="sd">    where :math:`head_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)`.</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">        embed_dim: total dimension of the model.</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="sd">        num_heads: parallel attention heads.</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a><span class="sd">        dropout: a Dropout layer on attn_output_weights. Default: 0.0.</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a><span class="sd">        bias: add bias as module parameter. Default: True.</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="sd">        add_bias_kv: add bias to the key and value sequences at dim=0.</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a><span class="sd">        add_zero_attn: add a new batch of zeros to the key and</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="sd">                       value sequences at dim=1.</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a><span class="sd">        k_dim: total number of features in key. Default: None.</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a><span class="sd">        v_dim: total number of features in value. Default: None.</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a><span class="sd">        batch_first: If ``True``, then the input and output tensors are provided</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="sd">            as (batch, seq, feature). Default: ``False`` (seq, batch, feature).</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a><span class="sd">    Note that if :attr:`k_dim` and :attr:`v_dim` are None, they will be set</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">    to :attr:`embed_dim` such that query, key, and value have the same</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a><span class="sd">    number of features.</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a><span class="sd">    Examples::</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a><span class="sd">        &gt;&gt;&gt; multihead_attn = nn.MultiheadAttention(embed_dim, num_heads)</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a><span class="sd">        &gt;&gt;&gt; attn_output, attn_output_weights = multihead_attn(query, key, value)</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>        <span class="n">embed_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>        <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>        <span class="n">seq_len_max</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>        <span class="n">rel_pos_embed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>        <span class="n">rel_pos_embed_buckets</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>        <span class="n">rel_pos_embed_max</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>        <span class="n">pos_embed_dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>        <span class="n">pos_scale_factor</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>        <span class="n">has_cls_token</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span> <span class="o">=</span> <span class="n">embed_dim</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">seq_len_max</span> <span class="o">=</span> <span class="n">seq_len_max</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">has_cls_token</span> <span class="o">=</span> <span class="n">has_cls_token</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">pos_embed_dropout</span><span class="p">)</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_cls_token</span><span class="p">:</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>            <span class="c1"># make room for [CLS]-to-others and others-to-[CLS]</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">seq_len_max</span> <span class="o">+=</span> <span class="mi">2</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">abs_pos_embed</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seq_len_max</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">))</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">ln</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">)</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">scaling</span> <span class="o">=</span> <span class="p">(</span><span class="n">embed_dim</span> <span class="o">/</span> <span class="n">num_heads</span> <span class="o">*</span> <span class="n">pos_scale_factor</span><span class="p">)</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">rel_pos_embed</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a>        <span class="k">if</span> <span class="n">rel_pos_embed</span><span class="p">:</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a>            <span class="k">assert</span> <span class="n">rel_pos_embed_buckets</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">rel_pos_embed_buckets</span> <span class="o">=</span> <span class="n">rel_pos_embed_buckets</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">rel_pos_embed_max</span> <span class="o">=</span> <span class="n">rel_pos_embed_max</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">rel_pos_embed</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rel_pos_embed_buckets</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">)</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">rel_pos_embed_bucket</span> <span class="o">=</span> <span class="n">relative_position_bucket</span><span class="p">(</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>                <span class="n">seq_len_max</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seq_len_max</span><span class="p">,</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>                <span class="n">num_buckets</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rel_pos_embed_buckets</span><span class="p">,</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>                <span class="n">max_distance</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rel_pos_embed_max</span><span class="p">,</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>            <span class="p">)</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">cls_token_index</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>        <span class="n">B</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="n">src</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>        <span class="c1"># 0 is for others-to-[CLS] 1 is for [CLS]-to-others</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>        <span class="c1"># Assume the input is ordered. If your input token is permuted, you may need to update this accordingly</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_cls_token</span><span class="p">:</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>            <span class="c1"># only plus 1 here since because [CLS] already plused 1</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>            <span class="n">N</span> <span class="o">+=</span> <span class="mi">1</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>        <span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ln</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">abs_pos_embed</span><span class="p">[:</span><span class="n">N</span><span class="p">,</span> <span class="p">:])</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>        <span class="n">q</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_proj</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">C</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>        <span class="n">q</span> <span class="o">=</span> <span class="n">q</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaling</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>        <span class="n">pos_embed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_cls_token</span><span class="p">:</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>            <span class="c1"># p_0 \dot p_0 is [CLS]-to-others</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>            <span class="n">cls_2_others</span> <span class="o">=</span> <span class="n">pos_embed</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a>            <span class="c1"># p_1 \dot p_1 is others-to-[CLS]</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>            <span class="n">others_2_cls</span> <span class="o">=</span> <span class="n">pos_embed</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a>            <span class="c1"># offset</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>            <span class="n">pos_embed</span> <span class="o">=</span> <span class="n">pos_embed</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:,</span> <span class="mi">1</span><span class="p">:]</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a>            <span class="c1"># if [CLS] is not the first token</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a>            <span class="k">if</span> <span class="n">cls_token_index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a>                <span class="n">pos_embed</span> <span class="o">=</span> <span class="n">pos_embed</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a>                <span class="n">pos_embed</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">B</span><span class="p">),</span> <span class="p">:,</span> <span class="n">cls_token_index</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">cls_2_others</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>                <span class="n">pos_embed</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">B</span><span class="p">),</span> <span class="p">:,</span> <span class="p">:,</span> <span class="n">cls_token_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">others_2_cls</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a>                <span class="n">pos_embed</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">cls_2_others</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>                <span class="n">pos_embed</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">others_2_cls</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>            <span class="n">N</span> <span class="o">-=</span> <span class="mi">1</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a>        <span class="n">rel_pos_embed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">pos_embed</span><span class="p">)</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rel_pos_embed</span><span class="p">:</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>            <span class="n">rel_pos_embed_bucket</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rel_pos_embed_bucket</span><span class="p">[:</span><span class="n">N</span><span class="p">,</span> <span class="p">:</span><span class="n">N</span><span class="p">]</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_cls_token</span><span class="p">:</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>                <span class="k">if</span> <span class="n">cls_token_index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>                    <span class="n">rel_pos_embed_bucket</span> <span class="o">=</span> <span class="n">rel_pos_embed_bucket</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>                    <span class="n">rel_pos_embed_bucket</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">B</span><span class="p">),</span> <span class="n">cls_token_index</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rel_pos_embed_buckets</span> <span class="o">//</span> <span class="mi">2</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>                    <span class="n">rel_pos_embed_bucket</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">B</span><span class="p">),</span> <span class="p">:,</span> <span class="n">cls_token_index</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rel_pos_embed_buckets</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>                    <span class="n">rel_pos_embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rel_pos_embed</span><span class="p">(</span><span class="n">rel_pos_embed_bucket</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>                <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a>                    <span class="n">rel_pos_embed_bucket</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rel_pos_embed_buckets</span> <span class="o">//</span> <span class="mi">2</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a>                    <span class="n">rel_pos_embed_bucket</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rel_pos_embed_buckets</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a>                    <span class="n">rel_pos_embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rel_pos_embed</span><span class="p">(</span><span class="n">rel_pos_embed_bucket</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>                <span class="n">rel_pos_embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rel_pos_embed</span><span class="p">(</span><span class="n">rel_pos_embed_bucket</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a>            <span class="n">pos_embed</span> <span class="o">+=</span> <span class="n">rel_pos_embed</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a>        <span class="n">pos_embed</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a>            <span class="n">pos_embed</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">pos_embed</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span> <span class="k">if</span> <span class="n">cls_token_index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">pos_embed</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a>        <span class="p">)</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">pos_embed</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">











  </div>

  </div>

</div>


<div class="doc doc-object doc-function">



<h2 id="danling.catch" class="doc doc-heading">
<code class="highlight language-python"><span class="n">catch</span><span class="p">(</span><span class="n">error</span><span class="o">=</span><span class="ne">Exception</span><span class="p">,</span> <span class="n">exclude</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">print_args</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#danling.catch" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
  
      <p>Decorator to catch <code>error</code> except for <code>exclude</code>.
Detailed traceback will be printed to <code>stdout</code>.</p>
<p><code>catch</code> is extremely useful for unfatal errors.
For example, <code>Runner</code> by de</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>error</code></td>
          <td>
                <code>Exception</code>
          </td>
          <td></td>
          <td>
                <code>Exception</code>
          </td>
        </tr>
        <tr>
          <td><code>exclude</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[Exception]</code>
          </td>
          <td></td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>print_args</code></td>
          <td>
                <code>bool</code>
          </td>
          <td><p>Whether to print the arguments passed to the function.</p></td>
          <td>
                <code>False</code>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>danling/utils/decorator.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-47">47</a></span>
<span class="normal"><a href="#__codelineno-0-48">48</a></span>
<span class="normal"><a href="#__codelineno-0-49">49</a></span>
<span class="normal"><a href="#__codelineno-0-50">50</a></span>
<span class="normal"><a href="#__codelineno-0-51">51</a></span>
<span class="normal"><a href="#__codelineno-0-52">52</a></span>
<span class="normal"><a href="#__codelineno-0-53">53</a></span>
<span class="normal"><a href="#__codelineno-0-54">54</a></span>
<span class="normal"><a href="#__codelineno-0-55">55</a></span>
<span class="normal"><a href="#__codelineno-0-56">56</a></span>
<span class="normal"><a href="#__codelineno-0-57">57</a></span>
<span class="normal"><a href="#__codelineno-0-58">58</a></span>
<span class="normal"><a href="#__codelineno-0-59">59</a></span>
<span class="normal"><a href="#__codelineno-0-60">60</a></span>
<span class="normal"><a href="#__codelineno-0-61">61</a></span>
<span class="normal"><a href="#__codelineno-0-62">62</a></span>
<span class="normal"><a href="#__codelineno-0-63">63</a></span>
<span class="normal"><a href="#__codelineno-0-64">64</a></span>
<span class="normal"><a href="#__codelineno-0-65">65</a></span>
<span class="normal"><a href="#__codelineno-0-66">66</a></span>
<span class="normal"><a href="#__codelineno-0-67">67</a></span>
<span class="normal"><a href="#__codelineno-0-68">68</a></span>
<span class="normal"><a href="#__codelineno-0-69">69</a></span>
<span class="normal"><a href="#__codelineno-0-70">70</a></span>
<span class="normal"><a href="#__codelineno-0-71">71</a></span>
<span class="normal"><a href="#__codelineno-0-72">72</a></span>
<span class="normal"><a href="#__codelineno-0-73">73</a></span>
<span class="normal"><a href="#__codelineno-0-74">74</a></span>
<span class="normal"><a href="#__codelineno-0-75">75</a></span>
<span class="normal"><a href="#__codelineno-0-76">76</a></span>
<span class="normal"><a href="#__codelineno-0-77">77</a></span>
<span class="normal"><a href="#__codelineno-0-78">78</a></span>
<span class="normal"><a href="#__codelineno-0-79">79</a></span>
<span class="normal"><a href="#__codelineno-0-80">80</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-47" name="__codelineno-0-47"></a><span class="nd">@flexible_decorator</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a><span class="k">def</span> <span class="nf">catch</span><span class="p">(</span><span class="n">error</span><span class="p">:</span> <span class="ne">Exception</span> <span class="o">=</span> <span class="ne">Exception</span><span class="p">,</span> <span class="n">exclude</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="ne">Exception</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">print_args</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a>    <span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">    Decorator to catch `error` except for `exclude`.</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="sd">    Detailed traceback will be printed to `stdout`.</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a><span class="sd">    `catch` is extremely useful for unfatal errors.</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="sd">    For example, `Runner` by de</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a><span class="sd">    error: Exception</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a><span class="sd">    exclude: Optional[Exception] = None</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="sd">    print_args: bool = False</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a><span class="sd">        Whether to print the arguments passed to the function.</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a>    <span class="k">def</span> <span class="nf">decorator</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">error</span><span class="p">:</span> <span class="ne">Exception</span> <span class="o">=</span> <span class="ne">Exception</span><span class="p">,</span> <span class="n">exclude</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="ne">Exception</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">print_args</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a>        <span class="nd">@wraps</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a>        <span class="k">def</span> <span class="nf">wrapper</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>  <span class="c1"># pylint: disable=R1710</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a>            <span class="k">try</span><span class="p">:</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>                <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>            <span class="k">except</span> <span class="n">error</span> <span class="k">as</span> <span class="n">exc</span><span class="p">:</span>  <span class="c1"># pylint: disable=W0703</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a>                <span class="k">if</span> <span class="n">exclude</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">exc</span><span class="p">,</span> <span class="n">exclude</span><span class="p">):</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>                    <span class="k">raise</span> <span class="n">exc</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>                <span class="n">message</span> <span class="o">=</span> <span class="n">format_exc</span><span class="p">()</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>                <span class="n">message</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">encoutered when calling </span><span class="si">{</span><span class="n">func</span><span class="si">}</span><span class="s2">&quot;</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>                <span class="k">if</span> <span class="n">print_args</span><span class="p">:</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>                    <span class="n">message</span> <span class="o">+=</span> <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;with args </span><span class="si">{</span><span class="n">args</span><span class="si">}</span><span class="s2"> and kwargs </span><span class="si">{</span><span class="n">kwargs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,)</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>                <span class="nb">print</span><span class="p">(</span><span class="n">message</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><span class="n">stderr</span><span class="p">,</span> <span class="n">force</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>        <span class="k">return</span> <span class="n">wrapper</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a>    <span class="k">return</span> <span class="k">lambda</span> <span class="n">func</span><span class="p">:</span> <span class="n">decorator</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">error</span><span class="p">,</span> <span class="n">exclude</span><span class="p">,</span> <span class="n">print_args</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h2 id="danling.load" class="doc doc-heading">
<code class="highlight language-python"><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#danling.load" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
  
      <p>Load any file with supported extensions.</p>

      <details class="quote">
        <summary>Source code in <code>danling/utils/io.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-27">27</a></span>
<span class="normal"><a href="#__codelineno-0-28">28</a></span>
<span class="normal"><a href="#__codelineno-0-29">29</a></span>
<span class="normal"><a href="#__codelineno-0-30">30</a></span>
<span class="normal"><a href="#__codelineno-0-31">31</a></span>
<span class="normal"><a href="#__codelineno-0-32">32</a></span>
<span class="normal"><a href="#__codelineno-0-33">33</a></span>
<span class="normal"><a href="#__codelineno-0-34">34</a></span>
<span class="normal"><a href="#__codelineno-0-35">35</a></span>
<span class="normal"><a href="#__codelineno-0-36">36</a></span>
<span class="normal"><a href="#__codelineno-0-37">37</a></span>
<span class="normal"><a href="#__codelineno-0-38">38</a></span>
<span class="normal"><a href="#__codelineno-0-39">39</a></span>
<span class="normal"><a href="#__codelineno-0-40">40</a></span>
<span class="normal"><a href="#__codelineno-0-41">41</a></span>
<span class="normal"><a href="#__codelineno-0-42">42</a></span>
<span class="normal"><a href="#__codelineno-0-43">43</a></span>
<span class="normal"><a href="#__codelineno-0-44">44</a></span>
<span class="normal"><a href="#__codelineno-0-45">45</a></span>
<span class="normal"><a href="#__codelineno-0-46">46</a></span>
<span class="normal"><a href="#__codelineno-0-47">47</a></span>
<span class="normal"><a href="#__codelineno-0-48">48</a></span>
<span class="normal"><a href="#__codelineno-0-49">49</a></span>
<span class="normal"><a href="#__codelineno-0-50">50</a></span>
<span class="normal"><a href="#__codelineno-0-51">51</a></span>
<span class="normal"><a href="#__codelineno-0-52">52</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-27" name="__codelineno-0-27"></a><span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a>    <span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a><span class="sd">    Load any file with supported extensions.</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Trying to load </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2"> but it is not a file.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a>    <span class="n">extension</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">splitext</span><span class="p">(</span><span class="n">path</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()[</span><span class="mi">1</span><span class="p">:]</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a>    <span class="k">if</span> <span class="n">extension</span> <span class="ow">in</span> <span class="n">PYTORCH</span><span class="p">:</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a>        <span class="k">if</span> <span class="n">torch_load</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a>            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Trying to load </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2"> but torch is not installed.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a>        <span class="k">return</span> <span class="n">torch_load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a>    <span class="k">if</span> <span class="n">extension</span> <span class="ow">in</span> <span class="n">NUMPY</span><span class="p">:</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>        <span class="k">if</span> <span class="n">numpy_load</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a>            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Trying to load </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2"> but numpy is not installed.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>        <span class="k">return</span> <span class="n">numpy_load</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">allow_pickle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a>    <span class="k">if</span> <span class="n">extension</span> <span class="ow">in</span> <span class="n">CSV</span><span class="p">:</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a>        <span class="k">if</span> <span class="n">read_csv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Trying to load </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2"> but pandas is not installed.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a>        <span class="k">return</span> <span class="n">read_csv</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>    <span class="k">if</span> <span class="n">extension</span> <span class="ow">in</span> <span class="n">JSON</span><span class="p">:</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>  <span class="c1"># pylint: disable=W1514, C0103</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>            <span class="k">return</span> <span class="n">json_load</span><span class="p">(</span><span class="n">fp</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a>    <span class="k">if</span> <span class="n">extension</span> <span class="ow">in</span> <span class="n">PICKLE</span><span class="p">:</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>  <span class="c1"># pylint: disable=C0103</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a>            <span class="k">return</span> <span class="n">pickle_load</span><span class="p">(</span><span class="n">fp</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tying to load </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2"> with unsupported extension=</span><span class="si">{</span><span class="n">extension</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>



  </div>

  </div>

</div>

  
    
  
  


  <aside class="md-source-file">
    
      <span class="md-source-file__fact">
        <span class="md-icon" title="最后更新">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1-2.1-2M12.5 7v5.2l4 2.4-1 1L11 13V7h1.5M11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2v1.8Z"/></svg>
        </span>
        <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_datetime">2023-01-18 15:53:59</span>
      </span>
    
    
    
    
  </aside>


  




                

<!-- Giscus -->
<script
  src="https://giscus.app/client.js"
  data-repo="ZhiyuanChen/DanLing"
  data-repo-id="R_kgDOGv-RWA"
  data-category="General"
  data-category-id="DIC_kwDOGv-RWM4CTx_d"
  data-mapping="pathname"
  data-strict="0"
  data-reactions-enabled="1"
  data-emit-metadata="1"
  data-input-position="top"
  data-theme="preferred_color_scheme"
  data-lang="en"
  data-loading="lazy"
  crossorigin="anonymous"
  async
></script>

<!-- Reload on palette change -->
<script>
  var palette = __md_get("__palette");
  if (palette && typeof palette.color === "object")
    if (palette.color.scheme === "slate") {
      var giscus = document.querySelector("script[src*=giscus]");
      giscus.setAttribute("data-theme", "dark");
    }

  /* Register event handlers after documented loaded */
  document.addEventListener("DOMContentLoaded", function () {
    var ref = document.querySelector("[data-md-component=palette]");
    ref.addEventListener("change", function () {
      var palette = __md_get("__palette");
      if (palette && typeof palette.color === "object") {
        var theme = palette.color.scheme === "slate" ? "dark" : "light";

        /* Instruct Giscus to change theme */
        var frame = document.querySelector(".giscus-frame");
        frame.contentWindow.postMessage(
          { giscus: { setConfig: { theme } } },
          "https://giscus.app"
        );
      }
    });
  });
</script>

              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var tab,labels=set.querySelector(".tabbed-labels");for(tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" hidden>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
            回到页面顶部
          </a>
        
      </main>
      
        <footer class="md-footer">
  
    
    <nav class="md-footer__inner md-grid" aria-label="页脚" >
      
        
        <a href="../utils/io/" class="md-footer__link md-footer__link--prev" aria-label="上一页: IO" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                上一页
              </span>
              IO
            </div>
          </div>
        </a>
      
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      All rights reserved &copy; 2021-2023, DanLing Contributors
    </div>
  
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-consent" data-md-component="consent" id="__consent" hidden>
        <div class="md-consent__overlay"></div>
        <aside class="md-consent__inner">
          <form class="md-consent__form md-grid md-typeset" name="consent">
            

  
    
  


  
    
  



  


<h4>Cookie consent</h4>
<p>We use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they're searching for. With your consent, you're helping us to make our documentation better. Please check out our <a href="https://zyc.ai/about/privacy">Privacy Policy</a> for more information.</p>
<input class="md-toggle" type="checkbox" id="__settings" >
<div class="md-consent__settings">
  <ul class="task-list">
    
      
      
        
        
      
      <li class="task-list-item">
        <label class="task-list-control">
          <input type="checkbox" name="analytics" checked>
          <span class="task-list-indicator"></span>
          Google Analytics
        <label>
      </li>
    
      
      
        
        
      
      <li class="task-list-item">
        <label class="task-list-control">
          <input type="checkbox" name="github" checked>
          <span class="task-list-indicator"></span>
          GitHub
        <label>
      </li>
    
  </ul>
</div>
<div class="md-consent__controls">
  
    
      <button class="md-button md-button--primary">同意</button>
    
    
    
  
    
    
    
      <label class="md-button" for="__settings">管理设定</label>
    
  
</div>
          </form>
        </aside>
      </div>
      <script>var consent=__md_get("__consent");if(consent)for(var input of document.forms.consent.elements)input.name&&(input.checked=consent[input.name]||!1);else"file:"!==location.protocol&&setTimeout(function(){document.querySelector("[data-md-component=consent]").hidden=!1},250);var action,form=document.forms.consent;for(action of["submit","reset"])form.addEventListener(action,function(e){if(e.preventDefault(),"reset"===e.type)for(var n of document.forms.consent.elements)n.name&&(n.checked=!1);__md_set("__consent",Object.fromEntries(Array.from(new FormData(form).keys()).map(function(e){return[e,!0]}))),location.hash="",location.reload()})</script>
    
    <script id="__config" type="application/json">{"base": "..", "features": ["announce.dismiss", "content.code.annotate", "content.tabs.link", "content.tooltips", "header.autohide", "navigation.expand", "navigation.indexes", "navigation.instant", "navigation.prune", "navigation.sections", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow", "toc.integrate"], "search": "../assets/javascripts/workers/search.939a4419.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.config.lang": "en", "search.config.pipeline": "stemmer", "search.config.separator": "[\\s\\u200b\\u3000\\-\u3001\u3002\uff0c\uff0e\uff1f\uff01\uff1b]+", "search.placeholder": "\u641c\u7d22", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version.title": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../assets/javascripts/bundle.af94fead.min.js"></script>
      
        <script src="../javascripts/mathjax.js"></script>
      
        <script src="../assets/external/polyfill.io/v3/polyfill.min.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
        <script src="../javascripts/shortcuts.js"></script>
      
    
    
  </body>
</html>