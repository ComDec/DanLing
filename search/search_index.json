{"config":{"lang":["ja"],"separator":"[\\s\\u200b\\-]","pipeline":["stemmer"]},"docs":[{"location":"","title":"DanLing","text":""},{"location":"#introduction","title":"Introduction","text":"<p>DanLing (\u4e39\u7075) is a high-level library to help with running neural networks flexibly and transparently.</p> <p>DanLing is meant to be a scaffold for experienced researchers and engineers who know how to define a training loop, but are bored of writing the same boilerplate code, such as DDP, logging, checkpointing, etc., over and over again.</p> <p>Therefore, DanLing does not feature complex Runner designs with many pre-defined methods and complicated hooks. Instead, the Runner of DanLing just initialise the essential parts for you, and you can do whatever you want, however you want.</p> <p>Although many attributes and properties are pre-defined and are expected to be used in DanLing, you have full control over your code.</p> <p>DanLing also provides some utilities, such as Registry, NestedTensor, catch, etc.</p>"},{"location":"#installation","title":"Installation","text":"<p>Install the most recent stable version on pypi:</p> Bash<pre><code>pip install danling\n</code></pre> <p>Install the latest version from source:</p> Bash<pre><code>pip install git+https://github.com/ZhiyuanChen/DanLing\n</code></pre> <p>It works the way it should have worked.</p>"},{"location":"#license","title":"License","text":"<p>DanLing is multi-licensed under the following licenses:</p> <ul> <li>Unlicense</li> <li>GNU GPL 2.0 (or any later version)</li> <li>MIT</li> <li>Apache 2.0</li> <li>BSD 2-Clause</li> <li>BSD 3-Clause</li> <li>BSD 4-Clause</li> </ul> <p>You can choose any (one or more) of them if you use this work.</p> <p><code>SPDX-License-Identifier: Unlicense OR GPL-2.0-or-later OR MIT OR Apache-2.0 OR BSD-2-Clause OR BSD-3-Clause OR BSD-4-Clause</code></p>"},{"location":"package/","title":"DanLing","text":""},{"location":"package/#danling.AverageMeter","title":"<code>AverageMeter</code>","text":"<p>Computes and stores the average and current value.</p> <p>Attributes:</p> Name Type Description <code>val</code> <code>int</code> <p>Current value.</p> <code>avg</code> <code>float</code> <p>Average value.</p> <code>sum</code> <code>int</code> <p>Sum of values.</p> <code>count</code> <code>int</code> <p>Number of values.</p> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; meter = AverageMeter()\n&gt;&gt;&gt; meter.update(0.7)\n&gt;&gt;&gt; meter.val\n0.7\n&gt;&gt;&gt; meter.avg\n0.7\n&gt;&gt;&gt; meter.update(0.9)\n&gt;&gt;&gt; meter.val\n0.9\n&gt;&gt;&gt; meter.avg\n0.8\n&gt;&gt;&gt; meter.sum\n1.6\n&gt;&gt;&gt; meter.count\n2\n&gt;&gt;&gt; meter.reset()\n&gt;&gt;&gt; meter.val\n0\n&gt;&gt;&gt; meter.avg\n0\n</code></pre> Source code in <code>danling/metrics/average_meter.py</code> Python<pre><code>class AverageMeter:\nr\"\"\"\n    Computes and stores the average and current value.\n    Attributes:\n        val: Current value.\n        avg: Average value.\n        sum: Sum of values.\n        count: Number of values.\n    Examples:\n    ```python\n    &gt;&gt;&gt; meter = AverageMeter()\n    &gt;&gt;&gt; meter.update(0.7)\n    &gt;&gt;&gt; meter.val\n    0.7\n    &gt;&gt;&gt; meter.avg\n    0.7\n    &gt;&gt;&gt; meter.update(0.9)\n    &gt;&gt;&gt; meter.val\n    0.9\n    &gt;&gt;&gt; meter.avg\n    0.8\n    &gt;&gt;&gt; meter.sum\n    1.6\n    &gt;&gt;&gt; meter.count\n    2\n    &gt;&gt;&gt; meter.reset()\n    &gt;&gt;&gt; meter.val\n    0\n    &gt;&gt;&gt; meter.avg\n    0\n    ```\n    \"\"\"\nval: int = 0\navg: float = 0\nsum: int = 0\ncount: int = 0\ndef __init__(self) -&gt; None:\nself.reset()\ndef reset(self) -&gt; None:\nr\"\"\"\n        Resets the meter.\n        Examples:\n        ```python\n        &gt;&gt;&gt; meter = AverageMeter()\n        &gt;&gt;&gt; meter.update(0.7)\n        &gt;&gt;&gt; meter.val\n        0.7\n        &gt;&gt;&gt; meter.avg\n        0.7\n        &gt;&gt;&gt; meter.reset()\n        &gt;&gt;&gt; meter.val\n        0\n        &gt;&gt;&gt; meter.avg\n        0\n        ```\n        \"\"\"\nself.val = 0\nself.avg = 0\nself.sum = 0\nself.count = 0\ndef update(self, val, n: int = 1) -&gt; None:\nr\"\"\"\n        Updates the average and current value in the meter.\n        Args:\n            val: Value to be added to the average.\n            n: Number of values to be added.\n        Examples:\n        ```python\n        &gt;&gt;&gt; meter = AverageMeter()\n        &gt;&gt;&gt; meter.update(0.7)\n        &gt;&gt;&gt; meter.val\n        0.7\n        &gt;&gt;&gt; meter.avg\n        0.7\n        &gt;&gt;&gt; meter.update(0.9)\n        &gt;&gt;&gt; meter.val\n        0.9\n        &gt;&gt;&gt; meter.avg\n        0.8\n        &gt;&gt;&gt; meter.sum\n        1.6\n        &gt;&gt;&gt; meter.count\n        2\n        ```\n        \"\"\"\n# pylint: disable=C0103\nself.val = val\nself.sum += val * n\nself.count += n\nself.avg = self.sum / self.count\n</code></pre>"},{"location":"package/#danling.metrics.average_meter.AverageMeter.reset","title":"<code>reset()</code>","text":"<p>Resets the meter.</p> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; meter = AverageMeter()\n&gt;&gt;&gt; meter.update(0.7)\n&gt;&gt;&gt; meter.val\n0.7\n&gt;&gt;&gt; meter.avg\n0.7\n&gt;&gt;&gt; meter.reset()\n&gt;&gt;&gt; meter.val\n0\n&gt;&gt;&gt; meter.avg\n0\n</code></pre> Source code in <code>danling/metrics/average_meter.py</code> Python<pre><code>def reset(self) -&gt; None:\nr\"\"\"\n    Resets the meter.\n    Examples:\n    ```python\n    &gt;&gt;&gt; meter = AverageMeter()\n    &gt;&gt;&gt; meter.update(0.7)\n    &gt;&gt;&gt; meter.val\n    0.7\n    &gt;&gt;&gt; meter.avg\n    0.7\n    &gt;&gt;&gt; meter.reset()\n    &gt;&gt;&gt; meter.val\n    0\n    &gt;&gt;&gt; meter.avg\n    0\n    ```\n    \"\"\"\nself.val = 0\nself.avg = 0\nself.sum = 0\nself.count = 0\n</code></pre>"},{"location":"package/#danling.metrics.average_meter.AverageMeter.update","title":"<code>update(val, n=1)</code>","text":"<p>Updates the average and current value in the meter.</p> <p>Parameters:</p> Name Type Description Default <code>val</code> <p>Value to be added to the average.</p> required <code>n</code> <code>int</code> <p>Number of values to be added.</p> <code>1</code> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; meter = AverageMeter()\n&gt;&gt;&gt; meter.update(0.7)\n&gt;&gt;&gt; meter.val\n0.7\n&gt;&gt;&gt; meter.avg\n0.7\n&gt;&gt;&gt; meter.update(0.9)\n&gt;&gt;&gt; meter.val\n0.9\n&gt;&gt;&gt; meter.avg\n0.8\n&gt;&gt;&gt; meter.sum\n1.6\n&gt;&gt;&gt; meter.count\n2\n</code></pre> Source code in <code>danling/metrics/average_meter.py</code> Python<pre><code>def update(self, val, n: int = 1) -&gt; None:\nr\"\"\"\n    Updates the average and current value in the meter.\n    Args:\n        val: Value to be added to the average.\n        n: Number of values to be added.\n    Examples:\n    ```python\n    &gt;&gt;&gt; meter = AverageMeter()\n    &gt;&gt;&gt; meter.update(0.7)\n    &gt;&gt;&gt; meter.val\n    0.7\n    &gt;&gt;&gt; meter.avg\n    0.7\n    &gt;&gt;&gt; meter.update(0.9)\n    &gt;&gt;&gt; meter.val\n    0.9\n    &gt;&gt;&gt; meter.avg\n    0.8\n    &gt;&gt;&gt; meter.sum\n    1.6\n    &gt;&gt;&gt; meter.count\n    2\n    ```\n    \"\"\"\n# pylint: disable=C0103\nself.val = val\nself.sum += val * n\nself.count += n\nself.avg = self.sum / self.count\n</code></pre>"},{"location":"package/#danling.AverageMeters","title":"<code>AverageMeters</code>","text":"<p>         Bases: <code>DefaultDict</code></p> <p>A <code>DefaultDict</code> for <code>AverageMeter</code>.</p> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; meters = AverageMeters()\n&gt;&gt;&gt; meters.loss.reset()\n&gt;&gt;&gt; meters.loss.update(0.7)\n&gt;&gt;&gt; meters.loss.val\n0.7\n&gt;&gt;&gt; meters.loss.avg\n0.7\n&gt;&gt;&gt; meters.update(0.9)\n&gt;&gt;&gt; meters.loss.val\n0.9\n&gt;&gt;&gt; meters.loss.avg\n0.8\n&gt;&gt;&gt; meters.loss.sum\n1.6\n&gt;&gt;&gt; meters.loss.count\n2\n&gt;&gt;&gt; meters.reset()\n&gt;&gt;&gt; meters.loss.val\n0\n&gt;&gt;&gt; meters.loss.avg\n0\n</code></pre> Source code in <code>danling/metrics/average_meters.py</code> Python<pre><code>class AverageMeters(DefaultDict):\nr\"\"\"\n    A `DefaultDict` for `AverageMeter`.\n    Examples:\n    ```python\n    &gt;&gt;&gt; meters = AverageMeters()\n    &gt;&gt;&gt; meters.loss.reset()\n    &gt;&gt;&gt; meters.loss.update(0.7)\n    &gt;&gt;&gt; meters.loss.val\n    0.7\n    &gt;&gt;&gt; meters.loss.avg\n    0.7\n    &gt;&gt;&gt; meters.update(0.9)\n    &gt;&gt;&gt; meters.loss.val\n    0.9\n    &gt;&gt;&gt; meters.loss.avg\n    0.8\n    &gt;&gt;&gt; meters.loss.sum\n    1.6\n    &gt;&gt;&gt; meters.loss.count\n    2\n    &gt;&gt;&gt; meters.reset()\n    &gt;&gt;&gt; meters.loss.val\n    0\n    &gt;&gt;&gt; meters.loss.avg\n    0\n    ```\n    \"\"\"\ndef __init__(self, *args, **kwargs) -&gt; None:\nsuper().__init__(default_factory=AverageMeter, *args, **kwargs)\ndef reset(self) -&gt; None:\nr\"\"\"\n        Resets all meters.\n        Examples:\n        ```python\n        &gt;&gt;&gt; meters = AverageMeters()\n        &gt;&gt;&gt; meters.loss.update(0.7)\n        &gt;&gt;&gt; meters.loss.val\n        0.7\n        &gt;&gt;&gt; meters.loss.avg\n        0.7\n        &gt;&gt;&gt; meters.reset()\n        &gt;&gt;&gt; meters.loss.val\n        0\n        &gt;&gt;&gt; meters.loss.avg\n        0\n        ```\n        \"\"\"\nfor meter in self.values():\nmeter.reset()\ndef update(self, val, n: int = 1) -&gt; None:  # pylint: disable=W0237\nr\"\"\"\n        Updates the average and current value in all meters.\n        Args:\n            val: Value to be added to the average.\n            n: Number of values to be added.\n        Note:\n            This function is **NOT** recommended to use, as it alters all meters in the bank.\n        Examples:\n        ```python\n        &gt;&gt;&gt; meters = AverageMeters()\n        &gt;&gt;&gt; meters.loss.update(0.7)\n        &gt;&gt;&gt; meters.loss.val\n        0.7\n        &gt;&gt;&gt; meters.loss.avg\n        0.7\n        &gt;&gt;&gt; meters.update(0.9)\n        &gt;&gt;&gt; meters.loss.val\n        0.9\n        &gt;&gt;&gt; meters.loss.avg\n        0.8\n        &gt;&gt;&gt; meters.loss.sum\n        1.6\n        &gt;&gt;&gt; meters.loss.count\n        2\n        ```\n        \"\"\"\nfor meter in self.values():\nmeter.update(val, n)\n</code></pre>"},{"location":"package/#danling.metrics.average_meters.AverageMeters.reset","title":"<code>reset()</code>","text":"<p>Resets all meters.</p> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; meters = AverageMeters()\n&gt;&gt;&gt; meters.loss.update(0.7)\n&gt;&gt;&gt; meters.loss.val\n0.7\n&gt;&gt;&gt; meters.loss.avg\n0.7\n&gt;&gt;&gt; meters.reset()\n&gt;&gt;&gt; meters.loss.val\n0\n&gt;&gt;&gt; meters.loss.avg\n0\n</code></pre> Source code in <code>danling/metrics/average_meters.py</code> Python<pre><code>def reset(self) -&gt; None:\nr\"\"\"\n    Resets all meters.\n    Examples:\n    ```python\n    &gt;&gt;&gt; meters = AverageMeters()\n    &gt;&gt;&gt; meters.loss.update(0.7)\n    &gt;&gt;&gt; meters.loss.val\n    0.7\n    &gt;&gt;&gt; meters.loss.avg\n    0.7\n    &gt;&gt;&gt; meters.reset()\n    &gt;&gt;&gt; meters.loss.val\n    0\n    &gt;&gt;&gt; meters.loss.avg\n    0\n    ```\n    \"\"\"\nfor meter in self.values():\nmeter.reset()\n</code></pre>"},{"location":"package/#danling.metrics.average_meters.AverageMeters.update","title":"<code>update(val, n=1)</code>","text":"<p>Updates the average and current value in all meters.</p> <p>Parameters:</p> Name Type Description Default <code>val</code> <p>Value to be added to the average.</p> required <code>n</code> <code>int</code> <p>Number of values to be added.</p> <code>1</code> Note <p>This function is NOT recommended to use, as it alters all meters in the bank.</p> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; meters = AverageMeters()\n&gt;&gt;&gt; meters.loss.update(0.7)\n&gt;&gt;&gt; meters.loss.val\n0.7\n&gt;&gt;&gt; meters.loss.avg\n0.7\n&gt;&gt;&gt; meters.update(0.9)\n&gt;&gt;&gt; meters.loss.val\n0.9\n&gt;&gt;&gt; meters.loss.avg\n0.8\n&gt;&gt;&gt; meters.loss.sum\n1.6\n&gt;&gt;&gt; meters.loss.count\n2\n</code></pre> Source code in <code>danling/metrics/average_meters.py</code> Python<pre><code>def update(self, val, n: int = 1) -&gt; None:  # pylint: disable=W0237\nr\"\"\"\n    Updates the average and current value in all meters.\n    Args:\n        val: Value to be added to the average.\n        n: Number of values to be added.\n    Note:\n        This function is **NOT** recommended to use, as it alters all meters in the bank.\n    Examples:\n    ```python\n    &gt;&gt;&gt; meters = AverageMeters()\n    &gt;&gt;&gt; meters.loss.update(0.7)\n    &gt;&gt;&gt; meters.loss.val\n    0.7\n    &gt;&gt;&gt; meters.loss.avg\n    0.7\n    &gt;&gt;&gt; meters.update(0.9)\n    &gt;&gt;&gt; meters.loss.val\n    0.9\n    &gt;&gt;&gt; meters.loss.avg\n    0.8\n    &gt;&gt;&gt; meters.loss.sum\n    1.6\n    &gt;&gt;&gt; meters.loss.count\n    2\n    ```\n    \"\"\"\nfor meter in self.values():\nmeter.update(val, n)\n</code></pre>"},{"location":"package/#danling.Registry","title":"<code>Registry</code>","text":"<p>         Bases: <code>NestedDict</code></p> <p><code>Registry</code> for components.</p> Notes <p><code>Registry</code> inherits from <code>NestedDict</code>.</p> <p>Therefore, <code>Registry</code> comes in a nested structure by nature. You could create a sub-registry by simply calling <code>registry.sub_registry = Registry</code>, and access through <code>registry.sub_registry.register()</code>.</p> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; registry = Registry(\"test\")\n&gt;&gt;&gt; @registry.register\n... @registry.register(\"Module1\")\n... class Module:\n...     def __init__(self, a, b):\n...         self.a = a\n...         self.b = b\n&gt;&gt;&gt; module = registry.register(Module, \"Module2\")\n&gt;&gt;&gt; registry\nRegistry(\n('Module1'): &lt;class 'danling.registry.Module'&gt;\n('Module'): &lt;class 'danling.registry.Module'&gt;\n('Module2'): &lt;class 'danling.registry.Module'&gt;\n)\n&gt;&gt;&gt; registry.lookup(\"Module\")\n&lt;class 'danling.registry.Module'&gt;\n&gt;&gt;&gt; config = {\"module\": {\"name\": \"Module\", \"a\": 1, \"b\": 2}}\n&gt;&gt;&gt; # registry.register(Module)\n&gt;&gt;&gt; module = registry.build(config[\"module\"])\n&gt;&gt;&gt; type(module)\n&lt;class 'danling.registry.Module'&gt;\n&gt;&gt;&gt; module.a\n1\n&gt;&gt;&gt; module.b\n2\n</code></pre> Source code in <code>danling/registry.py</code> Python<pre><code>class Registry(NestedDict):\n\"\"\"\n    `Registry` for components.\n    Notes:\n        `Registry` inherits from [`NestedDict`](https://chanfig.danling.org/nested_dict/).\n        Therefore, `Registry` comes in a nested structure by nature.\n        You could create a sub-registry by simply calling `registry.sub_registry = Registry`,\n        and access through `registry.sub_registry.register()`.\n    Examples:\n    ```python\n    &gt;&gt;&gt; registry = Registry(\"test\")\n    &gt;&gt;&gt; @registry.register\n    ... @registry.register(\"Module1\")\n    ... class Module:\n    ...     def __init__(self, a, b):\n    ...         self.a = a\n    ...         self.b = b\n    &gt;&gt;&gt; module = registry.register(Module, \"Module2\")\n    &gt;&gt;&gt; registry\n    Registry(\n      ('Module1'): &lt;class 'danling.registry.Module'&gt;\n      ('Module'): &lt;class 'danling.registry.Module'&gt;\n      ('Module2'): &lt;class 'danling.registry.Module'&gt;\n    )\n    &gt;&gt;&gt; registry.lookup(\"Module\")\n    &lt;class 'danling.registry.Module'&gt;\n    &gt;&gt;&gt; config = {\"module\": {\"name\": \"Module\", \"a\": 1, \"b\": 2}}\n    &gt;&gt;&gt; # registry.register(Module)\n    &gt;&gt;&gt; module = registry.build(config[\"module\"])\n    &gt;&gt;&gt; type(module)\n    &lt;class 'danling.registry.Module'&gt;\n    &gt;&gt;&gt; module.a\n    1\n    &gt;&gt;&gt; module.b\n    2\n    ```\n    \"\"\"\noverride: bool = False\ndef __init__(self, override: bool = False):\nsuper().__init__()\nself.setattr(\"override\", override)\nwarn(\n\"DanLing Registry has been deprecated in favor of CHANfiG Registry, and will be removed in 0.2.0.\",\nDeprecationWarning,\n)\ndef register(self, component: Optional[Callable] = None, name: Optional[str] = None) -&gt; Callable:\nr\"\"\"\n        Register a new component.\n        Args:\n            component: The component to register.\n            name: The name of the component.\n        Returns:\n            component: The registered component.\n        Raises:\n            ValueError: If the component with the same name already registered and `Registry.override=False`.\n        Examples:\n        ```python\n        &gt;&gt;&gt; registry = Registry(\"test\")\n        &gt;&gt;&gt; @registry.register\n        ... @registry.register(\"Module1\")\n        ... class Module:\n        ...     def __init__(self, a, b):\n        ...         self.a = a\n        ...         self.b = b\n        &gt;&gt;&gt; module = registry.register(Module, \"Module2\")\n        &gt;&gt;&gt; registry\n        Registry(\n          ('Module1'): &lt;class 'danling.registry.Module'&gt;\n          ('Module'): &lt;class 'danling.registry.Module'&gt;\n          ('Module2'): &lt;class 'danling.registry.Module'&gt;\n        )\n        ```\n        \"\"\"\nif name in self and not self.override:\nraise ValueError(f\"Component with name {name} already registered.\")\n# Registry.register()\nif name is not None:\nself.set(name, component)\n# @Registry.register()\n@wraps(self.register)\ndef register(component, name=None):\nif name is None:\nname = component.__name__\nself.set(name, component)\nreturn component\n# @Registry.register\nif callable(component) and name is None:\nreturn register(component)\nreturn lambda x: register(x, component)\ndef lookup(self, name: str) -&gt; Any:\nr\"\"\"\n        Lookup for a component.\n        Args:\n            name:\n        Returns:\n            (Any): The component.\n        Raises:\n            KeyError: If the component is not registered.\n        Examples:\n        ```python\n        &gt;&gt;&gt; registry = Registry(\"test\")\n        &gt;&gt;&gt; @registry.register\n        ... class Module:\n        ...     def __init__(self, a, b):\n        ...         self.a = a\n        ...         self.b = b\n        &gt;&gt;&gt; registry.lookup(\"Module\")\n        &lt;class 'danling.registry.Module'&gt;\n        ```\n        \"\"\"\nreturn self.get(name)\ndef build(self, name: Union[str, Mapping], *args, **kwargs) -&gt; Any:\nr\"\"\"\n        Build a component.\n        Args:\n            name (str | Mapping):\n                If its a `Mapping`, it must contain `\"name\"` as a member, the rest will be treated as `**kwargs`.\n                Note that values in `kwargs` will override values in `name` if its a `Mapping`.\n            *args: The arguments to pass to the component.\n            **kwargs: The keyword arguments to pass to the component.\n        Returns:\n            (Any):\n        Raises:\n            KeyError: If the component is not registered.\n        Examples:\n        ```python\n        &gt;&gt;&gt; registry = Registry(\"test\")\n        &gt;&gt;&gt; @registry.register\n        ... class Module:\n        ...     def __init__(self, a, b):\n        ...         self.a = a\n        ...         self.b = b\n        &gt;&gt;&gt; config = {\"module\": {\"name\": \"Module\", \"a\": 1, \"b\": 2}}\n        &gt;&gt;&gt; # registry.register(Module)\n        &gt;&gt;&gt; module = registry.build(**config[\"module\"])\n        &gt;&gt;&gt; type(module)\n        &lt;class 'danling.registry.Module'&gt;\n        &gt;&gt;&gt; module.a\n        1\n        &gt;&gt;&gt; module.b\n        2\n        &gt;&gt;&gt; module = registry.build(config[\"module\"], a=2)\n        &gt;&gt;&gt; module.a\n        2\n        ```\n        \"\"\"\nif isinstance(name, Mapping):\nname = deepcopy(name)\nname, kwargs = name.pop(\"name\"), dict(name, **kwargs)  # type: ignore\nreturn self.get(name)(*args, **kwargs)  # type: ignore\ndef __wrapped__(self, *args, **kwargs):\npass\n</code></pre>"},{"location":"package/#danling.registry.Registry.register","title":"<code>register(component=None, name=None)</code>","text":"<p>Register a new component.</p> <p>Parameters:</p> Name Type Description Default <code>component</code> <code>Optional[Callable]</code> <p>The component to register.</p> <code>None</code> <code>name</code> <code>Optional[str]</code> <p>The name of the component.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>component</code> <code>Callable</code> <p>The registered component.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the component with the same name already registered and <code>Registry.override=False</code>.</p> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; registry = Registry(\"test\")\n&gt;&gt;&gt; @registry.register\n... @registry.register(\"Module1\")\n... class Module:\n...     def __init__(self, a, b):\n...         self.a = a\n...         self.b = b\n&gt;&gt;&gt; module = registry.register(Module, \"Module2\")\n&gt;&gt;&gt; registry\nRegistry(\n('Module1'): &lt;class 'danling.registry.Module'&gt;\n('Module'): &lt;class 'danling.registry.Module'&gt;\n('Module2'): &lt;class 'danling.registry.Module'&gt;\n)\n</code></pre> Source code in <code>danling/registry.py</code> Python<pre><code>def register(self, component: Optional[Callable] = None, name: Optional[str] = None) -&gt; Callable:\nr\"\"\"\n    Register a new component.\n    Args:\n        component: The component to register.\n        name: The name of the component.\n    Returns:\n        component: The registered component.\n    Raises:\n        ValueError: If the component with the same name already registered and `Registry.override=False`.\n    Examples:\n    ```python\n    &gt;&gt;&gt; registry = Registry(\"test\")\n    &gt;&gt;&gt; @registry.register\n    ... @registry.register(\"Module1\")\n    ... class Module:\n    ...     def __init__(self, a, b):\n    ...         self.a = a\n    ...         self.b = b\n    &gt;&gt;&gt; module = registry.register(Module, \"Module2\")\n    &gt;&gt;&gt; registry\n    Registry(\n      ('Module1'): &lt;class 'danling.registry.Module'&gt;\n      ('Module'): &lt;class 'danling.registry.Module'&gt;\n      ('Module2'): &lt;class 'danling.registry.Module'&gt;\n    )\n    ```\n    \"\"\"\nif name in self and not self.override:\nraise ValueError(f\"Component with name {name} already registered.\")\n# Registry.register()\nif name is not None:\nself.set(name, component)\n# @Registry.register()\n@wraps(self.register)\ndef register(component, name=None):\nif name is None:\nname = component.__name__\nself.set(name, component)\nreturn component\n# @Registry.register\nif callable(component) and name is None:\nreturn register(component)\nreturn lambda x: register(x, component)\n</code></pre>"},{"location":"package/#danling.registry.Registry.lookup","title":"<code>lookup(name)</code>","text":"<p>Lookup for a component.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> required <p>Returns:</p> Type Description <code>Any</code> <p>The component.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If the component is not registered.</p> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; registry = Registry(\"test\")\n&gt;&gt;&gt; @registry.register\n... class Module:\n...     def __init__(self, a, b):\n...         self.a = a\n...         self.b = b\n&gt;&gt;&gt; registry.lookup(\"Module\")\n&lt;class 'danling.registry.Module'&gt;\n</code></pre> Source code in <code>danling/registry.py</code> Python<pre><code>def lookup(self, name: str) -&gt; Any:\nr\"\"\"\n    Lookup for a component.\n    Args:\n        name:\n    Returns:\n        (Any): The component.\n    Raises:\n        KeyError: If the component is not registered.\n    Examples:\n    ```python\n    &gt;&gt;&gt; registry = Registry(\"test\")\n    &gt;&gt;&gt; @registry.register\n    ... class Module:\n    ...     def __init__(self, a, b):\n    ...         self.a = a\n    ...         self.b = b\n    &gt;&gt;&gt; registry.lookup(\"Module\")\n    &lt;class 'danling.registry.Module'&gt;\n    ```\n    \"\"\"\nreturn self.get(name)\n</code></pre>"},{"location":"package/#danling.registry.Registry.build","title":"<code>build(name, *args, **kwargs)</code>","text":"<p>Build a component.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | Mapping</code> <p>If its a <code>Mapping</code>, it must contain <code>\"name\"</code> as a member, the rest will be treated as <code>**kwargs</code>. Note that values in <code>kwargs</code> will override values in <code>name</code> if its a <code>Mapping</code>.</p> required <code>*args</code> <p>The arguments to pass to the component.</p> <code>()</code> <code>**kwargs</code> <p>The keyword arguments to pass to the component.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Any</code> <p>Raises:</p> Type Description <code>KeyError</code> <p>If the component is not registered.</p> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; registry = Registry(\"test\")\n&gt;&gt;&gt; @registry.register\n... class Module:\n...     def __init__(self, a, b):\n...         self.a = a\n...         self.b = b\n&gt;&gt;&gt; config = {\"module\": {\"name\": \"Module\", \"a\": 1, \"b\": 2}}\n&gt;&gt;&gt; # registry.register(Module)\n&gt;&gt;&gt; module = registry.build(**config[\"module\"])\n&gt;&gt;&gt; type(module)\n&lt;class 'danling.registry.Module'&gt;\n&gt;&gt;&gt; module.a\n1\n&gt;&gt;&gt; module.b\n2\n&gt;&gt;&gt; module = registry.build(config[\"module\"], a=2)\n&gt;&gt;&gt; module.a\n2\n</code></pre> Source code in <code>danling/registry.py</code> Python<pre><code>def build(self, name: Union[str, Mapping], *args, **kwargs) -&gt; Any:\nr\"\"\"\n    Build a component.\n    Args:\n        name (str | Mapping):\n            If its a `Mapping`, it must contain `\"name\"` as a member, the rest will be treated as `**kwargs`.\n            Note that values in `kwargs` will override values in `name` if its a `Mapping`.\n        *args: The arguments to pass to the component.\n        **kwargs: The keyword arguments to pass to the component.\n    Returns:\n        (Any):\n    Raises:\n        KeyError: If the component is not registered.\n    Examples:\n    ```python\n    &gt;&gt;&gt; registry = Registry(\"test\")\n    &gt;&gt;&gt; @registry.register\n    ... class Module:\n    ...     def __init__(self, a, b):\n    ...         self.a = a\n    ...         self.b = b\n    &gt;&gt;&gt; config = {\"module\": {\"name\": \"Module\", \"a\": 1, \"b\": 2}}\n    &gt;&gt;&gt; # registry.register(Module)\n    &gt;&gt;&gt; module = registry.build(**config[\"module\"])\n    &gt;&gt;&gt; type(module)\n    &lt;class 'danling.registry.Module'&gt;\n    &gt;&gt;&gt; module.a\n    1\n    &gt;&gt;&gt; module.b\n    2\n    &gt;&gt;&gt; module = registry.build(config[\"module\"], a=2)\n    &gt;&gt;&gt; module.a\n    2\n    ```\n    \"\"\"\nif isinstance(name, Mapping):\nname = deepcopy(name)\nname, kwargs = name.pop(\"name\"), dict(name, **kwargs)  # type: ignore\nreturn self.get(name)(*args, **kwargs)  # type: ignore\n</code></pre>"},{"location":"package/#danling.PNTensor","title":"<code>PNTensor</code>","text":"<p>         Bases: <code>Tensor</code></p> <p>Wrapper for tensors to be converted to <code>NestedTensor</code>.</p> <p><code>PNTensor</code> is a subclass of <code>torch.Tensor</code>. It implements two additional methods as <code>NestedTensor</code>: <code>tensor</code> and <code>mask</code>.</p> <p>Although it is possible to construct <code>NestedTensor</code> in dataset, the best practice is to do so in <code>collate_fn</code>. However, it is hard to tell if a batch of <code>Tensor</code> should be stacked or converted to <code>NestedTensor</code>.</p> <p><code>PNTensor</code> is introduced overcome this limitation.</p> <p>Convert tensors that will be converted to <code>NestedTensor</code> to a <code>PNTensor</code>, and all you need to do is to convert <code>PNTensor</code> to <code>NestedTensor</code> in <code>collate_fn</code>.</p> Source code in <code>danling/tensors/nested_tensor.py</code> Python<pre><code>class PNTensor(Tensor):\nr\"\"\"\n    Wrapper for tensors to be converted to `NestedTensor`.\n    `PNTensor` is a subclass of `torch.Tensor`.\n    It implements two additional methods as `NestedTensor`: `tensor` and `mask`.\n    Although it is possible to construct `NestedTensor` in dataset,\n    the best practice is to do so in `collate_fn`.\n    However, it is hard to tell if a batch of `Tensor` should be stacked or converted to `NestedTensor`.\n    `PNTensor` is introduced overcome this limitation.\n    Convert tensors that will be converted to `NestedTensor` to a `PNTensor`,\n    and all you need to do is to convert `PNTensor` to `NestedTensor` in `collate_fn`.\n    \"\"\"\n@property\ndef tensor(self) -&gt; Tensor:\nr\"\"\"\n        Identical to `self`.\n        Returns:\n            (torch.Tensor):\n        Examples:\n        ```python\n        &gt;&gt;&gt; tensor = torch.tensor([1, 2, 3])\n        &gt;&gt;&gt; pn_tensor = PNTensor(tensor)\n        &gt;&gt;&gt; (tensor == pn_tensor).all()\n        PNTensor(True)\n        &gt;&gt;&gt; (tensor == pn_tensor.tensor).all()\n        PNTensor(True)\n        ```\n        \"\"\"\nreturn self\n@property\ndef mask(self) -&gt; Tensor:\nr\"\"\"\n        Identical to `torch.ones_like(self)`.\n        Returns:\n            (torch.Tensor):\n        Examples:\n        ```python\n        &gt;&gt;&gt; tensor = torch.tensor([1, 2, 3])\n        &gt;&gt;&gt; pn_tensor = PNTensor(tensor)\n        &gt;&gt;&gt; (pn_tensor.mask == torch.ones_like(pn_tensor)).all()\n        PNTensor(True)\n        ```\n        \"\"\"\nreturn torch.ones_like(self)  # pylint: disable=E1101\n</code></pre>"},{"location":"package/#danling.tensors.nested_tensor.PNTensor.tensor","title":"<code>tensor: Tensor</code>  <code>property</code>","text":"<p>Identical to <code>self</code>.</p> <p>Returns:</p> Type Description <code>torch.Tensor</code> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; tensor = torch.tensor([1, 2, 3])\n&gt;&gt;&gt; pn_tensor = PNTensor(tensor)\n&gt;&gt;&gt; (tensor == pn_tensor).all()\nPNTensor(True)\n&gt;&gt;&gt; (tensor == pn_tensor.tensor).all()\nPNTensor(True)\n</code></pre>"},{"location":"package/#danling.tensors.nested_tensor.PNTensor.mask","title":"<code>mask: Tensor</code>  <code>property</code>","text":"<p>Identical to <code>torch.ones_like(self)</code>.</p> <p>Returns:</p> Type Description <code>torch.Tensor</code> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; tensor = torch.tensor([1, 2, 3])\n&gt;&gt;&gt; pn_tensor = PNTensor(tensor)\n&gt;&gt;&gt; (pn_tensor.mask == torch.ones_like(pn_tensor)).all()\nPNTensor(True)\n</code></pre>"},{"location":"package/#danling.TorchRunner","title":"<code>TorchRunner</code>","text":"<p>         Bases: <code>BaseRunner</code></p> <p>Set up everything for running a job.</p> <p>Attributes:</p> Name Type Description <code>accelerator</code> <code>Accelerator</code> <code>accelerate</code> <code>Mapping[str, Any]</code> <p>Defaults to <code>{}</code>. if is <code>None</code>, will not use <code>accelerate</code>.</p> Source code in <code>danling/runner/torch_runner.py</code> Python<pre><code>class TorchRunner(BaseRunner):\nr\"\"\"\n    Set up everything for running a job.\n    Attributes:\n        accelerator (Accelerator):\n        accelerate: Defaults to `{}`.\n            if is `None`, will not use `accelerate`.\n    \"\"\"\n# pylint: disable=R0902\naccelerator: Accelerator = None  # type: ignore\naccelerate: Mapping[str, Any]\ndef __init__(self, *args, **kwargs) -&gt; None:\nif \"accelerate\" not in self:\nself.accelerate = {}\nif len(args) == 1 and isinstance(args[0], dict):\nself.accelerate.update(args[0].pop(\"accelerate\", {}))  # type: ignore\nif \"accelerate\" in kwargs:\nself.accelerate.update(kwargs.pop(\"accelerate\"))  # type: ignore\nsuper().__init__(*args, **kwargs)\ndef init_distributed(self) -&gt; None:\nr\"\"\"\n        Set up distributed training.\n        Initialise process group and set up DDP variables.\n        \"\"\"\nif self.accelerate is None:\nself.accelerate = {}\nself.accelerator = Accelerator(**self.accelerate)\nif self.distributed:\nobject_list = [self.state.id]\ndist.broadcast_object_list(object_list)\nself.state.id = object_list[0]\n@on_main_process\ndef init_tensorboard(self, *args, **kwargs) -&gt; None:\nr\"\"\"\n        Set up Tensoraoard SummaryWriter.\n        \"\"\"\nfrom torch.utils.tensorboard.writer import SummaryWriter  # pylint: disable=C0415\nif \"log_dir\" not in kwargs:\nkwargs[\"log_dir\"] = self.dir\nself.writer = SummaryWriter(*args, **kwargs)\nself.writer.add_scalar = catch(OSError, verbose=False)(self.writer.add_scalar)  # type: ignore\ndef set_seed(self, seed: int = None, bias: Optional[int] = None) -&gt; None:  # type: ignore\nr\"\"\"\n        Set up random seed.\n        Args:\n            seed: Random seed to set.\n                Defaults to `self.state.seed` (`config.seed`).\n            bias: Make the seed different for each processes.\n                This avoids same data augmentation are applied on every processes.\n                Defaults to `self.rank`.\n                Set to `False` to disable this feature.\n        \"\"\"\nif seed is None:\nseed = self.state.seed\nif self.distributed:\nobject_list = [seed]\ndist.broadcast_object_list(object_list)\nseed = object_list[0]\nif bias is None:\nbias = self.rank\nif bias:\nseed += bias  # type: ignore\nself.state.seed = seed\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\nnp.random.seed(seed)\nrandom.seed(seed)\ndef set_deterministic(self) -&gt; None:\nr\"\"\"\n        Set up deterministic.\n        \"\"\"\ncudnn.benchmark = False\ncudnn.deterministic = True\nif torch.__version__ &gt;= \"1.8.0\":\ntorch.use_deterministic_algorithms(True)\ndef state_dict(self, cls: Callable = dict) -&gt; Mapping:\nr\"\"\"\n        Return dict of all attributes for checkpoint.\n        \"\"\"\nif self.model is None:\nraise ValueError(\"Model must be defined when calling state_dict\")\nmodel = self.accelerator.unwrap_model(self.model)\nreturn cls(\nrunner=self.state.dict(),\nmodel=model.state_dict(),\noptimizer=self.optimizer.state_dict() if self.optimizer else None,\nscheduler=self.scheduler.state_dict() if self.scheduler else None,\n)\ndef prepare(self, *args, device_placement: Optional[List[bool]] = None) -&gt; None:\nr\"\"\"\n        Prepare all objects passed in `args` for distributed training and mixed precision,\n        then return them in the same order.\n        \"\"\"\nreturn self.accelerator.prepare(*args, device_placement=device_placement)\ndef autocast(self):\nr\"\"\"\n        Context manager that enables autocasting for the forward pass (and maybe backward pass).\n        \"\"\"\nreturn self.accelerator.autocast()\ndef backward(self, loss) -&gt; None:\nr\"\"\"\n        Backward loss to compute gradients.\n        \"\"\"\nreturn self.accelerator.backward(loss)\ndef unwrap_model(self, model: Optional[nn.Module] = None) -&gt; nn.Module:\nr\"\"\"\n        Unwrap DDP model.\n        Args:\n            model (Optional[nn.Module]):\n                Defaults to `self.model`.\n        \"\"\"\nif model is not None:\nmodel = self.model  # type: ignore\nif self.accelerator is not None:\nreturn self.accelerator.unwrap_model(model)\nif self.distributed:\nreturn model.module  # type: ignore\nreturn model  # type: ignore\n@property\ndef batch_size(self) -&gt; int:\nr\"\"\"\n        Batch size.\n        Notes:\n            If `train` is in `dataloaders`, then `batch_size` is the batch size of `train`.\n            Otherwise, `batch_size` is the batch size of the first dataloader.\n        Returns:\n            (int):\n        \"\"\"\nif self.dataloaders:\nloader = self.dataloaders[\"train\"] if \"train\" in self.dataloaders else next(iter(self.dataloaders.values()))\nbatch_sampler = loader.sampler if isinstance(loader.sampler, BatchSampler) else loader.batch_sampler\nreturn batch_sampler.batch_size\nraise AttributeError(\"batch_size could not be inferred, since no dataloaedr found.\")\n@property\ndef accum_steps(self) -&gt; int:\nr\"\"\"\n        Gradient accumulation steps.\n        Returns:\n            (int):\n        \"\"\"\nreturn self.accelerator.gradient_accumulation_steps\n@property\ndef device(self) -&gt; torch.device:  # pylint: disable=E1101\nr\"\"\"\n        Device of runner.\n        \"\"\"\nreturn self.accelerator.device\n@property\ndef world_size(self) -&gt; int:\nr\"\"\"\n        Number of Processes.\n        \"\"\"\nreturn self.accelerator.num_processes\n@property\ndef rank(self) -&gt; int:\nr\"\"\"\n        Process index in all processes.\n        \"\"\"\nreturn self.accelerator.process_index\n@property\ndef local_rank(self) -&gt; int:\nr\"\"\"\n        Process index in local processes.\n        \"\"\"\nreturn self.accelerator.local_process_index\ndef gather(self, tensor) -&gt; torch.Tensor:\nr\"\"\"\n        Gather tensor.\n        \"\"\"\nreturn self.accelerator.gather(tensor)\ndef reduce(self, tensor, reduction: str = \"sum\") -&gt; torch.Tensor:\nr\"\"\"\n        Reduce tensor.\n        \"\"\"\nreturn self.accelerator.reduce(tensor, reduction=reduction)\ndef __getattr__(self, name: str) -&gt; Any:\ntry:\nreturn super().__getattr__(name)\nexcept AttributeError:\npass\nif self.accelerator is not None and hasattr(self.accelerator, name):\nreturn getattr(self.accelerator, name)\nraise super().__getattribute__(name)\n</code></pre>"},{"location":"package/#danling.runner.torch_runner.TorchRunner.batch_size","title":"<code>batch_size: int</code>  <code>property</code>","text":"<p>Batch size.</p> Notes <p>If <code>train</code> is in <code>dataloaders</code>, then <code>batch_size</code> is the batch size of <code>train</code>. Otherwise, <code>batch_size</code> is the batch size of the first dataloader.</p> <p>Returns:</p> Type Description <code>int</code>"},{"location":"package/#danling.runner.torch_runner.TorchRunner.accum_steps","title":"<code>accum_steps: int</code>  <code>property</code>","text":"<p>Gradient accumulation steps.</p> <p>Returns:</p> Type Description <code>int</code>"},{"location":"package/#danling.runner.torch_runner.TorchRunner.device","title":"<code>device: torch.device</code>  <code>property</code>","text":"<p>Device of runner.</p>"},{"location":"package/#danling.runner.torch_runner.TorchRunner.world_size","title":"<code>world_size: int</code>  <code>property</code>","text":"<p>Number of Processes.</p>"},{"location":"package/#danling.runner.torch_runner.TorchRunner.rank","title":"<code>rank: int</code>  <code>property</code>","text":"<p>Process index in all processes.</p>"},{"location":"package/#danling.runner.torch_runner.TorchRunner.local_rank","title":"<code>local_rank: int</code>  <code>property</code>","text":"<p>Process index in local processes.</p>"},{"location":"package/#danling.runner.torch_runner.TorchRunner.init_distributed","title":"<code>init_distributed()</code>","text":"<p>Set up distributed training.</p> <p>Initialise process group and set up DDP variables.</p> Source code in <code>danling/runner/torch_runner.py</code> Python<pre><code>def init_distributed(self) -&gt; None:\nr\"\"\"\n    Set up distributed training.\n    Initialise process group and set up DDP variables.\n    \"\"\"\nif self.accelerate is None:\nself.accelerate = {}\nself.accelerator = Accelerator(**self.accelerate)\nif self.distributed:\nobject_list = [self.state.id]\ndist.broadcast_object_list(object_list)\nself.state.id = object_list[0]\n</code></pre>"},{"location":"package/#danling.runner.torch_runner.TorchRunner.init_tensorboard","title":"<code>init_tensorboard(*args, **kwargs)</code>","text":"<p>Set up Tensoraoard SummaryWriter.</p> Source code in <code>danling/runner/torch_runner.py</code> Python<pre><code>@on_main_process\ndef init_tensorboard(self, *args, **kwargs) -&gt; None:\nr\"\"\"\n    Set up Tensoraoard SummaryWriter.\n    \"\"\"\nfrom torch.utils.tensorboard.writer import SummaryWriter  # pylint: disable=C0415\nif \"log_dir\" not in kwargs:\nkwargs[\"log_dir\"] = self.dir\nself.writer = SummaryWriter(*args, **kwargs)\nself.writer.add_scalar = catch(OSError, verbose=False)(self.writer.add_scalar)  # type: ignore\n</code></pre>"},{"location":"package/#danling.runner.torch_runner.TorchRunner.set_seed","title":"<code>set_seed(seed=None, bias=None)</code>","text":"<p>Set up random seed.</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>int</code> <p>Random seed to set. Defaults to <code>self.state.seed</code> (<code>config.seed</code>).</p> <code>None</code> <code>bias</code> <code>Optional[int]</code> <p>Make the seed different for each processes.</p> <p>This avoids same data augmentation are applied on every processes.</p> <p>Defaults to <code>self.rank</code>.</p> <p>Set to <code>False</code> to disable this feature.</p> <code>None</code> Source code in <code>danling/runner/torch_runner.py</code> Python<pre><code>def set_seed(self, seed: int = None, bias: Optional[int] = None) -&gt; None:  # type: ignore\nr\"\"\"\n    Set up random seed.\n    Args:\n        seed: Random seed to set.\n            Defaults to `self.state.seed` (`config.seed`).\n        bias: Make the seed different for each processes.\n            This avoids same data augmentation are applied on every processes.\n            Defaults to `self.rank`.\n            Set to `False` to disable this feature.\n    \"\"\"\nif seed is None:\nseed = self.state.seed\nif self.distributed:\nobject_list = [seed]\ndist.broadcast_object_list(object_list)\nseed = object_list[0]\nif bias is None:\nbias = self.rank\nif bias:\nseed += bias  # type: ignore\nself.state.seed = seed\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\nnp.random.seed(seed)\nrandom.seed(seed)\n</code></pre>"},{"location":"package/#danling.runner.torch_runner.TorchRunner.set_deterministic","title":"<code>set_deterministic()</code>","text":"<p>Set up deterministic.</p> Source code in <code>danling/runner/torch_runner.py</code> Python<pre><code>def set_deterministic(self) -&gt; None:\nr\"\"\"\n    Set up deterministic.\n    \"\"\"\ncudnn.benchmark = False\ncudnn.deterministic = True\nif torch.__version__ &gt;= \"1.8.0\":\ntorch.use_deterministic_algorithms(True)\n</code></pre>"},{"location":"package/#danling.runner.torch_runner.TorchRunner.state_dict","title":"<code>state_dict(cls=dict)</code>","text":"<p>Return dict of all attributes for checkpoint.</p> Source code in <code>danling/runner/torch_runner.py</code> Python<pre><code>def state_dict(self, cls: Callable = dict) -&gt; Mapping:\nr\"\"\"\n    Return dict of all attributes for checkpoint.\n    \"\"\"\nif self.model is None:\nraise ValueError(\"Model must be defined when calling state_dict\")\nmodel = self.accelerator.unwrap_model(self.model)\nreturn cls(\nrunner=self.state.dict(),\nmodel=model.state_dict(),\noptimizer=self.optimizer.state_dict() if self.optimizer else None,\nscheduler=self.scheduler.state_dict() if self.scheduler else None,\n)\n</code></pre>"},{"location":"package/#danling.runner.torch_runner.TorchRunner.prepare","title":"<code>prepare(*args, device_placement=None)</code>","text":"<p>Prepare all objects passed in <code>args</code> for distributed training and mixed precision, then return them in the same order.</p> Source code in <code>danling/runner/torch_runner.py</code> Python<pre><code>def prepare(self, *args, device_placement: Optional[List[bool]] = None) -&gt; None:\nr\"\"\"\n    Prepare all objects passed in `args` for distributed training and mixed precision,\n    then return them in the same order.\n    \"\"\"\nreturn self.accelerator.prepare(*args, device_placement=device_placement)\n</code></pre>"},{"location":"package/#danling.runner.torch_runner.TorchRunner.autocast","title":"<code>autocast()</code>","text":"<p>Context manager that enables autocasting for the forward pass (and maybe backward pass).</p> Source code in <code>danling/runner/torch_runner.py</code> Python<pre><code>def autocast(self):\nr\"\"\"\n    Context manager that enables autocasting for the forward pass (and maybe backward pass).\n    \"\"\"\nreturn self.accelerator.autocast()\n</code></pre>"},{"location":"package/#danling.runner.torch_runner.TorchRunner.backward","title":"<code>backward(loss)</code>","text":"<p>Backward loss to compute gradients.</p> Source code in <code>danling/runner/torch_runner.py</code> Python<pre><code>def backward(self, loss) -&gt; None:\nr\"\"\"\n    Backward loss to compute gradients.\n    \"\"\"\nreturn self.accelerator.backward(loss)\n</code></pre>"},{"location":"package/#danling.runner.torch_runner.TorchRunner.unwrap_model","title":"<code>unwrap_model(model=None)</code>","text":"<p>Unwrap DDP model.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Optional[nn.Module]</code> <p>Defaults to <code>self.model</code>.</p> <code>None</code> Source code in <code>danling/runner/torch_runner.py</code> Python<pre><code>def unwrap_model(self, model: Optional[nn.Module] = None) -&gt; nn.Module:\nr\"\"\"\n    Unwrap DDP model.\n    Args:\n        model (Optional[nn.Module]):\n            Defaults to `self.model`.\n    \"\"\"\nif model is not None:\nmodel = self.model  # type: ignore\nif self.accelerator is not None:\nreturn self.accelerator.unwrap_model(model)\nif self.distributed:\nreturn model.module  # type: ignore\nreturn model  # type: ignore\n</code></pre>"},{"location":"package/#danling.runner.torch_runner.TorchRunner.gather","title":"<code>gather(tensor)</code>","text":"<p>Gather tensor.</p> Source code in <code>danling/runner/torch_runner.py</code> Python<pre><code>def gather(self, tensor) -&gt; torch.Tensor:\nr\"\"\"\n    Gather tensor.\n    \"\"\"\nreturn self.accelerator.gather(tensor)\n</code></pre>"},{"location":"package/#danling.runner.torch_runner.TorchRunner.reduce","title":"<code>reduce(tensor, reduction='sum')</code>","text":"<p>Reduce tensor.</p> Source code in <code>danling/runner/torch_runner.py</code> Python<pre><code>def reduce(self, tensor, reduction: str = \"sum\") -&gt; torch.Tensor:\nr\"\"\"\n    Reduce tensor.\n    \"\"\"\nreturn self.accelerator.reduce(tensor, reduction=reduction)\n</code></pre>"},{"location":"package/#danling.BaseRunner","title":"<code>BaseRunner</code>","text":"<p>         Bases: <code>RunnerBase</code></p> <p>Base class for running a neural network.</p> <p><code>BaseRunner</code> sets up basic running environment, including <code>seed</code>, <code>deterministic</code>, and <code>logging</code>.</p> <p><code>BaseRunner</code> also provides some basic methods, such as, <code>step</code>, <code>state_dict</code>, <code>save_checkpoint</code>, <code>load_checkpoint</code>.</p> <p>All runners should inherit <code>BaseRunner</code>.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>class BaseRunner(RunnerBase):\nr\"\"\"\n    Base class for running a neural network.\n    `BaseRunner` sets up basic running environment, including `seed`, `deterministic`, and `logging`.\n    `BaseRunner` also provides some basic methods, such as, `step`, `state_dict`, `save_checkpoint`, `load_checkpoint`.\n    All runners should inherit `BaseRunner`.\n    \"\"\"\n# pylint: disable=R0902\ndef __init__(self, *args, **kwargs) -&gt; None:\nsuper().__init__(*args, **kwargs)\nself.init_distributed()\nif self.state.seed is not None:\nself.set_seed()\nif self.state.deterministic:\nself.set_deterministic()\nif self.state.log:\nself.init_logging()\nself.init_print()\nif self.state.tensorboard:\nself.init_tensorboard()\n@on_main_process\ndef init_logging(self) -&gt; None:\nr\"\"\"\n        Set up logging.\n        \"\"\"\n# Why is setting up proper logging so !@?#! ugly?\nlogging.config.dictConfig(\n{\n\"version\": 1,\n\"disable_existing_loggers\": False,\n\"formatters\": {\n\"standard\": {\"format\": \"%(asctime)s [%(levelname)s] %(name)s: %(message)s\"},\n},\n\"handlers\": {\n\"stdout\": {\n\"level\": \"INFO\",\n\"formatter\": \"standard\",\n\"class\": \"logging.StreamHandler\",\n\"stream\": \"ext://sys.stdout\",\n},\n\"logfile\": {\n\"level\": \"DEBUG\",\n\"formatter\": \"standard\",\n\"class\": \"logging.FileHandler\",\n\"filename\": self.log_path,\n\"mode\": \"a\",\n},\n},\n\"loggers\": {\n\"\": {\n\"handlers\": [\"stdout\", \"logfile\"],\n\"level\": \"DEBUG\",\n\"propagate\": True,\n},\n},\n}\n)\nlogging.captureWarnings(True)\nself.logger = logging.getLogger(\"runner\")\nself.logger.flush = lambda: [h.flush() for h in self.logger.handlers]  # type: ignore\ndef init_print(self, process: int = 0) -&gt; None:\nr\"\"\"\n        Set up `print`.\n        Only print on a specific `process` or when `force = True`.\n        Args:\n            process: The process to `print` on.\n        Notes\n        -----\n        If `self.state.log = True`, the default `print` function will be override by `logging.info`.\n        \"\"\"\nlogger = logging.getLogger(\"print\")\nlogger.flush = lambda: [h.flush for h in logger.handlers]  # type: ignore\nimport builtins as __builtin__  # pylint: disable=C0415\nbuiltin_print = __builtin__.print\n@catch\ndef print(*args, force=False, end=\"\\n\", file=None, flush=False, **kwargs):  # pylint: disable=W0622\nif self.rank == process or force:\nif self.state.log:\nlogger.info(*args, **kwargs)\nelse:\nbuiltin_print(*args, end=end, file=file, flush=flush, **kwargs)\n__builtin__.print = print\n@on_main_process\ndef init_tensorboard(self, *args, **kwargs) -&gt; None:\nr\"\"\"\n        Set up Tensoraoard SummaryWriter.\n        \"\"\"\nraise NotImplementedError\ndef set_seed(self, seed: Optional[int] = None, bias: Optional[int] = None) -&gt; None:\nr\"\"\"\n        Set up random seed.\n        Args:\n            seed: Random seed to set.\n                Defaults to `self.state.seed` (`config.seed`).\n            bias: Make the seed different for each processes.\n                This avoids same data augmentation are applied on every processes.\n                Defaults to `self.rank`.\n                Set to `False` to disable this feature.\n        \"\"\"\nif seed is None:\nseed = self.state.seed\nif bias is None:\nbias = self.rank\nif bias:\nseed += bias\nnp.random.seed(seed)\nrandom.seed(seed)\ndef set_deterministic(self) -&gt; None:\nr\"\"\"\n        Set up deterministic.\n        \"\"\"\nraise NotImplementedError\ndef scale_lr(\nself,\nlr: float,  # pylint: disable=C0103\nlr_scale_factor: Optional[float] = None,\nbatch_size_base: Optional[int] = None,\n) -&gt; float:\nr\"\"\"\n        Scale learning rate according to [linear scaling rule](https://arxiv.org/abs/1706.02677).\n        \"\"\"\n# pylint: disable=W0201\nif lr_scale_factor is None:\nif batch_size_base is None:\nbatch_size_base = getattr(self, \"batch_size_base\", None)\nif batch_size_base is None:\nraise ValueError(\"batch_size_base must be specified to auto scale lr\")\nlr_scale_factor = self.batch_size_equivalent / batch_size_base\nelif batch_size_base is not None:\nwarn(\n\"batch_size_base will be ignored if lr_scale_factor is specified\",\nRuntimeWarning,\n)\nlr = lr * lr_scale_factor  # pylint: disable=C0103, E1101\nself.lr_scale_factor = lr_scale_factor\nreturn lr\ndef step(self, zero_grad: bool = True, batch_size: Optional[int] = None) -&gt; None:\nr\"\"\"\n        Step optimizer and scheduler.\n        This method increment `self.state.steps`.\n        This method also increment `self.state.iters` when `batch_size` is specified.\n        Args:\n            zero_grad: Whether to zero the gradients.\n        \"\"\"\nif self.optimizer is not None:\nself.optimizer.step()\nif zero_grad:\nself.optimizer.zero_grad()\nif self.scheduler is not None:\nself.scheduler.step()\nself.state.steps += 1\nif batch_size is not None:\nself.state.iters += batch_size\n# TODO: Support `drop_last = False`\n# self.state.iters += self.batch_size_equivalent\ndef state_dict(self, cls: Callable = dict) -&gt; Mapping:\nr\"\"\"\n        Return dict of all attributes for checkpoint.\n        \"\"\"\nraise NotImplementedError\n@catch\n@on_main_process\ndef save_checkpoint(self) -&gt; None:\nr\"\"\"\n        Save checkpoint to `self.checkpoint_dir`.\n        The checkpoint will be saved to `self.checkpoint_dir/latest.pth`.\n        If `self.state.save_interval` is positive and `self.state.epochs + 1` is a multiple of `save_interval`,\n        the checkpoint will also be copied to `self.checkpoint_dir/epoch-{self.state.epochs}.pth`.\n        If `self.state.is_best` is `True`, the checkpoint will also be copied to `self.checkpoint_dir/best.pth`.\n        \"\"\"\nlatest_path = os.path.join(self.checkpoint_dir, \"latest.pth\")\nself.save(self.state_dict(), latest_path)\nif (\nhasattr(self, \"save_interval\")\nand self.save_interval &gt; 0\nand (self.state.epochs + 1) % self.save_interval == 0\n):\nsave_path = os.path.join(self.checkpoint_dir, f\"epoch-{self.state.epochs}.pth\")\nshutil.copy(latest_path, save_path)\nif self.is_best:\nbest_path = os.path.join(self.checkpoint_dir, \"best.pth\")\nshutil.copy(latest_path, best_path)\ndef load_checkpoint(  # pylint: disable=W1113\nself, checkpoint: Optional[Union[Mapping, str]] = None, override_state: bool = False, *args, **kwargs\n) -&gt; None:\n\"\"\"\n        Load info from checkpoint.\n        Args:\n            checkpoint: Checkpoint (or its path) to load.\n                Defaults to `self.checkpoint_dir/latest.pth`.\n            override_state: If True, override runner state with checkpoint state.\n                Defaults to `False`.\n            *args: Additional arguments to pass to `self.load`.\n            **kwargs: Additional keyword arguments to pass to `self.load`.\n        Raises:\n            FileNotFoundError: If `checkpoint` does not exists.\n        See Also:\n            [`from_checkpoint`][danling.BaseRunner.from_checkpoint]: Build runner from checkpoint.\n            [`load_pretrained`][danling.BaseRunner.load_pretrained]: Load parameters from pretrained checkpoint.\n        \"\"\"\nif checkpoint is None:\ncheckpoint = os.path.join(self.checkpoint_dir, \"latest.pth\")  # type: ignore\n# TODO: Support loading checkpoints in other format\nif isinstance(checkpoint, str):\nif not os.path.exists(checkpoint):\nraise FileNotFoundError(f\"checkpoint is set to {checkpoint} but does not exist.\")\nself.checkpoint = checkpoint  # pylint: disable=W0201\ncheckpoint: Mapping = self.load(checkpoint, *args, **kwargs)  # type: ignore\n# TODO: Wrap state_dict in a dataclass\nif override_state:\nself.__dict__.update(NestedDict(**checkpoint[\"runner\"]))  # type: ignore\nif self.model is not None and \"model\" in checkpoint:\nmodel = self.unwrap_model(self.model)\nmodel.load_state_dict(checkpoint[\"model\"])  # type: ignore\nif self.optimizer is not None and \"optimizer\" in checkpoint:\nself.optimizer.load_state_dict(checkpoint[\"optimizer\"])  # type: ignore\nif self.scheduler is not None and \"scheduler\" in checkpoint:\nself.scheduler.load_state_dict(checkpoint[\"scheduler\"])  # type: ignore\ndef load_pretrained(self, checkpoint: Union[Mapping, str], *args, **kwargs) -&gt; None:\n\"\"\"\n        Load parameters from pretrained checkpoint.\n        Args:\n            checkpoint: Pretrained checkpoint (or its path) to load.\n            *args: Additional arguments to pass to `self.load`.\n            **kwargs: Additional keyword arguments to pass to `self.load`.\n        Raises:\n            FileNotFoundError: If `checkpoint` does not exists.\n        See Also:\n            [`load_checkpoint`][danling.BaseRunner.load_checkpoint]: Load info from checkpoint.\n        \"\"\"\n# TODO: Support loading checkpoints in other format\nif isinstance(checkpoint, str):\nif not os.path.exists(checkpoint):\nraise FileNotFoundError(f\"pretrained is set to {checkpoint} but does not exist.\")\ncheckpoint: Mapping = self.load(checkpoint, *args, **kwargs)  # type: ignore\nif \"model\" in checkpoint:\ncheckpoint = checkpoint[\"model\"]  # type: ignore\nif \"state_dict\" in checkpoint:\ncheckpoint = checkpoint[\"state_dict\"]  # type: ignore\nmodel = self.unwrap_model(self.model)\nmodel.load_state_dict(checkpoint)  # type: ignore\n@classmethod\ndef from_checkpoint(cls, checkpoint: Union[Mapping, str], *args, **kwargs) -&gt; BaseRunner:\nr\"\"\"\n        Build BaseRunner from checkpoint.\n        Args:\n            checkpoint: Checkpoint (or its path) to load.\n                Defaults to `self.checkpoint_dir/latest.pth`.\n            *args: Additional arguments to pass to `self.load`.\n            **kwargs: Additional keyword arguments to pass to `self.load`.\n        Returns:\n            (BaseRunner):\n        \"\"\"\nif isinstance(checkpoint, str):\ncheckpoint = cls.load(checkpoint, *args, **kwargs)\nrunner = cls(**checkpoint[\"runner\"])  # type: ignore\nrunner.load_checkpoint(checkpoint, override_state=False)\nreturn runner\ndef append_result(self, result) -&gt; None:\nr\"\"\"\n        Append result to `self.state.results`.\n        Warnings:\n            `self.state.results` is heavily relied upon for computing metrics.\n            Failed to use this method may lead to unexpected behavior.\n        \"\"\"\nself.state.results.append(result)\ndef print_result(self) -&gt; None:\nr\"\"\"\n        Print latest and best result.\n        \"\"\"\nprint(f\"results: {self.state.results}\")\nprint(f\"latest result: {self.latest_result}\")\nprint(f\"best result: {self.best_result}\")\n@catch\n@on_main_process\ndef save_result(self) -&gt; None:\nr\"\"\"\n        Save result to `self.dir`.\n        This method will save latest and best result to\n        `self.dir/latest.json` and `self.dir/best.json` respectively.\n        \"\"\"\nresults_path = os.path.join(self.dir, \"results.json\")\nself.save({\"id\": self.state.id, \"name\": self.state.name, \"results\": self.state.results}, results_path, indent=4)\nret = {\"id\": self.state.id, \"name\": self.state.name}\nresult = self.latest_result  # type: ignore\nif isinstance(result, FlatDict):\nresult = result.dict()  # type: ignore\n# This is slower but ensure id is the first key\nif result is not None:\nret.update(result)  # type: ignore\nlatest_path = os.path.join(self.dir, \"latest.json\")\nself.save(ret, latest_path, indent=4)\nif self.is_best:\nbest_path = os.path.join(self.dir, \"best.json\")\nshutil.copy(latest_path, best_path)\n</code></pre>"},{"location":"package/#danling.runner.base_runner.BaseRunner.init_logging","title":"<code>init_logging()</code>","text":"<p>Set up logging.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>@on_main_process\ndef init_logging(self) -&gt; None:\nr\"\"\"\n    Set up logging.\n    \"\"\"\n# Why is setting up proper logging so !@?#! ugly?\nlogging.config.dictConfig(\n{\n\"version\": 1,\n\"disable_existing_loggers\": False,\n\"formatters\": {\n\"standard\": {\"format\": \"%(asctime)s [%(levelname)s] %(name)s: %(message)s\"},\n},\n\"handlers\": {\n\"stdout\": {\n\"level\": \"INFO\",\n\"formatter\": \"standard\",\n\"class\": \"logging.StreamHandler\",\n\"stream\": \"ext://sys.stdout\",\n},\n\"logfile\": {\n\"level\": \"DEBUG\",\n\"formatter\": \"standard\",\n\"class\": \"logging.FileHandler\",\n\"filename\": self.log_path,\n\"mode\": \"a\",\n},\n},\n\"loggers\": {\n\"\": {\n\"handlers\": [\"stdout\", \"logfile\"],\n\"level\": \"DEBUG\",\n\"propagate\": True,\n},\n},\n}\n)\nlogging.captureWarnings(True)\nself.logger = logging.getLogger(\"runner\")\nself.logger.flush = lambda: [h.flush() for h in self.logger.handlers]  # type: ignore\n</code></pre>"},{"location":"package/#danling.runner.base_runner.BaseRunner.init_print","title":"<code>init_print(process=0)</code>","text":"<p>Set up <code>print</code>.</p> <p>Only print on a specific <code>process</code> or when <code>force = True</code>.</p> <p>Parameters:</p> Name Type Description Default <code>process</code> <code>int</code> <p>The process to <code>print</code> on.</p> <code>0</code>"},{"location":"package/#danling.runner.base_runner.BaseRunner.init_print--notes","title":"Notes","text":"<p>If <code>self.state.log = True</code>, the default <code>print</code> function will be override by <code>logging.info</code>.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>def init_print(self, process: int = 0) -&gt; None:\nr\"\"\"\n    Set up `print`.\n    Only print on a specific `process` or when `force = True`.\n    Args:\n        process: The process to `print` on.\n    Notes\n    -----\n    If `self.state.log = True`, the default `print` function will be override by `logging.info`.\n    \"\"\"\nlogger = logging.getLogger(\"print\")\nlogger.flush = lambda: [h.flush for h in logger.handlers]  # type: ignore\nimport builtins as __builtin__  # pylint: disable=C0415\nbuiltin_print = __builtin__.print\n@catch\ndef print(*args, force=False, end=\"\\n\", file=None, flush=False, **kwargs):  # pylint: disable=W0622\nif self.rank == process or force:\nif self.state.log:\nlogger.info(*args, **kwargs)\nelse:\nbuiltin_print(*args, end=end, file=file, flush=flush, **kwargs)\n__builtin__.print = print\n</code></pre>"},{"location":"package/#danling.runner.base_runner.BaseRunner.init_tensorboard","title":"<code>init_tensorboard(*args, **kwargs)</code>","text":"<p>Set up Tensoraoard SummaryWriter.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>@on_main_process\ndef init_tensorboard(self, *args, **kwargs) -&gt; None:\nr\"\"\"\n    Set up Tensoraoard SummaryWriter.\n    \"\"\"\nraise NotImplementedError\n</code></pre>"},{"location":"package/#danling.runner.base_runner.BaseRunner.set_seed","title":"<code>set_seed(seed=None, bias=None)</code>","text":"<p>Set up random seed.</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>Optional[int]</code> <p>Random seed to set. Defaults to <code>self.state.seed</code> (<code>config.seed</code>).</p> <code>None</code> <code>bias</code> <code>Optional[int]</code> <p>Make the seed different for each processes.</p> <p>This avoids same data augmentation are applied on every processes.</p> <p>Defaults to <code>self.rank</code>.</p> <p>Set to <code>False</code> to disable this feature.</p> <code>None</code> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>def set_seed(self, seed: Optional[int] = None, bias: Optional[int] = None) -&gt; None:\nr\"\"\"\n    Set up random seed.\n    Args:\n        seed: Random seed to set.\n            Defaults to `self.state.seed` (`config.seed`).\n        bias: Make the seed different for each processes.\n            This avoids same data augmentation are applied on every processes.\n            Defaults to `self.rank`.\n            Set to `False` to disable this feature.\n    \"\"\"\nif seed is None:\nseed = self.state.seed\nif bias is None:\nbias = self.rank\nif bias:\nseed += bias\nnp.random.seed(seed)\nrandom.seed(seed)\n</code></pre>"},{"location":"package/#danling.runner.base_runner.BaseRunner.set_deterministic","title":"<code>set_deterministic()</code>","text":"<p>Set up deterministic.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>def set_deterministic(self) -&gt; None:\nr\"\"\"\n    Set up deterministic.\n    \"\"\"\nraise NotImplementedError\n</code></pre>"},{"location":"package/#danling.runner.base_runner.BaseRunner.scale_lr","title":"<code>scale_lr(lr, lr_scale_factor=None, batch_size_base=None)</code>","text":"<p>Scale learning rate according to linear scaling rule.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>def scale_lr(\nself,\nlr: float,  # pylint: disable=C0103\nlr_scale_factor: Optional[float] = None,\nbatch_size_base: Optional[int] = None,\n) -&gt; float:\nr\"\"\"\n    Scale learning rate according to [linear scaling rule](https://arxiv.org/abs/1706.02677).\n    \"\"\"\n# pylint: disable=W0201\nif lr_scale_factor is None:\nif batch_size_base is None:\nbatch_size_base = getattr(self, \"batch_size_base\", None)\nif batch_size_base is None:\nraise ValueError(\"batch_size_base must be specified to auto scale lr\")\nlr_scale_factor = self.batch_size_equivalent / batch_size_base\nelif batch_size_base is not None:\nwarn(\n\"batch_size_base will be ignored if lr_scale_factor is specified\",\nRuntimeWarning,\n)\nlr = lr * lr_scale_factor  # pylint: disable=C0103, E1101\nself.lr_scale_factor = lr_scale_factor\nreturn lr\n</code></pre>"},{"location":"package/#danling.runner.base_runner.BaseRunner.step","title":"<code>step(zero_grad=True, batch_size=None)</code>","text":"<p>Step optimizer and scheduler.</p> <p>This method increment <code>self.state.steps</code>.</p> <p>This method also increment <code>self.state.iters</code> when <code>batch_size</code> is specified.</p> <p>Parameters:</p> Name Type Description Default <code>zero_grad</code> <code>bool</code> <p>Whether to zero the gradients.</p> <code>True</code> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>def step(self, zero_grad: bool = True, batch_size: Optional[int] = None) -&gt; None:\nr\"\"\"\n    Step optimizer and scheduler.\n    This method increment `self.state.steps`.\n    This method also increment `self.state.iters` when `batch_size` is specified.\n    Args:\n        zero_grad: Whether to zero the gradients.\n    \"\"\"\nif self.optimizer is not None:\nself.optimizer.step()\nif zero_grad:\nself.optimizer.zero_grad()\nif self.scheduler is not None:\nself.scheduler.step()\nself.state.steps += 1\nif batch_size is not None:\nself.state.iters += batch_size\n</code></pre>"},{"location":"package/#danling.runner.base_runner.BaseRunner.state_dict","title":"<code>state_dict(cls=dict)</code>","text":"<p>Return dict of all attributes for checkpoint.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>def state_dict(self, cls: Callable = dict) -&gt; Mapping:\nr\"\"\"\n    Return dict of all attributes for checkpoint.\n    \"\"\"\nraise NotImplementedError\n</code></pre>"},{"location":"package/#danling.runner.base_runner.BaseRunner.save_checkpoint","title":"<code>save_checkpoint()</code>","text":"<p>Save checkpoint to <code>self.checkpoint_dir</code>.</p> <p>The checkpoint will be saved to <code>self.checkpoint_dir/latest.pth</code>.</p> <p>If <code>self.state.save_interval</code> is positive and <code>self.state.epochs + 1</code> is a multiple of <code>save_interval</code>, the checkpoint will also be copied to <code>self.checkpoint_dir/epoch-{self.state.epochs}.pth</code>.</p> <p>If <code>self.state.is_best</code> is <code>True</code>, the checkpoint will also be copied to <code>self.checkpoint_dir/best.pth</code>.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>@catch\n@on_main_process\ndef save_checkpoint(self) -&gt; None:\nr\"\"\"\n    Save checkpoint to `self.checkpoint_dir`.\n    The checkpoint will be saved to `self.checkpoint_dir/latest.pth`.\n    If `self.state.save_interval` is positive and `self.state.epochs + 1` is a multiple of `save_interval`,\n    the checkpoint will also be copied to `self.checkpoint_dir/epoch-{self.state.epochs}.pth`.\n    If `self.state.is_best` is `True`, the checkpoint will also be copied to `self.checkpoint_dir/best.pth`.\n    \"\"\"\nlatest_path = os.path.join(self.checkpoint_dir, \"latest.pth\")\nself.save(self.state_dict(), latest_path)\nif (\nhasattr(self, \"save_interval\")\nand self.save_interval &gt; 0\nand (self.state.epochs + 1) % self.save_interval == 0\n):\nsave_path = os.path.join(self.checkpoint_dir, f\"epoch-{self.state.epochs}.pth\")\nshutil.copy(latest_path, save_path)\nif self.is_best:\nbest_path = os.path.join(self.checkpoint_dir, \"best.pth\")\nshutil.copy(latest_path, best_path)\n</code></pre>"},{"location":"package/#danling.runner.base_runner.BaseRunner.load_checkpoint","title":"<code>load_checkpoint(checkpoint=None, override_state=False, *args, **kwargs)</code>","text":"<p>Load info from checkpoint.</p> <p>Parameters:</p> Name Type Description Default <code>checkpoint</code> <code>Optional[Union[Mapping, str]]</code> <p>Checkpoint (or its path) to load. Defaults to <code>self.checkpoint_dir/latest.pth</code>.</p> <code>None</code> <code>override_state</code> <code>bool</code> <p>If True, override runner state with checkpoint state. Defaults to <code>False</code>.</p> <code>False</code> <code>*args</code> <p>Additional arguments to pass to <code>self.load</code>.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to <code>self.load</code>.</p> <code>{}</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If <code>checkpoint</code> does not exists.</p> See Also <p><code>from_checkpoint</code>: Build runner from checkpoint. <code>load_pretrained</code>: Load parameters from pretrained checkpoint.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>def load_checkpoint(  # pylint: disable=W1113\nself, checkpoint: Optional[Union[Mapping, str]] = None, override_state: bool = False, *args, **kwargs\n) -&gt; None:\n\"\"\"\n    Load info from checkpoint.\n    Args:\n        checkpoint: Checkpoint (or its path) to load.\n            Defaults to `self.checkpoint_dir/latest.pth`.\n        override_state: If True, override runner state with checkpoint state.\n            Defaults to `False`.\n        *args: Additional arguments to pass to `self.load`.\n        **kwargs: Additional keyword arguments to pass to `self.load`.\n    Raises:\n        FileNotFoundError: If `checkpoint` does not exists.\n    See Also:\n        [`from_checkpoint`][danling.BaseRunner.from_checkpoint]: Build runner from checkpoint.\n        [`load_pretrained`][danling.BaseRunner.load_pretrained]: Load parameters from pretrained checkpoint.\n    \"\"\"\nif checkpoint is None:\ncheckpoint = os.path.join(self.checkpoint_dir, \"latest.pth\")  # type: ignore\n# TODO: Support loading checkpoints in other format\nif isinstance(checkpoint, str):\nif not os.path.exists(checkpoint):\nraise FileNotFoundError(f\"checkpoint is set to {checkpoint} but does not exist.\")\nself.checkpoint = checkpoint  # pylint: disable=W0201\ncheckpoint: Mapping = self.load(checkpoint, *args, **kwargs)  # type: ignore\n# TODO: Wrap state_dict in a dataclass\nif override_state:\nself.__dict__.update(NestedDict(**checkpoint[\"runner\"]))  # type: ignore\nif self.model is not None and \"model\" in checkpoint:\nmodel = self.unwrap_model(self.model)\nmodel.load_state_dict(checkpoint[\"model\"])  # type: ignore\nif self.optimizer is not None and \"optimizer\" in checkpoint:\nself.optimizer.load_state_dict(checkpoint[\"optimizer\"])  # type: ignore\nif self.scheduler is not None and \"scheduler\" in checkpoint:\nself.scheduler.load_state_dict(checkpoint[\"scheduler\"])  # type: ignore\n</code></pre>"},{"location":"package/#danling.runner.base_runner.BaseRunner.load_pretrained","title":"<code>load_pretrained(checkpoint, *args, **kwargs)</code>","text":"<p>Load parameters from pretrained checkpoint.</p> <p>Parameters:</p> Name Type Description Default <code>checkpoint</code> <code>Union[Mapping, str]</code> <p>Pretrained checkpoint (or its path) to load.</p> required <code>*args</code> <p>Additional arguments to pass to <code>self.load</code>.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to <code>self.load</code>.</p> <code>{}</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If <code>checkpoint</code> does not exists.</p> See Also <p><code>load_checkpoint</code>: Load info from checkpoint.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>def load_pretrained(self, checkpoint: Union[Mapping, str], *args, **kwargs) -&gt; None:\n\"\"\"\n    Load parameters from pretrained checkpoint.\n    Args:\n        checkpoint: Pretrained checkpoint (or its path) to load.\n        *args: Additional arguments to pass to `self.load`.\n        **kwargs: Additional keyword arguments to pass to `self.load`.\n    Raises:\n        FileNotFoundError: If `checkpoint` does not exists.\n    See Also:\n        [`load_checkpoint`][danling.BaseRunner.load_checkpoint]: Load info from checkpoint.\n    \"\"\"\n# TODO: Support loading checkpoints in other format\nif isinstance(checkpoint, str):\nif not os.path.exists(checkpoint):\nraise FileNotFoundError(f\"pretrained is set to {checkpoint} but does not exist.\")\ncheckpoint: Mapping = self.load(checkpoint, *args, **kwargs)  # type: ignore\nif \"model\" in checkpoint:\ncheckpoint = checkpoint[\"model\"]  # type: ignore\nif \"state_dict\" in checkpoint:\ncheckpoint = checkpoint[\"state_dict\"]  # type: ignore\nmodel = self.unwrap_model(self.model)\nmodel.load_state_dict(checkpoint)  # type: ignore\n</code></pre>"},{"location":"package/#danling.runner.base_runner.BaseRunner.from_checkpoint","title":"<code>from_checkpoint(checkpoint, *args, **kwargs)</code>  <code>classmethod</code>","text":"<p>Build BaseRunner from checkpoint.</p> <p>Parameters:</p> Name Type Description Default <code>checkpoint</code> <code>Union[Mapping, str]</code> <p>Checkpoint (or its path) to load. Defaults to <code>self.checkpoint_dir/latest.pth</code>.</p> required <code>*args</code> <p>Additional arguments to pass to <code>self.load</code>.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to <code>self.load</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>BaseRunner</code> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>@classmethod\ndef from_checkpoint(cls, checkpoint: Union[Mapping, str], *args, **kwargs) -&gt; BaseRunner:\nr\"\"\"\n    Build BaseRunner from checkpoint.\n    Args:\n        checkpoint: Checkpoint (or its path) to load.\n            Defaults to `self.checkpoint_dir/latest.pth`.\n        *args: Additional arguments to pass to `self.load`.\n        **kwargs: Additional keyword arguments to pass to `self.load`.\n    Returns:\n        (BaseRunner):\n    \"\"\"\nif isinstance(checkpoint, str):\ncheckpoint = cls.load(checkpoint, *args, **kwargs)\nrunner = cls(**checkpoint[\"runner\"])  # type: ignore\nrunner.load_checkpoint(checkpoint, override_state=False)\nreturn runner\n</code></pre>"},{"location":"package/#danling.runner.base_runner.BaseRunner.append_result","title":"<code>append_result(result)</code>","text":"<p>Append result to <code>self.state.results</code>.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>def append_result(self, result) -&gt; None:\nr\"\"\"\n    Append result to `self.state.results`.\n    Warnings:\n        `self.state.results` is heavily relied upon for computing metrics.\n        Failed to use this method may lead to unexpected behavior.\n    \"\"\"\nself.state.results.append(result)\n</code></pre>"},{"location":"package/#danling.runner.base_runner.BaseRunner.print_result","title":"<code>print_result()</code>","text":"<p>Print latest and best result.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>def print_result(self) -&gt; None:\nr\"\"\"\n    Print latest and best result.\n    \"\"\"\nprint(f\"results: {self.state.results}\")\nprint(f\"latest result: {self.latest_result}\")\nprint(f\"best result: {self.best_result}\")\n</code></pre>"},{"location":"package/#danling.runner.base_runner.BaseRunner.save_result","title":"<code>save_result()</code>","text":"<p>Save result to <code>self.dir</code>.</p> <p>This method will save latest and best result to <code>self.dir/latest.json</code> and <code>self.dir/best.json</code> respectively.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>@catch\n@on_main_process\ndef save_result(self) -&gt; None:\nr\"\"\"\n    Save result to `self.dir`.\n    This method will save latest and best result to\n    `self.dir/latest.json` and `self.dir/best.json` respectively.\n    \"\"\"\nresults_path = os.path.join(self.dir, \"results.json\")\nself.save({\"id\": self.state.id, \"name\": self.state.name, \"results\": self.state.results}, results_path, indent=4)\nret = {\"id\": self.state.id, \"name\": self.state.name}\nresult = self.latest_result  # type: ignore\nif isinstance(result, FlatDict):\nresult = result.dict()  # type: ignore\n# This is slower but ensure id is the first key\nif result is not None:\nret.update(result)  # type: ignore\nlatest_path = os.path.join(self.dir, \"latest.json\")\nself.save(ret, latest_path, indent=4)\nif self.is_best:\nbest_path = os.path.join(self.dir, \"best.json\")\nshutil.copy(latest_path, best_path)\n</code></pre>"},{"location":"package/#danling.NestedTensor","title":"<code>NestedTensor</code>","text":"<p>Wrap a sequence of tensors into a single tensor with a mask.</p> <p>In sequence to sequence tasks, elements of a batch are usually not of the same length. This made it tricky to use a single tensor to represent a batch of sequences.</p> <p><code>NestedTensor</code> allows to store a sequence of tensors of different lengths in a single object. It also provides a mask that can be used to retrieve the original sequence of tensors.</p> <p>Attributes:</p> Name Type Description <code>storage</code> <code>Sequence[Tensor]</code> <p>The sequence of tensors.</p> <code>batch_first</code> <code>bool</code> <p>Whether the first dimension of the tensors is the batch dimension.</p> <p>If <code>True</code>, the first dimension is the batch dimension, i.e., <code>B, N, *</code>.</p> <p>If <code>False</code>, the first dimension is the sequence dimension, i.e., <code>N, B, *</code></p> <code>padding_value</code> <code>SupportsFloat</code> <p>The value used to pad the tensors.</p> <p>Parameters:</p> Name Type Description Default <code>tensors</code> <code>Iterable[Tensor]</code> required <code>batch_first</code> <code>bool</code> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>tensors</code> is not a sequence.</p> <code>ValueError</code> <p>If <code>tensors</code> is empty.</p> Notes <p>We have rewritten the <code>__getattr__</code> function to support as much native tensor operations as possible. However, not all operations are tested.</p> <p>Please file an issue if you find any bugs.</p> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n&gt;&gt;&gt; nested_tensor.shape\ntorch.Size([2, 3])\n&gt;&gt;&gt; nested_tensor.device\ndevice(type='cpu')\n&gt;&gt;&gt; nested_tensor.dtype\ntorch.int64\n&gt;&gt;&gt; nested_tensor.tensor\ntensor([[1, 2, 3],\n[4, 5, 0]])\n&gt;&gt;&gt; nested_tensor.mask\ntensor([[ True,  True,  True],\n[ True,  True, False]])\n&gt;&gt;&gt; nested_tensor.to(torch.float).tensor\ntensor([[1., 2., 3.],\n[4., 5., 0.]])\n&gt;&gt;&gt; nested_tensor.half().tensor\ntensor([[1., 2., 3.],\n[4., 5., 0.]], dtype=torch.float16)\n</code></pre> Source code in <code>danling/tensors/nested_tensor.py</code> Python<pre><code>class NestedTensor:\nr\"\"\"\n    Wrap a sequence of tensors into a single tensor with a mask.\n    In sequence to sequence tasks, elements of a batch are usually not of the same length.\n    This made it tricky to use a single tensor to represent a batch of sequences.\n    `NestedTensor` allows to store a sequence of tensors of different lengths in a single object.\n    It also provides a mask that can be used to retrieve the original sequence of tensors.\n    Attributes:\n        storage: The sequence of tensors.\n        batch_first:  Whether the first dimension of the tensors is the batch dimension.\n            If `True`, the first dimension is the batch dimension, i.e., `B, N, *`.\n            If `False`, the first dimension is the sequence dimension, i.e., `N, B, *`\n        padding_value: The value used to pad the tensors.\n    Args:\n        tensors:\n        batch_first:\n    Raises:\n        ValueError: If `tensors` is not a sequence.\n        ValueError: If `tensors` is empty.\n    Notes:\n        We have rewritten the `__getattr__` function to support as much native tensor operations as possible.\n        However, not all operations are tested.\n        Please file an issue if you find any bugs.\n    Examples:\n    ```python\n    &gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n    &gt;&gt;&gt; nested_tensor.shape\n    torch.Size([2, 3])\n    &gt;&gt;&gt; nested_tensor.device\n    device(type='cpu')\n    &gt;&gt;&gt; nested_tensor.dtype\n    torch.int64\n    &gt;&gt;&gt; nested_tensor.tensor\n    tensor([[1, 2, 3],\n            [4, 5, 0]])\n    &gt;&gt;&gt; nested_tensor.mask\n    tensor([[ True,  True,  True],\n            [ True,  True, False]])\n    &gt;&gt;&gt; nested_tensor.to(torch.float).tensor\n    tensor([[1., 2., 3.],\n            [4., 5., 0.]])\n    &gt;&gt;&gt; nested_tensor.half().tensor\n    tensor([[1., 2., 3.],\n            [4., 5., 0.]], dtype=torch.float16)\n    ```\n    \"\"\"\n# pylint: disable=C0103\nstorage: Sequence[Tensor] = []\nbatch_first: bool = True\npadding_value: SupportsFloat = 0.0\nmask_value: bool = False\ndef __init__(\nself,\ntensors: Iterable[Tensor],\nbatch_first: bool = True,\npadding_value: SupportsFloat = 0.0,\nmask_value: bool = False,\n) -&gt; None:\nif not isinstance(tensors, Iterable):\nraise ValueError(f\"NestedTensor must be initialised with an Iterable, bug got {type(tensors)}.\")\ntensors = list(tensors)\nif len(tensors) == 0:\nraise ValueError(\"NestedTensor must be initialised with a non-empty Iterable.\")\nif not isinstance(tensors[0], Tensor):\ntensors = [torch.tensor(tensor) for tensor in tensors]  # pylint: disable=E1101\nself.storage = tensors\nself.batch_first = batch_first\nself.padding_value = padding_value\nself.mask_value = mask_value\n@property\ndef tensor(self) -&gt; Tensor:\nr\"\"\"\n        Return a single tensor by padding all the tensors.\n        Returns:\n            (torch.Tensor):\n        Examples:\n        ```python\n        &gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n        &gt;&gt;&gt; nested_tensor.tensor\n        tensor([[1, 2, 3],\n                [4, 5, 0]])\n        ```\n        \"\"\"\nreturn self._tensor(tuple(self.storage), self.batch_first, float(self.padding_value))\n@property\ndef mask(self) -&gt; Tensor:\nr\"\"\"\n        Padding mask of `tensor`.\n        Returns:\n            (torch.Tensor):\n        Examples:\n        ```python\n        &gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n        &gt;&gt;&gt; nested_tensor.mask\n        tensor([[ True,  True,  True],\n                [ True,  True, False]])\n        ```\n        \"\"\"\nreturn self._mask(tuple(self.storage), self.mask_value)\n@property\ndef device(self) -&gt; torch.device:  # pylint: disable=E1101\nr\"\"\"\n        Device of the NestedTensor.\n        Returns:\n            (torch.Tensor):\n        Examples:\n        ```python\n        &gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n        &gt;&gt;&gt; nested_tensor.device\n        device(type='cpu')\n        ```\n        \"\"\"\nreturn self._device(tuple(self.storage))\n@property\ndef shape(self) -&gt; torch.Size:  # pylint: disable=E1101\nr\"\"\"\n        Alias for `size`.\n        Returns:\n            (torch.Size):\n        Examples:\n        ```python\n        &gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n        &gt;&gt;&gt; nested_tensor.shape\n        torch.Size([2, 3])\n        &gt;&gt;&gt; nested_tensor.storage.append(torch.tensor([6, 7, 8, 9]))\n        &gt;&gt;&gt; nested_tensor.shape\n        torch.Size([3, 4])\n        ```\n        \"\"\"\nreturn self.size()\ndef size(self) -&gt; torch.Size:  # pylint: disable=E1101\nr\"\"\"\n        Shape of the NestedTensor.\n        Returns:\n            (torch.Size):\n        Examples:\n        ```python\n        &gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n        &gt;&gt;&gt; nested_tensor.size()\n        torch.Size([2, 3])\n        &gt;&gt;&gt; nested_tensor.storage[1] = torch.tensor([4, 5, 6, 7])\n        &gt;&gt;&gt; nested_tensor.size()\n        torch.Size([2, 4])\n        ```\n        \"\"\"\nreturn self._size(tuple(self.storage))\ndef where(self, condition, other) -&gt; NestedTensor:\nr\"\"\"\n        Return a NestedTensor of elements selected from either self or other, depending on condition.\n        Returns:\n            (NestedTensor):\n        Examples:\n        ```python\n        &gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n        &gt;&gt;&gt; nested_tensor.size()\n        torch.Size([2, 3])\n        &gt;&gt;&gt; nested_tensor.storage[1] = torch.tensor([4, 5, 6, 7])\n        &gt;&gt;&gt; nested_tensor.size()\n        torch.Size([2, 4])\n        ```\n        \"\"\"\nif isinstance(condition, NestedTensor) and isinstance(other, NestedTensor):\nreturn NestedTensor(\n[x.where(c, y) for x, c, y in zip(self.storage, condition.storage, other.storage)], **self._state()\n)\nif isinstance(condition, NestedTensor):\nreturn NestedTensor([x.where(c, other) for x, c in zip(self.storage, condition.storage)], **self._state())\nif isinstance(other, NestedTensor):\nreturn NestedTensor([x.where(condition, y) for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor(x.where(condition, other) for x in self.storage)\ndef __abs__(self):\nreturn NestedTensor([abs(value) for value in self.storage], **self._state())\ndef __add__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([x + y for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([value + other for value in self.storage], **self._state())\ndef __radd__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([y + x for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([other + value for value in self.storage], **self._state())\ndef __iadd__(self, other):\nif isinstance(other, NestedTensor):\nfor x, y in zip(self.storage, other.storage):\nx += y\nelse:\nfor value in self.storage:\nvalue += other\nreturn self\ndef __and__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([x &amp; y for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([value &amp; other for value in self.storage], **self._state())\ndef __rand__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([y &amp; x for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([other &amp; value for value in self.storage], **self._state())\ndef __iand__(self, other):\nif isinstance(other, NestedTensor):\nfor x, y in zip(self.storage, other.storage):\nx &amp;= y\nelse:\nfor value in self.storage:\nvalue &amp;= other\nreturn self\ndef __floordiv__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([x // y for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([value // other for value in self.storage], **self._state())\ndef __rfloordiv__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([y // x for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([other // value for value in self.storage], **self._state())\ndef __ifloordiv__(self, other):\nif isinstance(other, NestedTensor):\nfor x, y in zip(self.storage, other.storage):\nx //= y\nelse:\nfor value in self.storage:\nvalue //= other\nreturn self\ndef __mod__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([x % y for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([value % other for value in self.storage], **self._state())\ndef __rmod__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([y % x for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([other % value for value in self.storage], **self._state())\ndef __imod__(self, other):\nif isinstance(other, NestedTensor):\nfor x, y in zip(self.storage, other.storage):\nx %= y\nelse:\nfor value in self.storage:\nvalue %= other\nreturn self\ndef __mul__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([x * y for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([value * other for value in self.storage], **self._state())\ndef __rmul__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([y * x for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([other * value for value in self.storage], **self._state())\ndef __imul__(self, other):\nif isinstance(other, NestedTensor):\nfor x, y in zip(self.storage, other.storage):\nx *= y\nelse:\nfor value in self.storage:\nvalue *= other\nreturn self\ndef __matmul__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([x @ y for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([value @ other for value in self.storage], **self._state())\ndef __rmatmul__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([y @ x for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([other @ value for value in self.storage], **self._state())\ndef __imatmul__(self, other):\nif isinstance(other, NestedTensor):\nfor x, y in zip(self.storage, other.storage):\nx @= y\nelse:\nfor value in self.storage:\nvalue @= other\nreturn self\ndef __pow__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([x**y for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([value**other for value in self.storage], **self._state())\ndef __rpow__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([y**x for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([other**value for value in self.storage], **self._state())\ndef __ipow__(self, other):\nif isinstance(other, NestedTensor):\nfor x, y in zip(self.storage, other.storage):\nx *= y\nelse:\nfor value in self.storage:\nvalue *= other\nreturn self\ndef __truediv__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([x / y for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([value / other for value in self.storage], **self._state())\ndef __rtruediv__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([y / x for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([other / value for value in self.storage], **self._state())\ndef __itruediv__(self, other):\nif isinstance(other, NestedTensor):\nfor x, y in zip(self.storage, other.storage):\nx /= y\nelse:\nfor value in self.storage:\nvalue /= other\nreturn self\ndef __sub__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([x - y for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([value - other for value in self.storage], **self._state())\ndef __rsub__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([y - x for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([other - value for value in self.storage], **self._state())\ndef __isub__(self, other):\nif isinstance(other, NestedTensor):\nfor x, y in zip(self.storage, other.storage):\nx -= y\nelse:\nfor value in self.storage:\nvalue -= other\nreturn self\ndef __getitem__(self, index) -&gt; Tuple[Tensor, Tensor]:\nret = self.storage[index]\nif isinstance(ret, Tensor):\nreturn ret, torch.ones_like(ret)  # pylint: disable=E1101\nreturn self.tensor, self.mask\ndef __getattr__(self, name) -&gt; Any:\nif not self.storage:\nraise ValueError(f\"Unable to get {name} from an empty {self.__class__.__name__}\")\nret = [getattr(i, name) for i in self.storage]\nelem = ret[0]\nif isinstance(elem, Tensor):\nreturn NestedTensor(ret, **self._state())\nif callable(elem):\nreturn NestedTensorFuncWrapper(ret, state=self._state())\nif elem.__hash__ is not None and len(set(ret)) == 1:\nreturn elem\nreturn ret\n@classmethod\ndef __torch_function__(cls, func, types, args=(), kwargs=None):\nif kwargs is None:\nkwargs = {}\nif func not in NestedTensorFunc or not all(issubclass(t, (torch.Tensor, NestedTensor)) for t in types):\nargs = [a.tensor() if hasattr(a, \"tensor\") else a for a in args]\nreturn func(*args, **kwargs)\nreturn NestedTensorFunc[func](*args, **kwargs)\ndef __len__(self) -&gt; int:\nreturn len(self.storage)\ndef __eq__(self, other) -&gt; Union[bool, Tensor, NestedTensor]:  # type: ignore[override]\nif isinstance(other, NestedTensor):\nreturn self.storage == other.storage\nif isinstance(other, Tensor):\nreturn self.tensor == other\nif isinstance(other, SupportsFloat):\nreturn NestedTensor([x == other for x in self.storage], **self._state())\nraise NotImplementedError(f\"Cannot compare {self.__class__.__name__} with {other.__class__.__name__}\")\ndef _state(self) -&gt; Mapping:\nreturn {k: v for k, v in self.__dict__.items() if k != \"storage\"}\ndef __state__(self) -&gt; Mapping:\nreturn self.__dict__\ndef __setstate__(self, state: Mapping) -&gt; None:\nself.__dict__.update(state)\ndef __repr__(self):\nreturn self.__class__.__name__ + repr(self.tensor)[len(self.tensor.__class__.__name__) :]  # noqa: E203\n@staticmethod\n@lru_cache(maxsize=None)\ndef _tensor(storage, batch_first, padding_value: float = 0) -&gt; Tensor:\nif storage[0].dim() == 0:\nreturn torch.stack(storage, dim=0)  # pylint: disable=E1101\nreturn pad_sequence(storage, batch_first=batch_first, padding_value=padding_value)\n@staticmethod\n@lru_cache(maxsize=None)\ndef _mask(storage, mask_value: bool = False) -&gt; Tensor:\n# pylint: disable=E1101\nif storage[0].dim() == 0:\nreturn torch.ones(len(storage), dtype=torch.bool)\nlens = torch.tensor([len(t) for t in storage], device=storage[0].device)\narange = torch.arange(max(lens), device=storage[0].device)[None, :]\nreturn arange &gt;= lens[:, None] if mask_value else arange &lt; lens[:, None]\n@staticmethod\n@lru_cache(maxsize=None)\ndef _device(storage) -&gt; torch.device:  # pylint: disable=E1101\nreturn storage[0].device\n@staticmethod\n@lru_cache(maxsize=None)\ndef _size(storage) -&gt; torch.Size:\n# pylint: disable=E1101\nif storage[0].dim() == 0:\nreturn torch.Size([len(storage)])\nreturn torch.Size([len(storage), max(t.shape[0] for t in storage), *storage[0].shape[1:]])\n</code></pre>"},{"location":"package/#danling.tensors.nested_tensor.NestedTensor.tensor","title":"<code>tensor: Tensor</code>  <code>property</code>","text":"<p>Return a single tensor by padding all the tensors.</p> <p>Returns:</p> Type Description <code>torch.Tensor</code> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n&gt;&gt;&gt; nested_tensor.tensor\ntensor([[1, 2, 3],\n[4, 5, 0]])\n</code></pre>"},{"location":"package/#danling.tensors.nested_tensor.NestedTensor.mask","title":"<code>mask: Tensor</code>  <code>property</code>","text":"<p>Padding mask of <code>tensor</code>.</p> <p>Returns:</p> Type Description <code>torch.Tensor</code> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n&gt;&gt;&gt; nested_tensor.mask\ntensor([[ True,  True,  True],\n[ True,  True, False]])\n</code></pre>"},{"location":"package/#danling.tensors.nested_tensor.NestedTensor.device","title":"<code>device: torch.device</code>  <code>property</code>","text":"<p>Device of the NestedTensor.</p> <p>Returns:</p> Type Description <code>torch.Tensor</code> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n&gt;&gt;&gt; nested_tensor.device\ndevice(type='cpu')\n</code></pre>"},{"location":"package/#danling.tensors.nested_tensor.NestedTensor.shape","title":"<code>shape: torch.Size</code>  <code>property</code>","text":"<p>Alias for <code>size</code>.</p> <p>Returns:</p> Type Description <code>torch.Size</code> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n&gt;&gt;&gt; nested_tensor.shape\ntorch.Size([2, 3])\n&gt;&gt;&gt; nested_tensor.storage.append(torch.tensor([6, 7, 8, 9]))\n&gt;&gt;&gt; nested_tensor.shape\ntorch.Size([3, 4])\n</code></pre>"},{"location":"package/#danling.tensors.nested_tensor.NestedTensor.size","title":"<code>size()</code>","text":"<p>Shape of the NestedTensor.</p> <p>Returns:</p> Type Description <code>torch.Size</code> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n&gt;&gt;&gt; nested_tensor.size()\ntorch.Size([2, 3])\n&gt;&gt;&gt; nested_tensor.storage[1] = torch.tensor([4, 5, 6, 7])\n&gt;&gt;&gt; nested_tensor.size()\ntorch.Size([2, 4])\n</code></pre> Source code in <code>danling/tensors/nested_tensor.py</code> Python<pre><code>def size(self) -&gt; torch.Size:  # pylint: disable=E1101\nr\"\"\"\n    Shape of the NestedTensor.\n    Returns:\n        (torch.Size):\n    Examples:\n    ```python\n    &gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n    &gt;&gt;&gt; nested_tensor.size()\n    torch.Size([2, 3])\n    &gt;&gt;&gt; nested_tensor.storage[1] = torch.tensor([4, 5, 6, 7])\n    &gt;&gt;&gt; nested_tensor.size()\n    torch.Size([2, 4])\n    ```\n    \"\"\"\nreturn self._size(tuple(self.storage))\n</code></pre>"},{"location":"package/#danling.tensors.nested_tensor.NestedTensor.where","title":"<code>where(condition, other)</code>","text":"<p>Return a NestedTensor of elements selected from either self or other, depending on condition.</p> <p>Returns:</p> Type Description <code>NestedTensor</code> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n&gt;&gt;&gt; nested_tensor.size()\ntorch.Size([2, 3])\n&gt;&gt;&gt; nested_tensor.storage[1] = torch.tensor([4, 5, 6, 7])\n&gt;&gt;&gt; nested_tensor.size()\ntorch.Size([2, 4])\n</code></pre> Source code in <code>danling/tensors/nested_tensor.py</code> Python<pre><code>def where(self, condition, other) -&gt; NestedTensor:\nr\"\"\"\n    Return a NestedTensor of elements selected from either self or other, depending on condition.\n    Returns:\n        (NestedTensor):\n    Examples:\n    ```python\n    &gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n    &gt;&gt;&gt; nested_tensor.size()\n    torch.Size([2, 3])\n    &gt;&gt;&gt; nested_tensor.storage[1] = torch.tensor([4, 5, 6, 7])\n    &gt;&gt;&gt; nested_tensor.size()\n    torch.Size([2, 4])\n    ```\n    \"\"\"\nif isinstance(condition, NestedTensor) and isinstance(other, NestedTensor):\nreturn NestedTensor(\n[x.where(c, y) for x, c, y in zip(self.storage, condition.storage, other.storage)], **self._state()\n)\nif isinstance(condition, NestedTensor):\nreturn NestedTensor([x.where(c, other) for x, c in zip(self.storage, condition.storage)], **self._state())\nif isinstance(other, NestedTensor):\nreturn NestedTensor([x.where(condition, y) for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor(x.where(condition, other) for x in self.storage)\n</code></pre>"},{"location":"package/#danling.flexible_decorator","title":"<code>flexible_decorator(maybe_decorator=None)</code>","text":"<p>Decorator to allow bracket-less when no arguments are passed.</p> <p>Examples:</p> <p>For decorator defined as follows:</p> Python<pre><code>&gt;&gt;&gt; @flexible_decorator\n... def decorator(*args, **kwargs):\n...     def wrapper(func, *args, **kwargs):\n...         pass\n...     return wrapper\n</code></pre> <p>The following two are equivalent:</p> Python<pre><code>&gt;&gt;&gt; @decorator\n... def func(*args, **kwargs):\n...     pass\n</code></pre> Python<pre><code>&gt;&gt;&gt; @decorator()\n... def func(*args, **kwargs):\n...     pass\n</code></pre> Source code in <code>danling/utils/decorators.py</code> Python<pre><code>def flexible_decorator(maybe_decorator: Optional[Callable] = None):\n\"\"\"\n    Decorator to allow bracket-less when no arguments are passed.\n    Examples:\n    For decorator defined as follows:\n    ```python\n    &gt;&gt;&gt; @flexible_decorator\n    ... def decorator(*args, **kwargs):\n    ...     def wrapper(func, *args, **kwargs):\n    ...         pass\n    ...     return wrapper\n    ```\n    The following two are equivalent:\n    ```python\n    &gt;&gt;&gt; @decorator\n    ... def func(*args, **kwargs):\n    ...     pass\n    ```\n    ```python\n    &gt;&gt;&gt; @decorator()\n    ... def func(*args, **kwargs):\n    ...     pass\n    ```\n    \"\"\"\ndef decorator(func: Callable):\n@wraps(decorator)\ndef wrapper(*args, **kwargs):\nif len(args) == 1 and isfunction(args[0]):\nreturn func(**kwargs)(args[0])\nreturn func(*args, **kwargs)\nreturn wrapper\nif maybe_decorator is None:\nreturn decorator\nreturn decorator(maybe_decorator)\n</code></pre>"},{"location":"package/#danling.save","title":"<code>save(obj, file, *args, **kwargs)</code>","text":"<p>Save any file with supported extensions.</p> Source code in <code>danling/utils/io.py</code> Python<pre><code>def save(obj: Any, file: PathStr, *args: List[Any], **kwargs: Dict[str, Any]) -&gt; File:  # pylint: disable=R0912\nr\"\"\"\n    Save any file with supported extensions.\n    \"\"\"\nextension = os.path.splitext(file)[-1].lower()[1:]  # type: ignore\nif extension in PYTORCH:\nif not TORCH_AVAILABLE:\nraise ImportError(f\"Trying to save {obj} to {file!r} but torch is not installed.\")\ntorch.save(obj, file, *args, **kwargs)  # type: ignore\nelif extension in NUMPY:\nif not NUMPY_AVAILABLE:\nraise ImportError(f\"Trying to save {obj} to {file!r} but numpy is not installed.\")\nnumpy.save(file, obj, *args, **kwargs)  # type: ignore\nelif extension in CSV:\nif isinstance(obj, pandas.DataFrame):\nobj.to_csv(file, *args, **kwargs)  # type: ignore\nelse:\nraise NotImplementedError(f\"Trying to save {obj} to {file!r} but is not supported\")\nelif extension in JSON:\nif isinstance(obj, FlatDict):\nobj.json(file)\nelse:\nwith open(file, \"w\") as fp:  # pylint: disable=W1514, C0103\njson.dump(obj, fp, *args, **kwargs)  # type: ignore\nelif extension in YAML:\nif isinstance(obj, FlatDict):\nobj.yaml(file)\nelse:\nwith open(file, \"w\") as fp:  # pylint: disable=W1514, C0103\nyaml.dump(obj, fp, *args, **kwargs)  # type: ignore\nelif extension in PICKLE:\nwith open(file, \"wb\") as fp:  # type: ignore # pylint: disable=C0103\npickle.dump(obj, fp, *args, **kwargs)  # type: ignore\nelse:\nraise ValueError(f\"Tying to save {obj} to {file!r} with unsupported extension={extension!r}\")\nreturn file\n</code></pre>"},{"location":"package/#danling.catch","title":"<code>catch(error=Exception, exclude=None, verbose=True, print_args=False)</code>","text":"<p>Decorator to catch <code>error</code> except for <code>exclude</code>. Detailed traceback will be printed to <code>stderr</code>.</p> <p><code>catch</code> is extremely useful for unfatal errors. For example, <code>Runner</code> saves checkpoint regularly, however, this might break running if the space is full. Decorating <code>save</code> method with <code>catch</code> will allow you to catch these errors and continue your running.</p> <p>Parameters:</p> Name Type Description Default <code>error</code> <code>Type[Exception]</code> <code>Exception</code> <code>exclude</code> <code>Optional[Type[Exception]]</code> <code>None</code> <code>print_args</code> <code>bool</code> <p>Whether to print the arguments passed to the function.</p> <code>False</code> Source code in <code>danling/utils/decorators.py</code> Python<pre><code>@flexible_decorator\ndef catch(\nerror: Type[Exception] = Exception,\nexclude: Optional[Type[Exception]] = None,\nverbose: bool = True,\nprint_args: bool = False,\n):\n\"\"\"\n    Decorator to catch `error` except for `exclude`.\n    Detailed traceback will be printed to `stderr`.\n    `catch` is extremely useful for unfatal errors.\n    For example, `Runner` saves checkpoint regularly, however, this might break running if the space is full.\n    Decorating `save` method with `catch` will allow you to catch these errors and continue your running.\n    Args:\n        error:\n        exclude:\n        print_args: Whether to print the arguments passed to the function.\n    \"\"\"\ndef decorator(\nfunc, error: Type[Exception] = Exception, exclude: Optional[Type[Exception]] = None, print_args: bool = False\n):\n@wraps(func)\ndef wrapper(*args, **kwargs):  # pylint: disable=R1710\ntry:\nreturn func(*args, **kwargs)\nexcept error as exc:  # pylint: disable=W0703\nif exclude is not None and isinstance(exc, exclude):\nraise exc\nif verbose:\nmessage = format_exc()\nmessage += f\"\\nencoutered when calling {func}\"\nif print_args:\nmessage += f\"with args {args} and kwargs {kwargs}\"\nprint(message, file=stderr, force=True)\nreturn wrapper\nreturn lambda func: decorator(func, error, exclude, print_args)\n</code></pre>"},{"location":"package/#danling.load","title":"<code>load(file, *args, **kwargs)</code>","text":"<p>Load any file with supported extensions.</p> Source code in <code>danling/utils/io.py</code> Python<pre><code>def load(file: PathStr, *args: List[Any], **kwargs: Dict[str, Any]) -&gt; Any:\nr\"\"\"\n    Load any file with supported extensions.\n    \"\"\"\nif not os.path.isfile(file):\nraise ValueError(f\"Trying to load {file!r} but it is not a file.\")\nextension = os.path.splitext(file)[-1].lower()[1:]  # type: ignore\nif extension in PYTORCH:\nif not TORCH_AVAILABLE:\nraise ImportError(f\"Trying to load {file!r} but torch is not installed.\")\nreturn torch.load(file, *args, **kwargs)  # type: ignore\nif extension in NUMPY:\nif not NUMPY_AVAILABLE:\nraise ImportError(f\"Trying to load {file!r} but numpy is not installed.\")\nreturn numpy.load(file, *args, **kwargs)  # type: ignore\nif extension in CSV:\nif not PANDAS_AVAILABLE:\nraise ImportError(f\"Trying to load {file!r} but pandas is not installed.\")\nreturn pandas.read_csv(file, *args, **kwargs)  # type: ignore\nif extension in JSON:\nwith open(file, \"r\") as fp:  # pylint: disable=W1514, C0103\nreturn json.load(fp, *args, **kwargs)  # type: ignore\nif extension in YAML:\nwith open(file, \"r\") as fp:  # pylint: disable=W1514, C0103\nreturn yaml.load(fp, *args, **kwargs)  # type: ignore\nif extension in PICKLE:\nwith open(file, \"rb\") as fp:  # type: ignore # pylint: disable=C0103\nreturn pickle.load(fp, *args, **kwargs)  # type: ignore\nraise ValueError(f\"Tying to load {file!r} with unsupported extension={extension!r}\")\n</code></pre>"},{"location":"package/#danling.method_cache","title":"<code>method_cache(*cache_args, **lru_kwargs)</code>","text":"<p>Decorator to cache the result of an instance method.</p> <p><code>functools.lru_cache</code> uses a strong reference to the instance, which will make the instance immortal and break the garbage collection.</p> <p><code>method_cache</code> uses a weak reference to the instance and works fine.</p> <p>https://rednafi.github.io/reflections/dont-wrap-instance-methods-with-functoolslru_cache-decorator-in-python.html</p> Source code in <code>danling/utils/decorators.py</code> Python<pre><code>def method_cache(*cache_args, **lru_kwargs):\nr\"\"\"\n    Decorator to cache the result of an instance method.\n    `functools.lru_cache` uses a strong reference to the instance,\n    which will make the instance immortal and break the garbage collection.\n    `method_cache` uses a weak reference to the instance and works fine.\n    https://rednafi.github.io/reflections/dont-wrap-instance-methods-with-functoolslru_cache-decorator-in-python.html\n    \"\"\"\ndef decorator(func):\n@wraps(func)\ndef wrapper(self, *args, **kwargs):\nself_ref = ref(self)\n@wraps(func)\n@lru_cache(*cache_args, **lru_kwargs)\ndef cached_method(*args, **kwargs):\nreturn func(self_ref(), *args, **kwargs)\nsetattr(self, func.__name__, cached_method)\nreturn cached_method(*args, **kwargs)\nreturn wrapper\nreturn decorator\n</code></pre>"},{"location":"package/#danling.is_json_serializable","title":"<code>is_json_serializable(obj)</code>","text":"<p>Check if <code>obj</code> is JSON serializable.</p> Source code in <code>danling/utils/io.py</code> Python<pre><code>def is_json_serializable(obj: Any) -&gt; bool:\nr\"\"\"\n    Check if `obj` is JSON serializable.\n    \"\"\"\ntry:\njson.dumps(obj)\nreturn True\nexcept (TypeError, OverflowError):\nreturn False\n</code></pre>"},{"location":"package/#danling.ensure_dir","title":"<code>ensure_dir(func)</code>","text":"<p>Decorator to ensure a directory property exists.</p> Source code in <code>danling/utils/decorators.py</code> Python<pre><code>def ensure_dir(func):\n\"\"\"\n    Decorator to ensure a directory property exists.\n    \"\"\"\n@wraps(func)\ndef wrapper(*args, **kwargs):\npath = abspath(func(*args, **kwargs))\nmakedirs(path, exist_ok=True)\nreturn path\nreturn wrapper\n</code></pre>"},{"location":"registry/","title":"Registry","text":"<p>         Bases: <code>NestedDict</code></p> <p><code>Registry</code> for components.</p> Notes <p><code>Registry</code> inherits from <code>NestedDict</code>.</p> <p>Therefore, <code>Registry</code> comes in a nested structure by nature. You could create a sub-registry by simply calling <code>registry.sub_registry = Registry</code>, and access through <code>registry.sub_registry.register()</code>.</p> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; registry = Registry(\"test\")\n&gt;&gt;&gt; @registry.register\n... @registry.register(\"Module1\")\n... class Module:\n...     def __init__(self, a, b):\n...         self.a = a\n...         self.b = b\n&gt;&gt;&gt; module = registry.register(Module, \"Module2\")\n&gt;&gt;&gt; registry\nRegistry(\n('Module1'): &lt;class 'danling.registry.Module'&gt;\n('Module'): &lt;class 'danling.registry.Module'&gt;\n('Module2'): &lt;class 'danling.registry.Module'&gt;\n)\n&gt;&gt;&gt; registry.lookup(\"Module\")\n&lt;class 'danling.registry.Module'&gt;\n&gt;&gt;&gt; config = {\"module\": {\"name\": \"Module\", \"a\": 1, \"b\": 2}}\n&gt;&gt;&gt; # registry.register(Module)\n&gt;&gt;&gt; module = registry.build(config[\"module\"])\n&gt;&gt;&gt; type(module)\n&lt;class 'danling.registry.Module'&gt;\n&gt;&gt;&gt; module.a\n1\n&gt;&gt;&gt; module.b\n2\n</code></pre> Source code in <code>danling/registry.py</code> Python<pre><code>class Registry(NestedDict):\n\"\"\"\n    `Registry` for components.\n    Notes:\n        `Registry` inherits from [`NestedDict`](https://chanfig.danling.org/nested_dict/).\n        Therefore, `Registry` comes in a nested structure by nature.\n        You could create a sub-registry by simply calling `registry.sub_registry = Registry`,\n        and access through `registry.sub_registry.register()`.\n    Examples:\n    ```python\n    &gt;&gt;&gt; registry = Registry(\"test\")\n    &gt;&gt;&gt; @registry.register\n    ... @registry.register(\"Module1\")\n    ... class Module:\n    ...     def __init__(self, a, b):\n    ...         self.a = a\n    ...         self.b = b\n    &gt;&gt;&gt; module = registry.register(Module, \"Module2\")\n    &gt;&gt;&gt; registry\n    Registry(\n      ('Module1'): &lt;class 'danling.registry.Module'&gt;\n      ('Module'): &lt;class 'danling.registry.Module'&gt;\n      ('Module2'): &lt;class 'danling.registry.Module'&gt;\n    )\n    &gt;&gt;&gt; registry.lookup(\"Module\")\n    &lt;class 'danling.registry.Module'&gt;\n    &gt;&gt;&gt; config = {\"module\": {\"name\": \"Module\", \"a\": 1, \"b\": 2}}\n    &gt;&gt;&gt; # registry.register(Module)\n    &gt;&gt;&gt; module = registry.build(config[\"module\"])\n    &gt;&gt;&gt; type(module)\n    &lt;class 'danling.registry.Module'&gt;\n    &gt;&gt;&gt; module.a\n    1\n    &gt;&gt;&gt; module.b\n    2\n    ```\n    \"\"\"\noverride: bool = False\ndef __init__(self, override: bool = False):\nsuper().__init__()\nself.setattr(\"override\", override)\nwarn(\n\"DanLing Registry has been deprecated in favor of CHANfiG Registry, and will be removed in 0.2.0.\",\nDeprecationWarning,\n)\ndef register(self, component: Optional[Callable] = None, name: Optional[str] = None) -&gt; Callable:\nr\"\"\"\n        Register a new component.\n        Args:\n            component: The component to register.\n            name: The name of the component.\n        Returns:\n            component: The registered component.\n        Raises:\n            ValueError: If the component with the same name already registered and `Registry.override=False`.\n        Examples:\n        ```python\n        &gt;&gt;&gt; registry = Registry(\"test\")\n        &gt;&gt;&gt; @registry.register\n        ... @registry.register(\"Module1\")\n        ... class Module:\n        ...     def __init__(self, a, b):\n        ...         self.a = a\n        ...         self.b = b\n        &gt;&gt;&gt; module = registry.register(Module, \"Module2\")\n        &gt;&gt;&gt; registry\n        Registry(\n          ('Module1'): &lt;class 'danling.registry.Module'&gt;\n          ('Module'): &lt;class 'danling.registry.Module'&gt;\n          ('Module2'): &lt;class 'danling.registry.Module'&gt;\n        )\n        ```\n        \"\"\"\nif name in self and not self.override:\nraise ValueError(f\"Component with name {name} already registered.\")\n# Registry.register()\nif name is not None:\nself.set(name, component)\n# @Registry.register()\n@wraps(self.register)\ndef register(component, name=None):\nif name is None:\nname = component.__name__\nself.set(name, component)\nreturn component\n# @Registry.register\nif callable(component) and name is None:\nreturn register(component)\nreturn lambda x: register(x, component)\ndef lookup(self, name: str) -&gt; Any:\nr\"\"\"\n        Lookup for a component.\n        Args:\n            name:\n        Returns:\n            (Any): The component.\n        Raises:\n            KeyError: If the component is not registered.\n        Examples:\n        ```python\n        &gt;&gt;&gt; registry = Registry(\"test\")\n        &gt;&gt;&gt; @registry.register\n        ... class Module:\n        ...     def __init__(self, a, b):\n        ...         self.a = a\n        ...         self.b = b\n        &gt;&gt;&gt; registry.lookup(\"Module\")\n        &lt;class 'danling.registry.Module'&gt;\n        ```\n        \"\"\"\nreturn self.get(name)\ndef build(self, name: Union[str, Mapping], *args, **kwargs) -&gt; Any:\nr\"\"\"\n        Build a component.\n        Args:\n            name (str | Mapping):\n                If its a `Mapping`, it must contain `\"name\"` as a member, the rest will be treated as `**kwargs`.\n                Note that values in `kwargs` will override values in `name` if its a `Mapping`.\n            *args: The arguments to pass to the component.\n            **kwargs: The keyword arguments to pass to the component.\n        Returns:\n            (Any):\n        Raises:\n            KeyError: If the component is not registered.\n        Examples:\n        ```python\n        &gt;&gt;&gt; registry = Registry(\"test\")\n        &gt;&gt;&gt; @registry.register\n        ... class Module:\n        ...     def __init__(self, a, b):\n        ...         self.a = a\n        ...         self.b = b\n        &gt;&gt;&gt; config = {\"module\": {\"name\": \"Module\", \"a\": 1, \"b\": 2}}\n        &gt;&gt;&gt; # registry.register(Module)\n        &gt;&gt;&gt; module = registry.build(**config[\"module\"])\n        &gt;&gt;&gt; type(module)\n        &lt;class 'danling.registry.Module'&gt;\n        &gt;&gt;&gt; module.a\n        1\n        &gt;&gt;&gt; module.b\n        2\n        &gt;&gt;&gt; module = registry.build(config[\"module\"], a=2)\n        &gt;&gt;&gt; module.a\n        2\n        ```\n        \"\"\"\nif isinstance(name, Mapping):\nname = deepcopy(name)\nname, kwargs = name.pop(\"name\"), dict(name, **kwargs)  # type: ignore\nreturn self.get(name)(*args, **kwargs)  # type: ignore\ndef __wrapped__(self, *args, **kwargs):\npass\n</code></pre>"},{"location":"registry/#danling.registry.Registry.register","title":"<code>register(component=None, name=None)</code>","text":"<p>Register a new component.</p> <p>Parameters:</p> Name Type Description Default <code>component</code> <code>Optional[Callable]</code> <p>The component to register.</p> <code>None</code> <code>name</code> <code>Optional[str]</code> <p>The name of the component.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>component</code> <code>Callable</code> <p>The registered component.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the component with the same name already registered and <code>Registry.override=False</code>.</p> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; registry = Registry(\"test\")\n&gt;&gt;&gt; @registry.register\n... @registry.register(\"Module1\")\n... class Module:\n...     def __init__(self, a, b):\n...         self.a = a\n...         self.b = b\n&gt;&gt;&gt; module = registry.register(Module, \"Module2\")\n&gt;&gt;&gt; registry\nRegistry(\n('Module1'): &lt;class 'danling.registry.Module'&gt;\n('Module'): &lt;class 'danling.registry.Module'&gt;\n('Module2'): &lt;class 'danling.registry.Module'&gt;\n)\n</code></pre> Source code in <code>danling/registry.py</code> Python<pre><code>def register(self, component: Optional[Callable] = None, name: Optional[str] = None) -&gt; Callable:\nr\"\"\"\n    Register a new component.\n    Args:\n        component: The component to register.\n        name: The name of the component.\n    Returns:\n        component: The registered component.\n    Raises:\n        ValueError: If the component with the same name already registered and `Registry.override=False`.\n    Examples:\n    ```python\n    &gt;&gt;&gt; registry = Registry(\"test\")\n    &gt;&gt;&gt; @registry.register\n    ... @registry.register(\"Module1\")\n    ... class Module:\n    ...     def __init__(self, a, b):\n    ...         self.a = a\n    ...         self.b = b\n    &gt;&gt;&gt; module = registry.register(Module, \"Module2\")\n    &gt;&gt;&gt; registry\n    Registry(\n      ('Module1'): &lt;class 'danling.registry.Module'&gt;\n      ('Module'): &lt;class 'danling.registry.Module'&gt;\n      ('Module2'): &lt;class 'danling.registry.Module'&gt;\n    )\n    ```\n    \"\"\"\nif name in self and not self.override:\nraise ValueError(f\"Component with name {name} already registered.\")\n# Registry.register()\nif name is not None:\nself.set(name, component)\n# @Registry.register()\n@wraps(self.register)\ndef register(component, name=None):\nif name is None:\nname = component.__name__\nself.set(name, component)\nreturn component\n# @Registry.register\nif callable(component) and name is None:\nreturn register(component)\nreturn lambda x: register(x, component)\n</code></pre>"},{"location":"registry/#danling.registry.Registry.lookup","title":"<code>lookup(name)</code>","text":"<p>Lookup for a component.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> required <p>Returns:</p> Type Description <code>Any</code> <p>The component.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If the component is not registered.</p> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; registry = Registry(\"test\")\n&gt;&gt;&gt; @registry.register\n... class Module:\n...     def __init__(self, a, b):\n...         self.a = a\n...         self.b = b\n&gt;&gt;&gt; registry.lookup(\"Module\")\n&lt;class 'danling.registry.Module'&gt;\n</code></pre> Source code in <code>danling/registry.py</code> Python<pre><code>def lookup(self, name: str) -&gt; Any:\nr\"\"\"\n    Lookup for a component.\n    Args:\n        name:\n    Returns:\n        (Any): The component.\n    Raises:\n        KeyError: If the component is not registered.\n    Examples:\n    ```python\n    &gt;&gt;&gt; registry = Registry(\"test\")\n    &gt;&gt;&gt; @registry.register\n    ... class Module:\n    ...     def __init__(self, a, b):\n    ...         self.a = a\n    ...         self.b = b\n    &gt;&gt;&gt; registry.lookup(\"Module\")\n    &lt;class 'danling.registry.Module'&gt;\n    ```\n    \"\"\"\nreturn self.get(name)\n</code></pre>"},{"location":"registry/#danling.registry.Registry.build","title":"<code>build(name, *args, **kwargs)</code>","text":"<p>Build a component.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | Mapping</code> <p>If its a <code>Mapping</code>, it must contain <code>\"name\"</code> as a member, the rest will be treated as <code>**kwargs</code>. Note that values in <code>kwargs</code> will override values in <code>name</code> if its a <code>Mapping</code>.</p> required <code>*args</code> <p>The arguments to pass to the component.</p> <code>()</code> <code>**kwargs</code> <p>The keyword arguments to pass to the component.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Any</code> <p>Raises:</p> Type Description <code>KeyError</code> <p>If the component is not registered.</p> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; registry = Registry(\"test\")\n&gt;&gt;&gt; @registry.register\n... class Module:\n...     def __init__(self, a, b):\n...         self.a = a\n...         self.b = b\n&gt;&gt;&gt; config = {\"module\": {\"name\": \"Module\", \"a\": 1, \"b\": 2}}\n&gt;&gt;&gt; # registry.register(Module)\n&gt;&gt;&gt; module = registry.build(**config[\"module\"])\n&gt;&gt;&gt; type(module)\n&lt;class 'danling.registry.Module'&gt;\n&gt;&gt;&gt; module.a\n1\n&gt;&gt;&gt; module.b\n2\n&gt;&gt;&gt; module = registry.build(config[\"module\"], a=2)\n&gt;&gt;&gt; module.a\n2\n</code></pre> Source code in <code>danling/registry.py</code> Python<pre><code>def build(self, name: Union[str, Mapping], *args, **kwargs) -&gt; Any:\nr\"\"\"\n    Build a component.\n    Args:\n        name (str | Mapping):\n            If its a `Mapping`, it must contain `\"name\"` as a member, the rest will be treated as `**kwargs`.\n            Note that values in `kwargs` will override values in `name` if its a `Mapping`.\n        *args: The arguments to pass to the component.\n        **kwargs: The keyword arguments to pass to the component.\n    Returns:\n        (Any):\n    Raises:\n        KeyError: If the component is not registered.\n    Examples:\n    ```python\n    &gt;&gt;&gt; registry = Registry(\"test\")\n    &gt;&gt;&gt; @registry.register\n    ... class Module:\n    ...     def __init__(self, a, b):\n    ...         self.a = a\n    ...         self.b = b\n    &gt;&gt;&gt; config = {\"module\": {\"name\": \"Module\", \"a\": 1, \"b\": 2}}\n    &gt;&gt;&gt; # registry.register(Module)\n    &gt;&gt;&gt; module = registry.build(**config[\"module\"])\n    &gt;&gt;&gt; type(module)\n    &lt;class 'danling.registry.Module'&gt;\n    &gt;&gt;&gt; module.a\n    1\n    &gt;&gt;&gt; module.b\n    2\n    &gt;&gt;&gt; module = registry.build(config[\"module\"], a=2)\n    &gt;&gt;&gt; module.a\n    2\n    ```\n    \"\"\"\nif isinstance(name, Mapping):\nname = deepcopy(name)\nname, kwargs = name.pop(\"name\"), dict(name, **kwargs)  # type: ignore\nreturn self.get(name)(*args, **kwargs)  # type: ignore\n</code></pre>"},{"location":"blog/","title":"DanLing","text":""},{"location":"metrics/average_meter/","title":"AverageMeter","text":"<p>Computes and stores the average and current value.</p> <p>Attributes:</p> Name Type Description <code>val</code> <code>int</code> <p>Current value.</p> <code>avg</code> <code>float</code> <p>Average value.</p> <code>sum</code> <code>int</code> <p>Sum of values.</p> <code>count</code> <code>int</code> <p>Number of values.</p> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; meter = AverageMeter()\n&gt;&gt;&gt; meter.update(0.7)\n&gt;&gt;&gt; meter.val\n0.7\n&gt;&gt;&gt; meter.avg\n0.7\n&gt;&gt;&gt; meter.update(0.9)\n&gt;&gt;&gt; meter.val\n0.9\n&gt;&gt;&gt; meter.avg\n0.8\n&gt;&gt;&gt; meter.sum\n1.6\n&gt;&gt;&gt; meter.count\n2\n&gt;&gt;&gt; meter.reset()\n&gt;&gt;&gt; meter.val\n0\n&gt;&gt;&gt; meter.avg\n0\n</code></pre> Source code in <code>danling/metrics/average_meter.py</code> Python<pre><code>class AverageMeter:\nr\"\"\"\n    Computes and stores the average and current value.\n    Attributes:\n        val: Current value.\n        avg: Average value.\n        sum: Sum of values.\n        count: Number of values.\n    Examples:\n    ```python\n    &gt;&gt;&gt; meter = AverageMeter()\n    &gt;&gt;&gt; meter.update(0.7)\n    &gt;&gt;&gt; meter.val\n    0.7\n    &gt;&gt;&gt; meter.avg\n    0.7\n    &gt;&gt;&gt; meter.update(0.9)\n    &gt;&gt;&gt; meter.val\n    0.9\n    &gt;&gt;&gt; meter.avg\n    0.8\n    &gt;&gt;&gt; meter.sum\n    1.6\n    &gt;&gt;&gt; meter.count\n    2\n    &gt;&gt;&gt; meter.reset()\n    &gt;&gt;&gt; meter.val\n    0\n    &gt;&gt;&gt; meter.avg\n    0\n    ```\n    \"\"\"\nval: int = 0\navg: float = 0\nsum: int = 0\ncount: int = 0\ndef __init__(self) -&gt; None:\nself.reset()\ndef reset(self) -&gt; None:\nr\"\"\"\n        Resets the meter.\n        Examples:\n        ```python\n        &gt;&gt;&gt; meter = AverageMeter()\n        &gt;&gt;&gt; meter.update(0.7)\n        &gt;&gt;&gt; meter.val\n        0.7\n        &gt;&gt;&gt; meter.avg\n        0.7\n        &gt;&gt;&gt; meter.reset()\n        &gt;&gt;&gt; meter.val\n        0\n        &gt;&gt;&gt; meter.avg\n        0\n        ```\n        \"\"\"\nself.val = 0\nself.avg = 0\nself.sum = 0\nself.count = 0\ndef update(self, val, n: int = 1) -&gt; None:\nr\"\"\"\n        Updates the average and current value in the meter.\n        Args:\n            val: Value to be added to the average.\n            n: Number of values to be added.\n        Examples:\n        ```python\n        &gt;&gt;&gt; meter = AverageMeter()\n        &gt;&gt;&gt; meter.update(0.7)\n        &gt;&gt;&gt; meter.val\n        0.7\n        &gt;&gt;&gt; meter.avg\n        0.7\n        &gt;&gt;&gt; meter.update(0.9)\n        &gt;&gt;&gt; meter.val\n        0.9\n        &gt;&gt;&gt; meter.avg\n        0.8\n        &gt;&gt;&gt; meter.sum\n        1.6\n        &gt;&gt;&gt; meter.count\n        2\n        ```\n        \"\"\"\n# pylint: disable=C0103\nself.val = val\nself.sum += val * n\nself.count += n\nself.avg = self.sum / self.count\n</code></pre>"},{"location":"metrics/average_meter/#danling.metrics.average_meter.AverageMeter.reset","title":"<code>reset()</code>","text":"<p>Resets the meter.</p> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; meter = AverageMeter()\n&gt;&gt;&gt; meter.update(0.7)\n&gt;&gt;&gt; meter.val\n0.7\n&gt;&gt;&gt; meter.avg\n0.7\n&gt;&gt;&gt; meter.reset()\n&gt;&gt;&gt; meter.val\n0\n&gt;&gt;&gt; meter.avg\n0\n</code></pre> Source code in <code>danling/metrics/average_meter.py</code> Python<pre><code>def reset(self) -&gt; None:\nr\"\"\"\n    Resets the meter.\n    Examples:\n    ```python\n    &gt;&gt;&gt; meter = AverageMeter()\n    &gt;&gt;&gt; meter.update(0.7)\n    &gt;&gt;&gt; meter.val\n    0.7\n    &gt;&gt;&gt; meter.avg\n    0.7\n    &gt;&gt;&gt; meter.reset()\n    &gt;&gt;&gt; meter.val\n    0\n    &gt;&gt;&gt; meter.avg\n    0\n    ```\n    \"\"\"\nself.val = 0\nself.avg = 0\nself.sum = 0\nself.count = 0\n</code></pre>"},{"location":"metrics/average_meter/#danling.metrics.average_meter.AverageMeter.update","title":"<code>update(val, n=1)</code>","text":"<p>Updates the average and current value in the meter.</p> <p>Parameters:</p> Name Type Description Default <code>val</code> <p>Value to be added to the average.</p> required <code>n</code> <code>int</code> <p>Number of values to be added.</p> <code>1</code> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; meter = AverageMeter()\n&gt;&gt;&gt; meter.update(0.7)\n&gt;&gt;&gt; meter.val\n0.7\n&gt;&gt;&gt; meter.avg\n0.7\n&gt;&gt;&gt; meter.update(0.9)\n&gt;&gt;&gt; meter.val\n0.9\n&gt;&gt;&gt; meter.avg\n0.8\n&gt;&gt;&gt; meter.sum\n1.6\n&gt;&gt;&gt; meter.count\n2\n</code></pre> Source code in <code>danling/metrics/average_meter.py</code> Python<pre><code>def update(self, val, n: int = 1) -&gt; None:\nr\"\"\"\n    Updates the average and current value in the meter.\n    Args:\n        val: Value to be added to the average.\n        n: Number of values to be added.\n    Examples:\n    ```python\n    &gt;&gt;&gt; meter = AverageMeter()\n    &gt;&gt;&gt; meter.update(0.7)\n    &gt;&gt;&gt; meter.val\n    0.7\n    &gt;&gt;&gt; meter.avg\n    0.7\n    &gt;&gt;&gt; meter.update(0.9)\n    &gt;&gt;&gt; meter.val\n    0.9\n    &gt;&gt;&gt; meter.avg\n    0.8\n    &gt;&gt;&gt; meter.sum\n    1.6\n    &gt;&gt;&gt; meter.count\n    2\n    ```\n    \"\"\"\n# pylint: disable=C0103\nself.val = val\nself.sum += val * n\nself.count += n\nself.avg = self.sum / self.count\n</code></pre>"},{"location":"optim/lr_scheduler/","title":"LRScheduler","text":"<p>         Bases: <code>lr_scheduler._LRScheduler</code></p> <p>General learning rate scheduler.</p> <p>PyTorch LRScheduler is hard to extend. This class is a wrapper of PyTorch LRScheduler, which provides a more general interface. You only needs to add a new method which calculates a learning rate ratio (range from 0 to 1) with total progress (range from 0 to 1), and everything else will be done automatically.</p> <p>Moreover, this class has warmup and cooldown built-in. By default, the first 5% and last 20% of training steps will be warmup and cooldown respectively. You can alternate by passing <code>warmup_steps</code> and <code>cooldown_steps</code>, or disable them by setting them to 0.</p> <p>Parameters:</p> Name Type Description Default <code>optimizer</code> <code>Optimizer</code> <p>Wrapped optimizer.</p> required <code>steps</code> <code>int</code> <p>Total number of steps.</p> required <code>final_lr_ratio</code> <code>float</code> <p>Final learning rate ratio to initial learning rate. Defaults to 100.</p> <code>100</code> <code>final_lr</code> <code>Optional[float]</code> <p>Final learning rate. Deprecated, use <code>final_lr_ratio</code> instead. Defaults to None.</p> <code>None</code> <code>min_lr</code> <code>float</code> <p>Minimal learning rate. Defaults to 1e-9.</p> <code>1e-09</code> <code>strategy</code> <code>str</code> <p>Scaling strategy. Defaults to \u201ccosine\u201d.</p> <code>'cosine'</code> <code>warmup_steps</code> <code>Optional[int]</code> <p>Number of warmup steps. Defaults to <code>steps // 20</code>.</p> <code>None</code> <code>cooldown_steps</code> <code>Optional[int]</code> <p>Number of cooldown steps. Defaults to <code>steps // 5</code>.</p> <code>None</code> <code>last_epoch</code> <code>int</code> <p>The index of last epoch. Defaults to -1.</p> <code>-1</code> <code>method</code> <code>str</code> <p>Method to calculate learning rate given ratio, should be one of \u201cpercentile\u201d or \u201clinear\u201d. Defaults to \u201cpercentile\u201d.</p> <code>'percentile'</code> <p>Examples:</p> Python Console Session<pre><code>&gt;&gt;&gt; from danling.optim import LRScheduler\n&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from torch import optim\n&gt;&gt;&gt; optimizer = optim.SGD([{'params': torch.tensor([0])}], lr=1, momentum=0.9)\n&gt;&gt;&gt; scheduler = LRScheduler(optimizer, steps=5, final_lr_ratio=1e-5, strategy='linear')\n&gt;&gt;&gt; lrs = []\n&gt;&gt;&gt; for epoch in range(5):\n...     lrs.append(scheduler.get_lr()[0])\n...     scheduler.step()\n&gt;&gt;&gt; [round(lr, 10) for lr in lrs]\n[0.1, 0.01, 0.001, 0.0001, 1e-09]\n&gt;&gt;&gt; scheduler = LRScheduler(optimizer, steps=5, final_lr_ratio=1e-5, strategy='cosine')\n&gt;&gt;&gt; lrs = []\n&gt;&gt;&gt; for epoch in range(5):\n...     lrs.append(scheduler.get_lr()[0])\n...     scheduler.step()\n&gt;&gt;&gt; [round(lr, 10) for lr in lrs]\n[0.3330753446, 0.0187302031, 0.000533897, 3.00232e-05, 1e-09]\n</code></pre> Source code in <code>danling/optim/lr_scheduler/lr_scheduler.py</code> Python<pre><code>class LRScheduler(lr_scheduler._LRScheduler):  # pylint: disable=W0212\nr\"\"\"\n    General learning rate scheduler.\n    PyTorch LRScheduler is hard to extend.\n    This class is a wrapper of PyTorch LRScheduler, which provides a more general interface.\n    You only needs to add a new method which calculates a learning rate ratio (range from 0 to 1)\n    with total progress (range from 0 to 1), and everything else will be done automatically.\n    Moreover, this class has warmup and cooldown built-in.\n    By default, the first 5% and last 20% of training steps will be warmup and cooldown respectively.\n    You can alternate by passing `warmup_steps` and `cooldown_steps`, or disable them by setting them to 0.\n    Args:\n        optimizer: Wrapped optimizer.\n        steps: Total number of steps.\n        final_lr_ratio: Final learning rate ratio to initial learning rate.\n            Defaults to 100.\n        final_lr: Final learning rate. Deprecated, use `final_lr_ratio` instead.\n            Defaults to None.\n        min_lr: Minimal learning rate.\n            Defaults to 1e-9.\n        strategy: Scaling strategy.\n            Defaults to \"cosine\".\n        warmup_steps: Number of warmup steps.\n            Defaults to `steps // 20`.\n        cooldown_steps: Number of cooldown steps.\n            Defaults to `steps // 5`.\n        last_epoch: The index of last epoch.\n            Defaults to -1.\n        method: Method to calculate learning rate given ratio, should be one of \"percentile\" or \"linear\".\n            Defaults to \"percentile\".\n    Examples:\n        &gt;&gt;&gt; from danling.optim import LRScheduler\n        &gt;&gt;&gt; import torch\n        &gt;&gt;&gt; from torch import optim\n        &gt;&gt;&gt; optimizer = optim.SGD([{'params': torch.tensor([0])}], lr=1, momentum=0.9)\n        &gt;&gt;&gt; scheduler = LRScheduler(optimizer, steps=5, final_lr_ratio=1e-5, strategy='linear')\n        &gt;&gt;&gt; lrs = []\n        &gt;&gt;&gt; for epoch in range(5):\n        ...     lrs.append(scheduler.get_lr()[0])\n        ...     scheduler.step()\n        &gt;&gt;&gt; [round(lr, 10) for lr in lrs]\n        [0.1, 0.01, 0.001, 0.0001, 1e-09]\n        &gt;&gt;&gt; scheduler = LRScheduler(optimizer, steps=5, final_lr_ratio=1e-5, strategy='cosine')\n        &gt;&gt;&gt; lrs = []\n        &gt;&gt;&gt; for epoch in range(5):\n        ...     lrs.append(scheduler.get_lr()[0])\n        ...     scheduler.step()\n        &gt;&gt;&gt; [round(lr, 10) for lr in lrs]\n        [0.3330753446, 0.0187302031, 0.000533897, 3.00232e-05, 1e-09]\n    \"\"\"\ndef __init__(  # pylint: disable=R0913\nself,\noptimizer: Optimizer,\nsteps: int,\nfinal_lr_ratio: float = 100,\nfinal_lr: Optional[float] = None,\nmin_lr: float = 1e-9,\nstrategy: str = \"cosine\",\nwarmup_steps: Optional[int] = None,\ncooldown_steps: Optional[int] = None,\nlast_epoch: int = -1,\nmethod: str = \"percentile\",\n):\nif warmup_steps is None:\nwarmup_steps = steps // 20\nelif warmup_steps &gt; steps:\nraise ValueError(f\"Warmup steps must be less than total steps, but got {warmup_steps} &gt; {steps}\")\nelif warmup_steps &lt; 0:\nraise ValueError(f\"Warmup steps must be positive, but got {warmup_steps}\")\nif cooldown_steps is None:\ncooldown_steps = steps // 5\nelif cooldown_steps &gt; steps:\nraise ValueError(f\"Cooldown steps must be less than total steps, but got {cooldown_steps} &gt; {steps}\")\nelif cooldown_steps &lt; 0:\nraise ValueError(f\"Cooldown steps must be positive, but got {cooldown_steps}\")\nif final_lr_ratio &lt; 0:\nraise ValueError(f\"`final_lr_ratio` must be positive, but got {final_lr_ratio}\")\nif min_lr &lt; 0:\nraise ValueError(f\"`min_lr` must be positive, but got {min_lr}\")\nself.strategies = {\nk: v for k, v in self.__class__.__dict__.items() if callable(v) and (not k.startswith(\"_\") or k in \"get_lr\")\n}\nif strategy not in self.strategies:\nraise ValueError(f\"Scaling strategy must be one of {self.strategies.keys()}, but got {strategy}\")\nself.steps = steps\nif final_lr is not None:\nwarn(\"Argument `final_lr` is deprecated, use `final_lr_ratio` instead\", DeprecationWarning)\nself.final_lr = final_lr\nself.final_lr_ratio = final_lr_ratio\nself.min_lr = min_lr\nself.strategy = strategy\nself.method = method\nself.warmup_steps = warmup_steps\nself.cooldown_steps = cooldown_steps\nself.cooldown_steps_begin = self.steps - self.cooldown_steps\nsuper().__init__(optimizer, last_epoch)\ndef get_lr(self) -&gt; List[float]:  # type: ignore\nstep_count = self._step_count  # type: ignore\nif step_count &gt; self.steps + 1 or step_count &lt; 1:\nwarn(f\"Step count {step_count} is out of range [1, {self.steps + 1}]\", RuntimeWarning)\nprogress = np.clip(step_count / self.steps, 0.0, 1.0)\nwarmup_ratio = step_count / self.warmup_steps if self.warmup_steps &gt; 0 else 1.0\ncooldown_ratio = (\n1 - (step_count - self.cooldown_steps_begin) / self.cooldown_steps if self.cooldown_steps &gt; 0 else 1.0\n)\nreturn [self._get_lr(lr, step_count, progress, warmup_ratio, cooldown_ratio) for lr in self.base_lrs]\ndef _get_lr(\nself,\nlr: float,\nstep_count: Optional[int] = None,\nprogress: Optional[float] = None,\nwarmup_ratio: Optional[float] = None,\ncooldown_ratio: Optional[float] = None,\nmethod: Optional[str] = None,\n) -&gt; float:\nmethod = method or self.method\nstep_count = step_count or self._step_count  # type: ignore\nprogress = progress or np.clip(step_count / self.steps, 0.0, 1.0)\nfinal_lr = self.final_lr or lr * self.final_lr_ratio\nratio = getattr(self, self.strategy)(progress)\nif method == \"percentile\":\nlr *= pow(final_lr / lr, ratio)\nelif method == \"numerical\":\nlr = (1 - ratio) * (lr - final_lr) + final_lr\nelse:\nraise ValueError(f\"Method must be one of ['percentile', 'numerical'], but got {method}\")\nif self.warmup_steps &gt; step_count &gt; 0:\nwarmup_ratio = warmup_ratio or step_count / self.warmup_steps\nlr = warmup_ratio * (lr - self.min_lr) + self.min_lr\nif step_count &gt; self.cooldown_steps_begin and self.cooldown_steps &gt; 0:\ncooldown_ratio = cooldown_ratio or 1 - (step_count - self.cooldown_steps_begin) / self.cooldown_steps\nlr = cooldown_ratio * (lr - self.min_lr) + self.min_lr\nreturn max(self.min_lr, lr)\ndef linear(self, progress: float) -&gt; float:  # pylint: disable=C0116\nreturn progress\ndef cosine(self, progress: float) -&gt; float:  # pylint: disable=C0116\nreturn 1 - ((1 + np.cos(np.pi * progress)) / 2)\ndef constant(self, progress: float) -&gt; float:  # pylint: disable=W0613, C0116\nreturn 0.0\ndef __repr__(self) -&gt; str:\nreturn (\nf\"{self.__class__.__name__}({self.strategy}, method={self.method}, \"\nf\"final_lr_ratio={self.final_lr_ratio}, steps={self.steps}, \"\nf\"warmup_steps={self.warmup_steps}, cooldown_steps={self.cooldown_steps})\"\n)\n</code></pre>"},{"location":"runner/","title":"Runner","text":"<p>The Runner of DanLing sets up the basic environment for running neural networks.</p>"},{"location":"runner/#components","title":"Components","text":"<p>For readability and maintainability, there are three levels of Runner + a RunnerState.</p> <p>The RunnerState stores all the information that is critical for a run and is stored in the checkpoint (e.g. <code>epochs</code>, <code>run_id</code>, etc.). With RunnerState and corresponding weights, you can resume a run from any point.</p> <p>The Runner contains all runtime information that is irrelevant to the checkpoint (e.g. <code>world_size</code>, <code>rank</code>, etc.).</p>"},{"location":"runner/#runnerstate","title":"<code>RunnerState</code>","text":"<p><code>RunnerState</code> stores the state of a run.</p> <p>All attributes stored in <code>RunnerState</code> will be saved in the checkpoint, and thus should be json serialisable. Except for <code>@property</code> of json serialisable attributes.</p>"},{"location":"runner/#runnerbase","title":"<code>RunnerBase</code>","text":"<p><code>RunnerBase</code> gives you a basic instinct on what attributes and properties are provided by the Runner.</p> <p>It works in an AbstractBaseClass manner and should neither be used directly nor be inherited from.</p>"},{"location":"runner/#baserunner","title":"<code>BaseRunner</code>","text":"<p><code>BaseRunner</code> contains core methods of general basic functionality, such as <code>init_logging</code>, <code>append_result</code>, <code>print_result</code>.</p>"},{"location":"runner/#runner_1","title":"<code>Runner</code>","text":"<p><code>Runner</code> should only contain platform-specific features. Currently, only <code>TorchRunner</code> is supported.</p>"},{"location":"runner/#experiments-management","title":"Experiments Management","text":"<p>DanLing Runner is designed for a 3.5-level experiments management system: Project, Group, Experiment, and, Run.</p>"},{"location":"runner/#project","title":"Project","text":"<p>A project corresponds to your project.</p> <p>Generally speaking, there should be only one project for each repository.</p> <p><code>project_root</code> is the root directory of all experiments of a certain project, and should be consistent across the project.</p>"},{"location":"runner/#group","title":"Group","text":"<p>A group groups multiple experiments with similar characteristics.</p> <p>For example, if you run multiple experiments on learning rate, you may want to group them into a group.</p> <p>Note that Group is a virtual level (which is why it only counts 0.5) and does not correspond to anything. There are no attributes/properties for groups.</p>"},{"location":"runner/#experiment","title":"Experiment","text":"<p>An experiment is the basic unit of experiments.</p> <p>Each experiment corresponds to a certain commit, which means the code should be consistent across the experiment.</p> <p>DanLing will automatically generate <code>experiment_id</code> and <code>experiment_uuid</code> based on git revision. They are unique for each commit.</p> <p>You may also set a catchy custom <code>experiment_name</code> to identify each experiment.</p>"},{"location":"runner/#run","title":"Run","text":"<p>A run is the basic unit of runnings.</p> <p>Run corresponds to a certain run of an experiment, each run may have different hyperparameters.</p> <p>DanLing will automatically generate <code>run_id</code> and <code>run_uuid</code> based on <code>experiment_uuid</code> and provided config. They are unique for each commit and config.</p> <p>You may also set a catchy custom <code>run_name</code> to identify each experiment.</p>"},{"location":"runner/#identifiers","title":"Identifiers","text":"<p>DanLing has two properties built-in to help you identify each run.</p> <ul> <li><code>id</code> by default is the join of <code>experiment_id</code>, <code>run_id</code>, and <code>uuid</code>. It is automatically generated hex-strings and is unique for each run.</li> <li><code>name</code> by default is <code>experiment_name-run_name</code>. It is manually specified and easy to read. Note that <code>name</code> is not guaranteed to be unique.</li> </ul>"},{"location":"runner/#directories","title":"Directories","text":"<p>To help you manage your experiments, DanLing will automatically generate directories for you.</p> <p><code>dir</code> is the directory of a certain run, defaults to <code>{dir/name-id}</code>. All run files should be under this directory.</p> <p>In particular, <code>checkpoint_dir</code>, which defaults to <code>dir/checkpoint_dir_name</code> contains all checkpoint files.</p> <p>As a result, your <code>project_root</code> should looks like following:</p> Bash<pre><code>- {project_root}\n-     |- {name}-{id} (equivalents to {experiment_name}-{run_name}-{experiment_id}-{run_id}-{uuid})\n-       |\n-       |- {checkpoint_dir_name}\n-       |    |\n-       |    |- best.pth\n-       |    |- latest.pth\n-       |    |- epoch-10.pth\n-       |\n-       |- run.log\n-       |- runner.yaml\n-       |- results.json\n-       |- latest.json\n-       |- best.json\n</code></pre>"},{"location":"runner/base_runner/","title":"BaseRunner","text":"<p>         Bases: <code>RunnerBase</code></p> <p>Base class for running a neural network.</p> <p><code>BaseRunner</code> sets up basic running environment, including <code>seed</code>, <code>deterministic</code>, and <code>logging</code>.</p> <p><code>BaseRunner</code> also provides some basic methods, such as, <code>step</code>, <code>state_dict</code>, <code>save_checkpoint</code>, <code>load_checkpoint</code>.</p> <p>All runners should inherit <code>BaseRunner</code>.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>class BaseRunner(RunnerBase):\nr\"\"\"\n    Base class for running a neural network.\n    `BaseRunner` sets up basic running environment, including `seed`, `deterministic`, and `logging`.\n    `BaseRunner` also provides some basic methods, such as, `step`, `state_dict`, `save_checkpoint`, `load_checkpoint`.\n    All runners should inherit `BaseRunner`.\n    \"\"\"\n# pylint: disable=R0902\ndef __init__(self, *args, **kwargs) -&gt; None:\nsuper().__init__(*args, **kwargs)\nself.init_distributed()\nif self.state.seed is not None:\nself.set_seed()\nif self.state.deterministic:\nself.set_deterministic()\nif self.state.log:\nself.init_logging()\nself.init_print()\nif self.state.tensorboard:\nself.init_tensorboard()\n@on_main_process\ndef init_logging(self) -&gt; None:\nr\"\"\"\n        Set up logging.\n        \"\"\"\n# Why is setting up proper logging so !@?#! ugly?\nlogging.config.dictConfig(\n{\n\"version\": 1,\n\"disable_existing_loggers\": False,\n\"formatters\": {\n\"standard\": {\"format\": \"%(asctime)s [%(levelname)s] %(name)s: %(message)s\"},\n},\n\"handlers\": {\n\"stdout\": {\n\"level\": \"INFO\",\n\"formatter\": \"standard\",\n\"class\": \"logging.StreamHandler\",\n\"stream\": \"ext://sys.stdout\",\n},\n\"logfile\": {\n\"level\": \"DEBUG\",\n\"formatter\": \"standard\",\n\"class\": \"logging.FileHandler\",\n\"filename\": self.log_path,\n\"mode\": \"a\",\n},\n},\n\"loggers\": {\n\"\": {\n\"handlers\": [\"stdout\", \"logfile\"],\n\"level\": \"DEBUG\",\n\"propagate\": True,\n},\n},\n}\n)\nlogging.captureWarnings(True)\nself.logger = logging.getLogger(\"runner\")\nself.logger.flush = lambda: [h.flush() for h in self.logger.handlers]  # type: ignore\ndef init_print(self, process: int = 0) -&gt; None:\nr\"\"\"\n        Set up `print`.\n        Only print on a specific `process` or when `force = True`.\n        Args:\n            process: The process to `print` on.\n        Notes\n        -----\n        If `self.state.log = True`, the default `print` function will be override by `logging.info`.\n        \"\"\"\nlogger = logging.getLogger(\"print\")\nlogger.flush = lambda: [h.flush for h in logger.handlers]  # type: ignore\nimport builtins as __builtin__  # pylint: disable=C0415\nbuiltin_print = __builtin__.print\n@catch\ndef print(*args, force=False, end=\"\\n\", file=None, flush=False, **kwargs):  # pylint: disable=W0622\nif self.rank == process or force:\nif self.state.log:\nlogger.info(*args, **kwargs)\nelse:\nbuiltin_print(*args, end=end, file=file, flush=flush, **kwargs)\n__builtin__.print = print\n@on_main_process\ndef init_tensorboard(self, *args, **kwargs) -&gt; None:\nr\"\"\"\n        Set up Tensoraoard SummaryWriter.\n        \"\"\"\nraise NotImplementedError\ndef set_seed(self, seed: Optional[int] = None, bias: Optional[int] = None) -&gt; None:\nr\"\"\"\n        Set up random seed.\n        Args:\n            seed: Random seed to set.\n                Defaults to `self.state.seed` (`config.seed`).\n            bias: Make the seed different for each processes.\n                This avoids same data augmentation are applied on every processes.\n                Defaults to `self.rank`.\n                Set to `False` to disable this feature.\n        \"\"\"\nif seed is None:\nseed = self.state.seed\nif bias is None:\nbias = self.rank\nif bias:\nseed += bias\nnp.random.seed(seed)\nrandom.seed(seed)\ndef set_deterministic(self) -&gt; None:\nr\"\"\"\n        Set up deterministic.\n        \"\"\"\nraise NotImplementedError\ndef scale_lr(\nself,\nlr: float,  # pylint: disable=C0103\nlr_scale_factor: Optional[float] = None,\nbatch_size_base: Optional[int] = None,\n) -&gt; float:\nr\"\"\"\n        Scale learning rate according to [linear scaling rule](https://arxiv.org/abs/1706.02677).\n        \"\"\"\n# pylint: disable=W0201\nif lr_scale_factor is None:\nif batch_size_base is None:\nbatch_size_base = getattr(self, \"batch_size_base\", None)\nif batch_size_base is None:\nraise ValueError(\"batch_size_base must be specified to auto scale lr\")\nlr_scale_factor = self.batch_size_equivalent / batch_size_base\nelif batch_size_base is not None:\nwarn(\n\"batch_size_base will be ignored if lr_scale_factor is specified\",\nRuntimeWarning,\n)\nlr = lr * lr_scale_factor  # pylint: disable=C0103, E1101\nself.lr_scale_factor = lr_scale_factor\nreturn lr\ndef step(self, zero_grad: bool = True, batch_size: Optional[int] = None) -&gt; None:\nr\"\"\"\n        Step optimizer and scheduler.\n        This method increment `self.state.steps`.\n        This method also increment `self.state.iters` when `batch_size` is specified.\n        Args:\n            zero_grad: Whether to zero the gradients.\n        \"\"\"\nif self.optimizer is not None:\nself.optimizer.step()\nif zero_grad:\nself.optimizer.zero_grad()\nif self.scheduler is not None:\nself.scheduler.step()\nself.state.steps += 1\nif batch_size is not None:\nself.state.iters += batch_size\n# TODO: Support `drop_last = False`\n# self.state.iters += self.batch_size_equivalent\ndef state_dict(self, cls: Callable = dict) -&gt; Mapping:\nr\"\"\"\n        Return dict of all attributes for checkpoint.\n        \"\"\"\nraise NotImplementedError\n@catch\n@on_main_process\ndef save_checkpoint(self) -&gt; None:\nr\"\"\"\n        Save checkpoint to `self.checkpoint_dir`.\n        The checkpoint will be saved to `self.checkpoint_dir/latest.pth`.\n        If `self.state.save_interval` is positive and `self.state.epochs + 1` is a multiple of `save_interval`,\n        the checkpoint will also be copied to `self.checkpoint_dir/epoch-{self.state.epochs}.pth`.\n        If `self.state.is_best` is `True`, the checkpoint will also be copied to `self.checkpoint_dir/best.pth`.\n        \"\"\"\nlatest_path = os.path.join(self.checkpoint_dir, \"latest.pth\")\nself.save(self.state_dict(), latest_path)\nif (\nhasattr(self, \"save_interval\")\nand self.save_interval &gt; 0\nand (self.state.epochs + 1) % self.save_interval == 0\n):\nsave_path = os.path.join(self.checkpoint_dir, f\"epoch-{self.state.epochs}.pth\")\nshutil.copy(latest_path, save_path)\nif self.is_best:\nbest_path = os.path.join(self.checkpoint_dir, \"best.pth\")\nshutil.copy(latest_path, best_path)\ndef load_checkpoint(  # pylint: disable=W1113\nself, checkpoint: Optional[Union[Mapping, str]] = None, override_state: bool = False, *args, **kwargs\n) -&gt; None:\n\"\"\"\n        Load info from checkpoint.\n        Args:\n            checkpoint: Checkpoint (or its path) to load.\n                Defaults to `self.checkpoint_dir/latest.pth`.\n            override_state: If True, override runner state with checkpoint state.\n                Defaults to `False`.\n            *args: Additional arguments to pass to `self.load`.\n            **kwargs: Additional keyword arguments to pass to `self.load`.\n        Raises:\n            FileNotFoundError: If `checkpoint` does not exists.\n        See Also:\n            [`from_checkpoint`][danling.BaseRunner.from_checkpoint]: Build runner from checkpoint.\n            [`load_pretrained`][danling.BaseRunner.load_pretrained]: Load parameters from pretrained checkpoint.\n        \"\"\"\nif checkpoint is None:\ncheckpoint = os.path.join(self.checkpoint_dir, \"latest.pth\")  # type: ignore\n# TODO: Support loading checkpoints in other format\nif isinstance(checkpoint, str):\nif not os.path.exists(checkpoint):\nraise FileNotFoundError(f\"checkpoint is set to {checkpoint} but does not exist.\")\nself.checkpoint = checkpoint  # pylint: disable=W0201\ncheckpoint: Mapping = self.load(checkpoint, *args, **kwargs)  # type: ignore\n# TODO: Wrap state_dict in a dataclass\nif override_state:\nself.__dict__.update(NestedDict(**checkpoint[\"runner\"]))  # type: ignore\nif self.model is not None and \"model\" in checkpoint:\nmodel = self.unwrap_model(self.model)\nmodel.load_state_dict(checkpoint[\"model\"])  # type: ignore\nif self.optimizer is not None and \"optimizer\" in checkpoint:\nself.optimizer.load_state_dict(checkpoint[\"optimizer\"])  # type: ignore\nif self.scheduler is not None and \"scheduler\" in checkpoint:\nself.scheduler.load_state_dict(checkpoint[\"scheduler\"])  # type: ignore\ndef load_pretrained(self, checkpoint: Union[Mapping, str], *args, **kwargs) -&gt; None:\n\"\"\"\n        Load parameters from pretrained checkpoint.\n        Args:\n            checkpoint: Pretrained checkpoint (or its path) to load.\n            *args: Additional arguments to pass to `self.load`.\n            **kwargs: Additional keyword arguments to pass to `self.load`.\n        Raises:\n            FileNotFoundError: If `checkpoint` does not exists.\n        See Also:\n            [`load_checkpoint`][danling.BaseRunner.load_checkpoint]: Load info from checkpoint.\n        \"\"\"\n# TODO: Support loading checkpoints in other format\nif isinstance(checkpoint, str):\nif not os.path.exists(checkpoint):\nraise FileNotFoundError(f\"pretrained is set to {checkpoint} but does not exist.\")\ncheckpoint: Mapping = self.load(checkpoint, *args, **kwargs)  # type: ignore\nif \"model\" in checkpoint:\ncheckpoint = checkpoint[\"model\"]  # type: ignore\nif \"state_dict\" in checkpoint:\ncheckpoint = checkpoint[\"state_dict\"]  # type: ignore\nmodel = self.unwrap_model(self.model)\nmodel.load_state_dict(checkpoint)  # type: ignore\n@classmethod\ndef from_checkpoint(cls, checkpoint: Union[Mapping, str], *args, **kwargs) -&gt; BaseRunner:\nr\"\"\"\n        Build BaseRunner from checkpoint.\n        Args:\n            checkpoint: Checkpoint (or its path) to load.\n                Defaults to `self.checkpoint_dir/latest.pth`.\n            *args: Additional arguments to pass to `self.load`.\n            **kwargs: Additional keyword arguments to pass to `self.load`.\n        Returns:\n            (BaseRunner):\n        \"\"\"\nif isinstance(checkpoint, str):\ncheckpoint = cls.load(checkpoint, *args, **kwargs)\nrunner = cls(**checkpoint[\"runner\"])  # type: ignore\nrunner.load_checkpoint(checkpoint, override_state=False)\nreturn runner\ndef append_result(self, result) -&gt; None:\nr\"\"\"\n        Append result to `self.state.results`.\n        Warnings:\n            `self.state.results` is heavily relied upon for computing metrics.\n            Failed to use this method may lead to unexpected behavior.\n        \"\"\"\nself.state.results.append(result)\ndef print_result(self) -&gt; None:\nr\"\"\"\n        Print latest and best result.\n        \"\"\"\nprint(f\"results: {self.state.results}\")\nprint(f\"latest result: {self.latest_result}\")\nprint(f\"best result: {self.best_result}\")\n@catch\n@on_main_process\ndef save_result(self) -&gt; None:\nr\"\"\"\n        Save result to `self.dir`.\n        This method will save latest and best result to\n        `self.dir/latest.json` and `self.dir/best.json` respectively.\n        \"\"\"\nresults_path = os.path.join(self.dir, \"results.json\")\nself.save({\"id\": self.state.id, \"name\": self.state.name, \"results\": self.state.results}, results_path, indent=4)\nret = {\"id\": self.state.id, \"name\": self.state.name}\nresult = self.latest_result  # type: ignore\nif isinstance(result, FlatDict):\nresult = result.dict()  # type: ignore\n# This is slower but ensure id is the first key\nif result is not None:\nret.update(result)  # type: ignore\nlatest_path = os.path.join(self.dir, \"latest.json\")\nself.save(ret, latest_path, indent=4)\nif self.is_best:\nbest_path = os.path.join(self.dir, \"best.json\")\nshutil.copy(latest_path, best_path)\n</code></pre>"},{"location":"runner/base_runner/#danling.runner.base_runner.BaseRunner.init_logging","title":"<code>init_logging()</code>","text":"<p>Set up logging.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>@on_main_process\ndef init_logging(self) -&gt; None:\nr\"\"\"\n    Set up logging.\n    \"\"\"\n# Why is setting up proper logging so !@?#! ugly?\nlogging.config.dictConfig(\n{\n\"version\": 1,\n\"disable_existing_loggers\": False,\n\"formatters\": {\n\"standard\": {\"format\": \"%(asctime)s [%(levelname)s] %(name)s: %(message)s\"},\n},\n\"handlers\": {\n\"stdout\": {\n\"level\": \"INFO\",\n\"formatter\": \"standard\",\n\"class\": \"logging.StreamHandler\",\n\"stream\": \"ext://sys.stdout\",\n},\n\"logfile\": {\n\"level\": \"DEBUG\",\n\"formatter\": \"standard\",\n\"class\": \"logging.FileHandler\",\n\"filename\": self.log_path,\n\"mode\": \"a\",\n},\n},\n\"loggers\": {\n\"\": {\n\"handlers\": [\"stdout\", \"logfile\"],\n\"level\": \"DEBUG\",\n\"propagate\": True,\n},\n},\n}\n)\nlogging.captureWarnings(True)\nself.logger = logging.getLogger(\"runner\")\nself.logger.flush = lambda: [h.flush() for h in self.logger.handlers]  # type: ignore\n</code></pre>"},{"location":"runner/base_runner/#danling.runner.base_runner.BaseRunner.init_print","title":"<code>init_print(process=0)</code>","text":"<p>Set up <code>print</code>.</p> <p>Only print on a specific <code>process</code> or when <code>force = True</code>.</p> <p>Parameters:</p> Name Type Description Default <code>process</code> <code>int</code> <p>The process to <code>print</code> on.</p> <code>0</code>"},{"location":"runner/base_runner/#danling.runner.base_runner.BaseRunner.init_print--notes","title":"Notes","text":"<p>If <code>self.state.log = True</code>, the default <code>print</code> function will be override by <code>logging.info</code>.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>def init_print(self, process: int = 0) -&gt; None:\nr\"\"\"\n    Set up `print`.\n    Only print on a specific `process` or when `force = True`.\n    Args:\n        process: The process to `print` on.\n    Notes\n    -----\n    If `self.state.log = True`, the default `print` function will be override by `logging.info`.\n    \"\"\"\nlogger = logging.getLogger(\"print\")\nlogger.flush = lambda: [h.flush for h in logger.handlers]  # type: ignore\nimport builtins as __builtin__  # pylint: disable=C0415\nbuiltin_print = __builtin__.print\n@catch\ndef print(*args, force=False, end=\"\\n\", file=None, flush=False, **kwargs):  # pylint: disable=W0622\nif self.rank == process or force:\nif self.state.log:\nlogger.info(*args, **kwargs)\nelse:\nbuiltin_print(*args, end=end, file=file, flush=flush, **kwargs)\n__builtin__.print = print\n</code></pre>"},{"location":"runner/base_runner/#danling.runner.base_runner.BaseRunner.init_tensorboard","title":"<code>init_tensorboard(*args, **kwargs)</code>","text":"<p>Set up Tensoraoard SummaryWriter.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>@on_main_process\ndef init_tensorboard(self, *args, **kwargs) -&gt; None:\nr\"\"\"\n    Set up Tensoraoard SummaryWriter.\n    \"\"\"\nraise NotImplementedError\n</code></pre>"},{"location":"runner/base_runner/#danling.runner.base_runner.BaseRunner.set_seed","title":"<code>set_seed(seed=None, bias=None)</code>","text":"<p>Set up random seed.</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>Optional[int]</code> <p>Random seed to set. Defaults to <code>self.state.seed</code> (<code>config.seed</code>).</p> <code>None</code> <code>bias</code> <code>Optional[int]</code> <p>Make the seed different for each processes.</p> <p>This avoids same data augmentation are applied on every processes.</p> <p>Defaults to <code>self.rank</code>.</p> <p>Set to <code>False</code> to disable this feature.</p> <code>None</code> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>def set_seed(self, seed: Optional[int] = None, bias: Optional[int] = None) -&gt; None:\nr\"\"\"\n    Set up random seed.\n    Args:\n        seed: Random seed to set.\n            Defaults to `self.state.seed` (`config.seed`).\n        bias: Make the seed different for each processes.\n            This avoids same data augmentation are applied on every processes.\n            Defaults to `self.rank`.\n            Set to `False` to disable this feature.\n    \"\"\"\nif seed is None:\nseed = self.state.seed\nif bias is None:\nbias = self.rank\nif bias:\nseed += bias\nnp.random.seed(seed)\nrandom.seed(seed)\n</code></pre>"},{"location":"runner/base_runner/#danling.runner.base_runner.BaseRunner.set_deterministic","title":"<code>set_deterministic()</code>","text":"<p>Set up deterministic.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>def set_deterministic(self) -&gt; None:\nr\"\"\"\n    Set up deterministic.\n    \"\"\"\nraise NotImplementedError\n</code></pre>"},{"location":"runner/base_runner/#danling.runner.base_runner.BaseRunner.scale_lr","title":"<code>scale_lr(lr, lr_scale_factor=None, batch_size_base=None)</code>","text":"<p>Scale learning rate according to linear scaling rule.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>def scale_lr(\nself,\nlr: float,  # pylint: disable=C0103\nlr_scale_factor: Optional[float] = None,\nbatch_size_base: Optional[int] = None,\n) -&gt; float:\nr\"\"\"\n    Scale learning rate according to [linear scaling rule](https://arxiv.org/abs/1706.02677).\n    \"\"\"\n# pylint: disable=W0201\nif lr_scale_factor is None:\nif batch_size_base is None:\nbatch_size_base = getattr(self, \"batch_size_base\", None)\nif batch_size_base is None:\nraise ValueError(\"batch_size_base must be specified to auto scale lr\")\nlr_scale_factor = self.batch_size_equivalent / batch_size_base\nelif batch_size_base is not None:\nwarn(\n\"batch_size_base will be ignored if lr_scale_factor is specified\",\nRuntimeWarning,\n)\nlr = lr * lr_scale_factor  # pylint: disable=C0103, E1101\nself.lr_scale_factor = lr_scale_factor\nreturn lr\n</code></pre>"},{"location":"runner/base_runner/#danling.runner.base_runner.BaseRunner.step","title":"<code>step(zero_grad=True, batch_size=None)</code>","text":"<p>Step optimizer and scheduler.</p> <p>This method increment <code>self.state.steps</code>.</p> <p>This method also increment <code>self.state.iters</code> when <code>batch_size</code> is specified.</p> <p>Parameters:</p> Name Type Description Default <code>zero_grad</code> <code>bool</code> <p>Whether to zero the gradients.</p> <code>True</code> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>def step(self, zero_grad: bool = True, batch_size: Optional[int] = None) -&gt; None:\nr\"\"\"\n    Step optimizer and scheduler.\n    This method increment `self.state.steps`.\n    This method also increment `self.state.iters` when `batch_size` is specified.\n    Args:\n        zero_grad: Whether to zero the gradients.\n    \"\"\"\nif self.optimizer is not None:\nself.optimizer.step()\nif zero_grad:\nself.optimizer.zero_grad()\nif self.scheduler is not None:\nself.scheduler.step()\nself.state.steps += 1\nif batch_size is not None:\nself.state.iters += batch_size\n</code></pre>"},{"location":"runner/base_runner/#danling.runner.base_runner.BaseRunner.state_dict","title":"<code>state_dict(cls=dict)</code>","text":"<p>Return dict of all attributes for checkpoint.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>def state_dict(self, cls: Callable = dict) -&gt; Mapping:\nr\"\"\"\n    Return dict of all attributes for checkpoint.\n    \"\"\"\nraise NotImplementedError\n</code></pre>"},{"location":"runner/base_runner/#danling.runner.base_runner.BaseRunner.save_checkpoint","title":"<code>save_checkpoint()</code>","text":"<p>Save checkpoint to <code>self.checkpoint_dir</code>.</p> <p>The checkpoint will be saved to <code>self.checkpoint_dir/latest.pth</code>.</p> <p>If <code>self.state.save_interval</code> is positive and <code>self.state.epochs + 1</code> is a multiple of <code>save_interval</code>, the checkpoint will also be copied to <code>self.checkpoint_dir/epoch-{self.state.epochs}.pth</code>.</p> <p>If <code>self.state.is_best</code> is <code>True</code>, the checkpoint will also be copied to <code>self.checkpoint_dir/best.pth</code>.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>@catch\n@on_main_process\ndef save_checkpoint(self) -&gt; None:\nr\"\"\"\n    Save checkpoint to `self.checkpoint_dir`.\n    The checkpoint will be saved to `self.checkpoint_dir/latest.pth`.\n    If `self.state.save_interval` is positive and `self.state.epochs + 1` is a multiple of `save_interval`,\n    the checkpoint will also be copied to `self.checkpoint_dir/epoch-{self.state.epochs}.pth`.\n    If `self.state.is_best` is `True`, the checkpoint will also be copied to `self.checkpoint_dir/best.pth`.\n    \"\"\"\nlatest_path = os.path.join(self.checkpoint_dir, \"latest.pth\")\nself.save(self.state_dict(), latest_path)\nif (\nhasattr(self, \"save_interval\")\nand self.save_interval &gt; 0\nand (self.state.epochs + 1) % self.save_interval == 0\n):\nsave_path = os.path.join(self.checkpoint_dir, f\"epoch-{self.state.epochs}.pth\")\nshutil.copy(latest_path, save_path)\nif self.is_best:\nbest_path = os.path.join(self.checkpoint_dir, \"best.pth\")\nshutil.copy(latest_path, best_path)\n</code></pre>"},{"location":"runner/base_runner/#danling.runner.base_runner.BaseRunner.load_checkpoint","title":"<code>load_checkpoint(checkpoint=None, override_state=False, *args, **kwargs)</code>","text":"<p>Load info from checkpoint.</p> <p>Parameters:</p> Name Type Description Default <code>checkpoint</code> <code>Optional[Union[Mapping, str]]</code> <p>Checkpoint (or its path) to load. Defaults to <code>self.checkpoint_dir/latest.pth</code>.</p> <code>None</code> <code>override_state</code> <code>bool</code> <p>If True, override runner state with checkpoint state. Defaults to <code>False</code>.</p> <code>False</code> <code>*args</code> <p>Additional arguments to pass to <code>self.load</code>.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to <code>self.load</code>.</p> <code>{}</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If <code>checkpoint</code> does not exists.</p> See Also <p><code>from_checkpoint</code>: Build runner from checkpoint. <code>load_pretrained</code>: Load parameters from pretrained checkpoint.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>def load_checkpoint(  # pylint: disable=W1113\nself, checkpoint: Optional[Union[Mapping, str]] = None, override_state: bool = False, *args, **kwargs\n) -&gt; None:\n\"\"\"\n    Load info from checkpoint.\n    Args:\n        checkpoint: Checkpoint (or its path) to load.\n            Defaults to `self.checkpoint_dir/latest.pth`.\n        override_state: If True, override runner state with checkpoint state.\n            Defaults to `False`.\n        *args: Additional arguments to pass to `self.load`.\n        **kwargs: Additional keyword arguments to pass to `self.load`.\n    Raises:\n        FileNotFoundError: If `checkpoint` does not exists.\n    See Also:\n        [`from_checkpoint`][danling.BaseRunner.from_checkpoint]: Build runner from checkpoint.\n        [`load_pretrained`][danling.BaseRunner.load_pretrained]: Load parameters from pretrained checkpoint.\n    \"\"\"\nif checkpoint is None:\ncheckpoint = os.path.join(self.checkpoint_dir, \"latest.pth\")  # type: ignore\n# TODO: Support loading checkpoints in other format\nif isinstance(checkpoint, str):\nif not os.path.exists(checkpoint):\nraise FileNotFoundError(f\"checkpoint is set to {checkpoint} but does not exist.\")\nself.checkpoint = checkpoint  # pylint: disable=W0201\ncheckpoint: Mapping = self.load(checkpoint, *args, **kwargs)  # type: ignore\n# TODO: Wrap state_dict in a dataclass\nif override_state:\nself.__dict__.update(NestedDict(**checkpoint[\"runner\"]))  # type: ignore\nif self.model is not None and \"model\" in checkpoint:\nmodel = self.unwrap_model(self.model)\nmodel.load_state_dict(checkpoint[\"model\"])  # type: ignore\nif self.optimizer is not None and \"optimizer\" in checkpoint:\nself.optimizer.load_state_dict(checkpoint[\"optimizer\"])  # type: ignore\nif self.scheduler is not None and \"scheduler\" in checkpoint:\nself.scheduler.load_state_dict(checkpoint[\"scheduler\"])  # type: ignore\n</code></pre>"},{"location":"runner/base_runner/#danling.runner.base_runner.BaseRunner.load_pretrained","title":"<code>load_pretrained(checkpoint, *args, **kwargs)</code>","text":"<p>Load parameters from pretrained checkpoint.</p> <p>Parameters:</p> Name Type Description Default <code>checkpoint</code> <code>Union[Mapping, str]</code> <p>Pretrained checkpoint (or its path) to load.</p> required <code>*args</code> <p>Additional arguments to pass to <code>self.load</code>.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to <code>self.load</code>.</p> <code>{}</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If <code>checkpoint</code> does not exists.</p> See Also <p><code>load_checkpoint</code>: Load info from checkpoint.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>def load_pretrained(self, checkpoint: Union[Mapping, str], *args, **kwargs) -&gt; None:\n\"\"\"\n    Load parameters from pretrained checkpoint.\n    Args:\n        checkpoint: Pretrained checkpoint (or its path) to load.\n        *args: Additional arguments to pass to `self.load`.\n        **kwargs: Additional keyword arguments to pass to `self.load`.\n    Raises:\n        FileNotFoundError: If `checkpoint` does not exists.\n    See Also:\n        [`load_checkpoint`][danling.BaseRunner.load_checkpoint]: Load info from checkpoint.\n    \"\"\"\n# TODO: Support loading checkpoints in other format\nif isinstance(checkpoint, str):\nif not os.path.exists(checkpoint):\nraise FileNotFoundError(f\"pretrained is set to {checkpoint} but does not exist.\")\ncheckpoint: Mapping = self.load(checkpoint, *args, **kwargs)  # type: ignore\nif \"model\" in checkpoint:\ncheckpoint = checkpoint[\"model\"]  # type: ignore\nif \"state_dict\" in checkpoint:\ncheckpoint = checkpoint[\"state_dict\"]  # type: ignore\nmodel = self.unwrap_model(self.model)\nmodel.load_state_dict(checkpoint)  # type: ignore\n</code></pre>"},{"location":"runner/base_runner/#danling.runner.base_runner.BaseRunner.from_checkpoint","title":"<code>from_checkpoint(checkpoint, *args, **kwargs)</code>  <code>classmethod</code>","text":"<p>Build BaseRunner from checkpoint.</p> <p>Parameters:</p> Name Type Description Default <code>checkpoint</code> <code>Union[Mapping, str]</code> <p>Checkpoint (or its path) to load. Defaults to <code>self.checkpoint_dir/latest.pth</code>.</p> required <code>*args</code> <p>Additional arguments to pass to <code>self.load</code>.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to <code>self.load</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>BaseRunner</code> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>@classmethod\ndef from_checkpoint(cls, checkpoint: Union[Mapping, str], *args, **kwargs) -&gt; BaseRunner:\nr\"\"\"\n    Build BaseRunner from checkpoint.\n    Args:\n        checkpoint: Checkpoint (or its path) to load.\n            Defaults to `self.checkpoint_dir/latest.pth`.\n        *args: Additional arguments to pass to `self.load`.\n        **kwargs: Additional keyword arguments to pass to `self.load`.\n    Returns:\n        (BaseRunner):\n    \"\"\"\nif isinstance(checkpoint, str):\ncheckpoint = cls.load(checkpoint, *args, **kwargs)\nrunner = cls(**checkpoint[\"runner\"])  # type: ignore\nrunner.load_checkpoint(checkpoint, override_state=False)\nreturn runner\n</code></pre>"},{"location":"runner/base_runner/#danling.runner.base_runner.BaseRunner.append_result","title":"<code>append_result(result)</code>","text":"<p>Append result to <code>self.state.results</code>.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>def append_result(self, result) -&gt; None:\nr\"\"\"\n    Append result to `self.state.results`.\n    Warnings:\n        `self.state.results` is heavily relied upon for computing metrics.\n        Failed to use this method may lead to unexpected behavior.\n    \"\"\"\nself.state.results.append(result)\n</code></pre>"},{"location":"runner/base_runner/#danling.runner.base_runner.BaseRunner.print_result","title":"<code>print_result()</code>","text":"<p>Print latest and best result.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>def print_result(self) -&gt; None:\nr\"\"\"\n    Print latest and best result.\n    \"\"\"\nprint(f\"results: {self.state.results}\")\nprint(f\"latest result: {self.latest_result}\")\nprint(f\"best result: {self.best_result}\")\n</code></pre>"},{"location":"runner/base_runner/#danling.runner.base_runner.BaseRunner.save_result","title":"<code>save_result()</code>","text":"<p>Save result to <code>self.dir</code>.</p> <p>This method will save latest and best result to <code>self.dir/latest.json</code> and <code>self.dir/best.json</code> respectively.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>@catch\n@on_main_process\ndef save_result(self) -&gt; None:\nr\"\"\"\n    Save result to `self.dir`.\n    This method will save latest and best result to\n    `self.dir/latest.json` and `self.dir/best.json` respectively.\n    \"\"\"\nresults_path = os.path.join(self.dir, \"results.json\")\nself.save({\"id\": self.state.id, \"name\": self.state.name, \"results\": self.state.results}, results_path, indent=4)\nret = {\"id\": self.state.id, \"name\": self.state.name}\nresult = self.latest_result  # type: ignore\nif isinstance(result, FlatDict):\nresult = result.dict()  # type: ignore\n# This is slower but ensure id is the first key\nif result is not None:\nret.update(result)  # type: ignore\nlatest_path = os.path.join(self.dir, \"latest.json\")\nself.save(ret, latest_path, indent=4)\nif self.is_best:\nbest_path = os.path.join(self.dir, \"best.json\")\nshutil.copy(latest_path, best_path)\n</code></pre>"},{"location":"runner/runner_base/","title":"RunnerBase","text":"<p>Base class for all runners.</p> <p><code>RunnerBase</code> is designed as a \u201cdataclass\u201d.</p> <p>It defines all basic attributes and relevant properties such as <code>scores</code>, <code>progress</code>, etc.</p> <p><code>RunnerBase</code> also defines basic IO operations such as <code>save</code>, <code>load</code>, <code>json</code>, <code>yaml</code>, etc.</p> <p>Model:</p> Name Type Description <code>model</code> <code>Callable</code> <code>criterion</code> <code>Callable</code> <code>optimizer</code> <code>Optional[Any]</code> <code>scheduler</code> <code>Optional[Any]</code> <p>Data:</p> Name Type Description <code>datasets</code> <code>FlatDict</code> <p>All datasets, should be in the form of <code>{subset: dataset}</code>.</p> <code>datasamplers</code> <code>FlatDict</code> <p>All datasamplers, should be in the form of <code>{subset: datasampler}</code>.</p> <code>dataloaders</code> <code>FlatDict</code> <p>All dataloaders, should be in the form of <code>{subset: dataloader}</code>.</p> <code>batch_size</code> <code>int, property</code> <p>Number of samples per batch in train dataloader or the first dataloader.</p> <code>batch_size_equivalent</code> <code>int, property</code> <p>Total batch_size (<code>batch_size * world_size * accum_steps</code>).</p> <p><code>datasets</code>, <code>datasamplers</code>, <code>dataloaders</code> should be a dict with the same keys. Their keys should be <code>split</code> (e.g. <code>train</code>, <code>val</code>, <code>test</code>).</p> <p>Progress:</p> Name Type Description <code>progress</code> <code>float, property</code> <p>Running Progress, in <code>range(0, 1)</code>.</p> <p>Results:</p> Name Type Description <code>latest_result</code> <code>NestedDict, property</code> <p>Most recent results, should be in the form of <code>{subset: {index: score}}</code>.</p> <code>best_result</code> <code>NestedDict, property</code> <p>Best recent results, should be in the form of <code>{subset: {index: score}}</code>.</p> <code>scores</code> <code>List[float], property</code> <p>All scores.</p> <code>latest_score</code> <code>float, property</code> <p>Most recent score.</p> <code>best_score</code> <code>float, property</code> <p>Best score.</p> <code>index_set</code> <code>Optional[str]</code> <p>The subset to calculate the core score. If is <code>None</code>, will use the last set of the result.</p> <code>index</code> <code>str</code> <p>The index to calculate the core score. Defaults to <code>\"loss\"</code>.</p> <code>is_best</code> <code>bool, property</code> <p>If <code>latest_score == best_score</code>.</p> <p>IO:</p> Name Type Description <code>dir</code> <code>str, property</code> <p>Directory of the run. Defaults to <code>os.path.join(self.project_root, f\"{self.name}-{self.id}\")</code>.</p> <code>checkpoint_dir</code> <code>str, property</code> <p>Directory of checkpoints.</p> <code>log_path</code> <code>str, property</code> <p>Path of log file.</p> <code>checkpoint_dir_name</code> <code>str</code> <p>The name of the directory under <code>runner.dir</code> to save checkpoints. Defaults to <code>\"checkpoints\"</code>.</p> <p>Parallel Training:</p> Name Type Description <code>world_size</code> <code>int, property</code> <p>Number of processes.</p> <code>rank</code> <code>int, property</code> <p>Process index of all processes.</p> <code>local_rank</code> <code>int, property</code> <p>Process index of local processes.</p> <code>distributed</code> <code>bool, property</code> <p>If runner is running in distributed mode.</p> <code>is_main_process</code> <code>bool, property</code> <p>If current process is the main process of all processes.</p> <code>is_local_main_process</code> <code>bool, property</code> <p>If current process is the main process of local processes.</p> <p>logging:</p> Name Type Description <code>logger</code> <code>Optional[logging.Logger]</code> <code>writer</code> <code>Optional[Any]</code> Notes <p>The <code>RunnerBase</code> class is not intended to be used directly, nor to be directly inherit from.</p> <p>This is because <code>RunnerBase</code> is designed as a \u201cdataclass\u201d, and is meant for demonstrating all attributes and properties only.</p> See Also <p><code>RunnerState</code>: The runeer base that stores runtime information. <code>BaseRunner</code>: The base runner class.</p> Source code in <code>danling/runner/runner_base.py</code> Python<pre><code>class RunnerBase:\nr\"\"\"\n    Base class for all runners.\n    `RunnerBase` is designed as a \"dataclass\".\n    It defines all basic attributes and relevant properties such as `scores`, `progress`, etc.\n    `RunnerBase` also defines basic IO operations such as `save`, `load`, `json`, `yaml`, etc.\n    Attributes: Model:\n        model (Callable):\n        criterion (Callable):\n        optimizer:\n        scheduler:\n    Attributes: Data:\n        datasets (FlatDict): All datasets, should be in the form of ``{subset: dataset}``.\n        datasamplers (FlatDict): All datasamplers, should be in the form of ``{subset: datasampler}``.\n        dataloaders (FlatDict): All dataloaders, should be in the form of ``{subset: dataloader}``.\n        batch_size (int, property): Number of samples per batch in train dataloader or the first dataloader.\n        batch_size_equivalent (int, property): Total batch_size (`batch_size * world_size * accum_steps`).\n    `datasets`, `datasamplers`, `dataloaders` should be a dict with the same keys.\n    Their keys should be `split` (e.g. `train`, `val`, `test`).\n    Attributes: Progress:\n        progress (float, property): Running Progress, in `range(0, 1)`.\n    Attributes: Results:\n        latest_result (NestedDict, property): Most recent results,\n            should be in the form of ``{subset: {index: score}}``.\n        best_result (NestedDict, property): Best recent results, should be in the form of ``{subset: {index: score}}``.\n        scores (List[float], property): All scores.\n        latest_score (float, property): Most recent score.\n        best_score (float, property): Best score.\n        index_set (Optional[str]): The subset to calculate the core score.\n            If is `None`, will use the last set of the result.\n        index (str): The index to calculate the core score.\n            Defaults to `\"loss\"`.\n        is_best (bool, property): If `latest_score == best_score`.\n    Attributes: IO:\n        dir (str, property): Directory of the run.\n            Defaults to `os.path.join(self.project_root, f\"{self.name}-{self.id}\")`.\n        checkpoint_dir (str, property): Directory of checkpoints.\n        log_path (str, property):  Path of log file.\n        checkpoint_dir_name (str): The name of the directory under `runner.dir` to save checkpoints.\n            Defaults to `\"checkpoints\"`.\n    Attributes: Parallel Training:\n        world_size (int, property): Number of processes.\n        rank (int, property): Process index of all processes.\n        local_rank (int, property): Process index of local processes.\n        distributed (bool, property): If runner is running in distributed mode.\n        is_main_process (bool, property): If current process is the main process of all processes.\n        is_local_main_process (bool, property): If current process is the main process of local processes.\n    Attributes: logging:\n        logger:\n        writer:\n    Notes:\n        The `RunnerBase` class is not intended to be used directly, nor to be directly inherit from.\n        This is because `RunnerBase` is designed as a \"dataclass\",\n        and is meant for demonstrating all attributes and properties only.\n    See Also:\n        [`RunnerState`][danling.runner.runner_state.RunnerState]: The runeer base that stores runtime information.\n        [`BaseRunner`][danling.runner.BaseRunner]: The base runner class.\n    \"\"\"\n# pylint: disable=R0902, R0904\n# DO NOT set default value in class, as they won't be stored in `__dict__`.\nstate: RunnerState\nmodel: Optional[Callable] = None\ncriterion: Optional[Callable] = None\noptimizer: Optional[Any] = None\nscheduler: Optional[Any] = None\ndatasets: FlatDict\ndatasamplers: FlatDict\ndataloaders: FlatDict\nmeters: Optional[AverageMeters] = None\nlogger: Optional[logging.Logger] = None\nwriter: Optional[Any] = None\ndef __init__(self, *args, **kwargs):\nsuper().__init__()\nself.state = RunnerState(*args, **kwargs)\nself.meters = AverageMeters()\nself.datasets = FlatDict()\nself.datasamplers = FlatDict()\nself.dataloaders = FlatDict()\n@property\ndef batch_size(self) -&gt; int:\nr\"\"\"\n        Batch size.\n        Notes:\n            If `train` is in `dataloaders`, then `batch_size` is the batch size of `train`.\n            Otherwise, `batch_size` is the batch size of the first dataloader.\n        Returns:\n            (int):\n        \"\"\"\nif self.dataloaders:\nloader = self.dataloaders[\"train\"] if \"train\" in self.dataloaders else next(iter(self.dataloaders.values()))\nreturn loader.batch_size\nraise AttributeError(\"batch_size could not be inferred, since no dataloaedr found.\")\n@property\ndef batch_size_equivalent(self) -&gt; int:\nr\"\"\"\n        Actual batch size.\n        Returns:\n            (int): `batch_size` * `world_size` * `accum_steps`\n        \"\"\"\nreturn self.batch_size * self.world_size * getattr(self, \"accum_steps\", 1)\n@property\ndef accum_steps(self) -&gt; int:\nr\"\"\"\n        Accumulated steps.\n        Returns:\n            (int):\n        \"\"\"\nraise AttributeError(\"accum_steps is not defined.\")\n@property\ndef device(self) -&gt; Any:\nr\"\"\"\n        Device of runner.\n        \"\"\"\nraise NotImplementedError\n@property\ndef world_size(self) -&gt; int:\nr\"\"\"\n        Number of processes.\n        \"\"\"\nreturn 1\n@property\ndef rank(self) -&gt; int:\nr\"\"\"\n        Process index of all processes.\n        \"\"\"\nreturn 0\n@property\ndef local_rank(self) -&gt; int:\nr\"\"\"\n        Process index of local processes.\n        \"\"\"\nreturn 0\n@property\ndef distributed(self) -&gt; bool:\nr\"\"\"\n        If runner is running in distributed mode.\n        \"\"\"\nreturn self.world_size &gt; 1\n@property\ndef is_main_process(self) -&gt; bool:\nr\"\"\"\n        If current process is the main process of all processes.\n        \"\"\"\nreturn self.rank == 0\n@property\ndef is_local_main_process(self) -&gt; bool:\nr\"\"\"\n        If current process is the main process of local processes.\n        \"\"\"\nreturn self.local_rank == 0\n@catch\ndef save(  # pylint: disable=W1113\nself, obj: Any, file: PathStr, main_process_only: bool = True, *args, **kwargs\n) -&gt; File:\nr\"\"\"\n        Save any file with supported extensions.\n        `Runner.save` internally calls `dl.save`,\n        but with additional arguments to allow it save only on the main process.\n        Moreover, any error raised by `Runner.save` will be caught and logged.\n        \"\"\"\nif main_process_only and self.is_main_process or not main_process_only:\nreturn save(obj, file, *args, **kwargs)\nreturn file\n@staticmethod\ndef load(file: PathStr, *args, **kwargs) -&gt; Any:  # pylint: disable=C0103\nr\"\"\"\n        Load any file with supported extensions.\n        `Runner.load` is identical to `dl.save`.\n        \"\"\"\nreturn load(file, *args, **kwargs)\ndef dict(self, cls: Callable = dict) -&gt; Mapping:\nr\"\"\"\n        Convert state to Mapping.\n        Args:\n            cls: Target `clc to convert to.\n        \"\"\"\n# pylint: disable=C0103\nreturn self.state.dict(cls)\n@catch\ndef json(self, file: File, main_process_only: bool = True, *args, **kwargs) -&gt; None:  # pylint: disable=W1113\nr\"\"\"\n        Dump Runner State to json file.\n        \"\"\"\nif main_process_only and self.is_main_process or not main_process_only:\nreturn self.state.json(file, *args, **kwargs)\n@classmethod\ndef from_json(cls, file: File, *args, **kwargs) -&gt; RunnerBase:\nr\"\"\"\n        Construct Runner from json file.\n        This function calls `self.from_jsons()` to construct object from json string.\n        You may overwrite `from_jsons` in case something is not json serializable.\n        \"\"\"\nwith FlatDict.open(file) as fp:  # pylint: disable=C0103\nreturn cls.from_jsons(fp.read(), *args, **kwargs)\ndef jsons(self, *args, **kwargs) -&gt; str:\nr\"\"\"\n        Dump Runner State to json string.\n        \"\"\"\nreturn self.state.jsons(*args, **kwargs)\n@classmethod\ndef from_jsons(cls, string: str, *args, **kwargs) -&gt; RunnerBase:\nr\"\"\"\n        Construct Runner from json string.\n        \"\"\"\nreturn cls(Config.from_jsons(string, *args, **kwargs))\n@catch\ndef yaml(self, file: File, main_process_only: bool = True, *args, **kwargs) -&gt; None:  # pylint: disable=W1113\nr\"\"\"\n        Dump Runner State to yaml file.\n        \"\"\"\nif main_process_only and self.is_main_process or not main_process_only:\nreturn self.state.yaml(file, *args, **kwargs)\n@classmethod\ndef from_yaml(cls, file: File, *args, **kwargs) -&gt; RunnerBase:\nr\"\"\"\n        Construct Runner from yaml file.\n        This function calls `self.from_yamls()` to construct object from yaml string.\n        You may overwrite `from_yamls` in case something is not yaml serializable.\n        \"\"\"\nwith FlatDict.open(file) as fp:  # pylint: disable=C0103\nreturn cls.from_yamls(fp.read(), *args, **kwargs)\ndef yamls(self, *args, **kwargs) -&gt; str:\nr\"\"\"\n        Dump Runner State to yaml string.\n        \"\"\"\nreturn self.state.yamls(*args, **kwargs)\n@classmethod\ndef from_yamls(cls, string: str, *args, **kwargs) -&gt; RunnerBase:\nr\"\"\"\n        Construct Runner from yaml string.\n        \"\"\"\nreturn cls(Config.from_yamls(string, *args, **kwargs))\n@property\ndef progress(self) -&gt; float:\nr\"\"\"\n        Training Progress.\n        Returns:\n            (float):\n        Raises:\n            RuntimeError: If no terminal is defined.\n        \"\"\"\nif hasattr(self.state, \"iter_end\"):\nreturn self.state.iters / self.state.iter_end\nif hasattr(self.state, \"step_end\"):\nreturn self.state.steps / self.state.step_end\nif hasattr(self.state, \"epoch_end\"):\nreturn self.state.epochs / self.state.epoch_end\nraise RuntimeError(\"DanLing cannot determine progress since no terminal is defined.\")\n@property\ndef best_fn(self) -&gt; Callable:  # pylint: disable=C0103\nr\"\"\"\n        Function to determine the best score from a list of scores.\n        Subclass can override this method to accommodate needs, such as `min`.\n        Returns:\n            (callable): `max`\n        \"\"\"\nreturn max\n@property\ndef latest_result(self) -&gt; Optional[NestedDict]:\nr\"\"\"\n        Latest result.\n        \"\"\"\nreturn self.state.results[-1] if self.state.results else None\n@property\ndef best_result(self) -&gt; Optional[NestedDict]:\nr\"\"\"\n        Best result.\n        \"\"\"\nif not self.state.results:\nreturn None\nreturn self.state.results[-1 - self.scores[::-1].index(self.best_score)]  # type: ignore\n@property\ndef scores(self) -&gt; List[float]:\nr\"\"\"\n        All scores.\n        Scores are extracted from results by `index_set` and `runner.index`,\n        following `[r[index_set][self.state.index] for r in self.state.results]`.\n        By default, `index_set` points to `self.state.index_set` and is set to `val`,\n        if `self.state.index_set` is not set, it will be the last key of the last result.\n        Scores are considered as the index of the performance of the model.\n        It is useful to determine the best model and the best hyper-parameters.\n        \"\"\"\nif not self.state.results:\nreturn []\nindex_set = self.state.index_set or next(reversed(self.state.results[-1]))\nreturn [r[index_set][self.state.index] for r in self.state.results]\n@property\ndef latest_score(self) -&gt; Optional[float]:\nr\"\"\"\n        Latest score.\n        \"\"\"\nreturn self.scores[-1] if self.state.results else None\n@property\ndef best_score(self) -&gt; Optional[float]:\nr\"\"\"\n        Best score.\n        \"\"\"\nreturn self.best_fn(self.scores) if self.results else None\n@property\ndef is_best(self) -&gt; bool:\nr\"\"\"\n        If current epoch is the best epoch.\n        \"\"\"\ntry:\nreturn abs(self.latest_score - self.best_score) &lt; 1e-7  # type: ignore\nexcept TypeError:\nreturn True\n@property  # type: ignore\n@ensure_dir\ndef dir(self) -&gt; str:\nr\"\"\"\n        Directory of the run.\n        \"\"\"\nreturn os.path.join(self.project_root, f\"{self.name}-{self.id}\")\n@property\ndef log_path(self) -&gt; str:\nr\"\"\"\n        Path of log file.\n        \"\"\"\nreturn os.path.join(self.dir, \"run.log\")\n@property  # type: ignore\n@ensure_dir\ndef checkpoint_dir(self) -&gt; str:\nr\"\"\"\n        Directory of checkpoints.\n        \"\"\"\nreturn os.path.join(self.dir, self.checkpoint_dir_name)\ndef __getattr__(self, name) -&gt; Any:\nif \"state\" not in self:\nraise RuntimeError(\"Runner is not initialised yet.\")\nif name in self.state:\nreturn self.state[name]\nif name in dir(self.state):\nreturn getattr(self.state, name)\nraise super().__getattribute__(name)\ndef __setattr__(self, name, value) -&gt; None:\nif name in self.__dict__ and isinstance(self.__dict__[name], Variable):\nself.__dict__[name].set(value)\nelse:\nself.__dict__[name] = value\ndef __contains__(self, name) -&gt; bool:\nreturn name in self.__dict__\ndef __repr__(self):\nlines = []\nfor key, value in self.__dict__.items():\nvalue_str = repr(value)\nvalue_str = self._add_indent(value_str)\nlines.append(\"(\" + key + \"): \" + value_str)\nmain_str = self.__class__.__name__ + \"(\"\nif lines:\nmain_str += \"\\n  \" + \"\\n  \".join(lines) + \"\\n\"\nmain_str += \")\"\nreturn main_str\ndef _add_indent(self, text):\nlines = text.split(\"\\n\")\n# don't do anything for single-line stuff\nif len(lines) == 1:\nreturn text\nfirst = lines.pop(0)\n# add 2 spaces to each line but the first\nlines = [(2 * \" \") + line for line in lines]\nlines = \"\\n\".join(lines)\nlines = first + \"\\n\" + lines\nreturn lines\n</code></pre>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.batch_size","title":"<code>batch_size: int</code>  <code>property</code>","text":"<p>Batch size.</p> Notes <p>If <code>train</code> is in <code>dataloaders</code>, then <code>batch_size</code> is the batch size of <code>train</code>. Otherwise, <code>batch_size</code> is the batch size of the first dataloader.</p> <p>Returns:</p> Type Description <code>int</code>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.batch_size_equivalent","title":"<code>batch_size_equivalent: int</code>  <code>property</code>","text":"<p>Actual batch size.</p> <p>Returns:</p> Type Description <code>int</code> <p><code>batch_size</code> * <code>world_size</code> * <code>accum_steps</code></p>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.accum_steps","title":"<code>accum_steps: int</code>  <code>property</code>","text":"<p>Accumulated steps.</p> <p>Returns:</p> Type Description <code>int</code>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.device","title":"<code>device: Any</code>  <code>property</code>","text":"<p>Device of runner.</p>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.world_size","title":"<code>world_size: int</code>  <code>property</code>","text":"<p>Number of processes.</p>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.rank","title":"<code>rank: int</code>  <code>property</code>","text":"<p>Process index of all processes.</p>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.local_rank","title":"<code>local_rank: int</code>  <code>property</code>","text":"<p>Process index of local processes.</p>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.distributed","title":"<code>distributed: bool</code>  <code>property</code>","text":"<p>If runner is running in distributed mode.</p>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.is_main_process","title":"<code>is_main_process: bool</code>  <code>property</code>","text":"<p>If current process is the main process of all processes.</p>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.is_local_main_process","title":"<code>is_local_main_process: bool</code>  <code>property</code>","text":"<p>If current process is the main process of local processes.</p>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.progress","title":"<code>progress: float</code>  <code>property</code>","text":"<p>Training Progress.</p> <p>Returns:</p> Type Description <code>float</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If no terminal is defined.</p>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.best_fn","title":"<code>best_fn: Callable</code>  <code>property</code>","text":"<p>Function to determine the best score from a list of scores.</p> <p>Subclass can override this method to accommodate needs, such as <code>min</code>.</p> <p>Returns:</p> Type Description <code>callable</code> <p><code>max</code></p>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.latest_result","title":"<code>latest_result: Optional[NestedDict]</code>  <code>property</code>","text":"<p>Latest result.</p>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.best_result","title":"<code>best_result: Optional[NestedDict]</code>  <code>property</code>","text":"<p>Best result.</p>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.scores","title":"<code>scores: List[float]</code>  <code>property</code>","text":"<p>All scores.</p> <p>Scores are extracted from results by <code>index_set</code> and <code>runner.index</code>, following <code>[r[index_set][self.state.index] for r in self.state.results]</code>.</p> <p>By default, <code>index_set</code> points to <code>self.state.index_set</code> and is set to <code>val</code>, if <code>self.state.index_set</code> is not set, it will be the last key of the last result.</p> <p>Scores are considered as the index of the performance of the model. It is useful to determine the best model and the best hyper-parameters.</p>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.latest_score","title":"<code>latest_score: Optional[float]</code>  <code>property</code>","text":"<p>Latest score.</p>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.best_score","title":"<code>best_score: Optional[float]</code>  <code>property</code>","text":"<p>Best score.</p>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.is_best","title":"<code>is_best: bool</code>  <code>property</code>","text":"<p>If current epoch is the best epoch.</p>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.dir","title":"<code>dir: str</code>  <code>property</code>","text":"<p>Directory of the run.</p>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.log_path","title":"<code>log_path: str</code>  <code>property</code>","text":"<p>Path of log file.</p>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.checkpoint_dir","title":"<code>checkpoint_dir: str</code>  <code>property</code>","text":"<p>Directory of checkpoints.</p>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.save","title":"<code>save(obj, file, main_process_only=True, *args, **kwargs)</code>","text":"<p>Save any file with supported extensions.</p> <p><code>Runner.save</code> internally calls <code>dl.save</code>, but with additional arguments to allow it save only on the main process. Moreover, any error raised by <code>Runner.save</code> will be caught and logged.</p> Source code in <code>danling/runner/runner_base.py</code> Python<pre><code>@catch\ndef save(  # pylint: disable=W1113\nself, obj: Any, file: PathStr, main_process_only: bool = True, *args, **kwargs\n) -&gt; File:\nr\"\"\"\n    Save any file with supported extensions.\n    `Runner.save` internally calls `dl.save`,\n    but with additional arguments to allow it save only on the main process.\n    Moreover, any error raised by `Runner.save` will be caught and logged.\n    \"\"\"\nif main_process_only and self.is_main_process or not main_process_only:\nreturn save(obj, file, *args, **kwargs)\nreturn file\n</code></pre>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.load","title":"<code>load(file, *args, **kwargs)</code>  <code>staticmethod</code>","text":"<p>Load any file with supported extensions.</p> <p><code>Runner.load</code> is identical to <code>dl.save</code>.</p> Source code in <code>danling/runner/runner_base.py</code> Python<pre><code>@staticmethod\ndef load(file: PathStr, *args, **kwargs) -&gt; Any:  # pylint: disable=C0103\nr\"\"\"\n    Load any file with supported extensions.\n    `Runner.load` is identical to `dl.save`.\n    \"\"\"\nreturn load(file, *args, **kwargs)\n</code></pre>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.dict","title":"<code>dict(cls=dict)</code>","text":"<p>Convert state to Mapping.</p> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>Callable</code> <p>Target `clc to convert to.</p> <code>dict</code> Source code in <code>danling/runner/runner_base.py</code> Python<pre><code>def dict(self, cls: Callable = dict) -&gt; Mapping:\nr\"\"\"\n    Convert state to Mapping.\n    Args:\n        cls: Target `clc to convert to.\n    \"\"\"\n# pylint: disable=C0103\nreturn self.state.dict(cls)\n</code></pre>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.json","title":"<code>json(file, main_process_only=True, *args, **kwargs)</code>","text":"<p>Dump Runner State to json file.</p> Source code in <code>danling/runner/runner_base.py</code> Python<pre><code>@catch\ndef json(self, file: File, main_process_only: bool = True, *args, **kwargs) -&gt; None:  # pylint: disable=W1113\nr\"\"\"\n    Dump Runner State to json file.\n    \"\"\"\nif main_process_only and self.is_main_process or not main_process_only:\nreturn self.state.json(file, *args, **kwargs)\n</code></pre>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.from_json","title":"<code>from_json(file, *args, **kwargs)</code>  <code>classmethod</code>","text":"<p>Construct Runner from json file.</p> <p>This function calls <code>self.from_jsons()</code> to construct object from json string. You may overwrite <code>from_jsons</code> in case something is not json serializable.</p> Source code in <code>danling/runner/runner_base.py</code> Python<pre><code>@classmethod\ndef from_json(cls, file: File, *args, **kwargs) -&gt; RunnerBase:\nr\"\"\"\n    Construct Runner from json file.\n    This function calls `self.from_jsons()` to construct object from json string.\n    You may overwrite `from_jsons` in case something is not json serializable.\n    \"\"\"\nwith FlatDict.open(file) as fp:  # pylint: disable=C0103\nreturn cls.from_jsons(fp.read(), *args, **kwargs)\n</code></pre>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.jsons","title":"<code>jsons(*args, **kwargs)</code>","text":"<p>Dump Runner State to json string.</p> Source code in <code>danling/runner/runner_base.py</code> Python<pre><code>def jsons(self, *args, **kwargs) -&gt; str:\nr\"\"\"\n    Dump Runner State to json string.\n    \"\"\"\nreturn self.state.jsons(*args, **kwargs)\n</code></pre>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.from_jsons","title":"<code>from_jsons(string, *args, **kwargs)</code>  <code>classmethod</code>","text":"<p>Construct Runner from json string.</p> Source code in <code>danling/runner/runner_base.py</code> Python<pre><code>@classmethod\ndef from_jsons(cls, string: str, *args, **kwargs) -&gt; RunnerBase:\nr\"\"\"\n    Construct Runner from json string.\n    \"\"\"\nreturn cls(Config.from_jsons(string, *args, **kwargs))\n</code></pre>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.yaml","title":"<code>yaml(file, main_process_only=True, *args, **kwargs)</code>","text":"<p>Dump Runner State to yaml file.</p> Source code in <code>danling/runner/runner_base.py</code> Python<pre><code>@catch\ndef yaml(self, file: File, main_process_only: bool = True, *args, **kwargs) -&gt; None:  # pylint: disable=W1113\nr\"\"\"\n    Dump Runner State to yaml file.\n    \"\"\"\nif main_process_only and self.is_main_process or not main_process_only:\nreturn self.state.yaml(file, *args, **kwargs)\n</code></pre>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.from_yaml","title":"<code>from_yaml(file, *args, **kwargs)</code>  <code>classmethod</code>","text":"<p>Construct Runner from yaml file.</p> <p>This function calls <code>self.from_yamls()</code> to construct object from yaml string. You may overwrite <code>from_yamls</code> in case something is not yaml serializable.</p> Source code in <code>danling/runner/runner_base.py</code> Python<pre><code>@classmethod\ndef from_yaml(cls, file: File, *args, **kwargs) -&gt; RunnerBase:\nr\"\"\"\n    Construct Runner from yaml file.\n    This function calls `self.from_yamls()` to construct object from yaml string.\n    You may overwrite `from_yamls` in case something is not yaml serializable.\n    \"\"\"\nwith FlatDict.open(file) as fp:  # pylint: disable=C0103\nreturn cls.from_yamls(fp.read(), *args, **kwargs)\n</code></pre>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.yamls","title":"<code>yamls(*args, **kwargs)</code>","text":"<p>Dump Runner State to yaml string.</p> Source code in <code>danling/runner/runner_base.py</code> Python<pre><code>def yamls(self, *args, **kwargs) -&gt; str:\nr\"\"\"\n    Dump Runner State to yaml string.\n    \"\"\"\nreturn self.state.yamls(*args, **kwargs)\n</code></pre>"},{"location":"runner/runner_base/#danling.runner.runner_base.RunnerBase.from_yamls","title":"<code>from_yamls(string, *args, **kwargs)</code>  <code>classmethod</code>","text":"<p>Construct Runner from yaml string.</p> Source code in <code>danling/runner/runner_base.py</code> Python<pre><code>@classmethod\ndef from_yamls(cls, string: str, *args, **kwargs) -&gt; RunnerBase:\nr\"\"\"\n    Construct Runner from yaml string.\n    \"\"\"\nreturn cls(Config.from_yamls(string, *args, **kwargs))\n</code></pre>"},{"location":"runner/runner_state/","title":"RunnerState","text":"<p>         Bases: <code>NestedDict</code></p> <p><code>RunnerState</code> is a <code>NestedDict</code> that contains all states of a <code>Runner</code>.</p> <p><code>RunnerState</code> is designed to store all critical information of a Run so that you can resume a run from a state and corresponding weights or even restart a run from a state.</p> <p><code>RunnerState</code> is also designed to be serialisable and hashable, so that you can save it to a file. <code>RunnerState</code> is saved in checkpoint together with weights by default.</p> <p>Since <code>RunnerState</code> is a <code>NestedDict</code>, you can access its attributes by <code>state[\"key\"]</code> or <code>state.key</code>.</p> <p>General:</p> Name Type Description <code>id</code> <code>str</code> <p><code>f\"{self.experiment_id:.4}{self.run_id:.4}{time_str}\"</code>.</p> <code>uuid</code> <code>UUID, property</code> <p><code>uuid5(self.run_id, self.id)</code>.</p> <code>name</code> <code>str</code> <p><code>f\"{self.experiment_name}-{self.run_name}\"</code>.</p> <code>run_id</code> <code>str</code> <p>hex of <code>self.run_uuid</code>.</p> <code>run_uuid</code> <code>UUID, property</code> <p><code>uuid5(self.experiment_id, config.jsons())</code>.</p> <code>run_name</code> <code>str</code> <p>Defaults to <code>\"DanLing\"</code>.</p> <code>experiment_id</code> <code>str</code> <p>git hash of the current HEAD. Defaults to <code>\"xxxxxxxxxxxxxxxx\"</code> if Runner not under a git repo or git/gitpython not installed.</p> <code>experiment_uuid</code> <code>UUID, property</code> <p>UUID of <code>self.experiment_id</code>. Defaults to <code>UUID('78787878-7878-7878-7878-787878787878')</code> if Runner not under a git repo or git/gitpython not installed.</p> <code>experiment_name</code> <code>str</code> <p>Defaults to <code>\"DanLing\"</code>.</p> <code>seed</code> <code>int</code> <p>Defaults to <code>randint(0, 2**32 - 1)</code>.</p> <code>deterministic</code> <code>bool</code> <p>Ensure deterministic operations. Defaults to <code>False</code>.</p> <p>Progress:</p> Name Type Description <code>iters</code> <code>int</code> <p>The number of data samples processed. equals to <code>steps</code> when <code>batch_size = 1</code>.</p> <code>steps</code> <code>int</code> <p>The number of <code>step</code> calls.</p> <code>epochs</code> <code>int</code> <p>The number of complete passes over the datasets.</p> <code>iter_end</code> <code>int</code> <p>End running iters. Note that <code>step_end</code> not initialised since this variable may not apply to some Runners.</p> <code>step_end</code> <code>int</code> <p>End running steps. Note that <code>step_end</code> not initialised since this variable may not apply to some Runners.</p> <code>epoch_end</code> <code>int</code> <p>End running epochs. Note that <code>epoch_end</code> not initialised since this variable may not apply to some Runners.</p> <p>In general you should only use one of <code>iter_end</code>, <code>step_end</code>, <code>epoch_end</code> to indicate the length of running.</p> <p>Results:</p> Name Type Description <code>results</code> <code>List[NestedDict]</code> <p>All results, should be in the form of <code>[{subset: {index: score}}]</code>.</p> <p><code>results</code> should be a list of <code>result</code>. <code>result</code> should be a dict with the same <code>split</code> as keys, like <code>dataloaders</code>. A typical <code>result</code> might look like this: Python<pre><code>{\n\"train\": {\n\"loss\": 0.1,\n\"accuracy\": 0.9,\n},\n\"val\": {\n\"loss\": 0.2,\n\"accuracy\": 0.8,\n},\n\"test\": {\n\"loss\": 0.3,\n\"accuracy\": 0.7,\n},\n}\n</code></pre></p> <p><code>scores</code> are usually a list of <code>float</code>, and are dynamically extracted from <code>results</code> by <code>index_set</code> and <code>index</code>. If <code>index_set = \"val\"</code>, <code>index = \"accuracy\"</code>, then <code>scores = 0.9</code>.</p> <p>IO:</p> Name Type Description <code>project_root</code> <code>str</code> <p>The root directory for all experiments. Defaults to <code>\"experiments\"</code>.</p> <p><code>project_root</code> is the root directory of all Experiments, and should be consistent across the Project.</p> <p><code>dir</code> is the directory of a certain Run.</p> <p>There is no attributes/properties for Group and Experiment.</p> <p><code>checkpoint_dir_name</code> is relative to <code>dir</code>, and is passed to generate <code>checkpoint_dir</code> (<code>checkpoint_dir = os.path.join(dir, checkpoint_dir_name)</code>). In practice, <code>checkpoint_dir_name</code> is rarely called.</p> <p>logging:</p> Name Type Description <code>log</code> <code>bool</code> <p>Whether to log the outputs. Defaults to <code>True</code>.</p> <code>tensorboard</code> <code>bool</code> <p>Whether to use <code>tensorboard</code>. Defaults to <code>False</code>.</p> <code>print_interval</code> <code>int</code> <p>Interval of printing logs. Defaults to -1.</p> <code>save_interval</code> <code>int</code> <p>Interval of saving intermediate checkpoints. Defaults to -1, never save intermediate checkpoints.</p> Notes <p><code>RunnerState</code> is a <code>NestedDict</code>, so you can access its attributes by <code>state[\"name\"]</code> or <code>state.name</code>.</p> See Also <p><code>RunnerBase</code>: The runeer state that stores critical information. <code>BaseRunner</code>: The base runner class.</p> Source code in <code>danling/runner/runner_state.py</code> Python<pre><code>class RunnerState(NestedDict):\nr\"\"\"\n    `RunnerState` is a `NestedDict` that contains all states of a `Runner`.\n    `RunnerState` is designed to store all critical information of a Run so that you can resume a run\n    from a state and corresponding weights or even restart a run from a state.\n    `RunnerState` is also designed to be serialisable and hashable, so that you can save it to a file.\n    `RunnerState` is saved in checkpoint together with weights by default.\n    Since `RunnerState` is a `NestedDict`, you can access its attributes by `state[\"key\"]` or `state.key`.\n    Attributes: General:\n        id (str): `f\"{self.experiment_id:.4}{self.run_id:.4}{time_str}\"`.\n        uuid (UUID, property): `uuid5(self.run_id, self.id)`.\n        name (str): `f\"{self.experiment_name}-{self.run_name}\"`.\n        run_id (str): hex of `self.run_uuid`.\n        run_uuid (UUID, property): `uuid5(self.experiment_id, config.jsons())`.\n        run_name (str): Defaults to `\"DanLing\"`.\n        experiment_id (str): git hash of the current HEAD.\n            Defaults to `\"xxxxxxxxxxxxxxxx\"` if Runner not under a git repo or git/gitpython not installed.\n        experiment_uuid (UUID, property): UUID of `self.experiment_id`.\n            Defaults to `UUID('78787878-7878-7878-7878-787878787878')`\n            if Runner not under a git repo or git/gitpython not installed.\n        experiment_name (str): Defaults to `\"DanLing\"`.\n        seed (int): Defaults to `randint(0, 2**32 - 1)`.\n        deterministic (bool): Ensure [deterministic](https://pytorch.org/docs/stable/notes/randomness.html) operations.\n            Defaults to `False`.\n    Attributes: Progress:\n        iters (int): The number of data samples processed.\n            equals to `steps` when `batch_size = 1`.\n        steps (int): The number of `step` calls.\n        epochs (int): The number of complete passes over the datasets.\n        iter_end (int): End running iters.\n            Note that `step_end` not initialised since this variable may not apply to some Runners.\n        step_end (int): End running steps.\n            Note that `step_end` not initialised since this variable may not apply to some Runners.\n        epoch_end (int): End running epochs.\n            Note that `epoch_end` not initialised since this variable may not apply to some Runners.\n    In general you should only use one of `iter_end`, `step_end`, `epoch_end` to indicate the length of running.\n    Attributes: Results:\n        results (List[NestedDict]): All results, should be in the form of ``[{subset: {index: score}}]``.\n    `results` should be a list of `result`.\n    `result` should be a dict with the same `split` as keys, like `dataloaders`.\n    A typical `result` might look like this:\n    ```python\n    {\n        \"train\": {\n            \"loss\": 0.1,\n            \"accuracy\": 0.9,\n        },\n        \"val\": {\n            \"loss\": 0.2,\n            \"accuracy\": 0.8,\n        },\n        \"test\": {\n            \"loss\": 0.3,\n            \"accuracy\": 0.7,\n        },\n    }\n    ```\n    `scores` are usually a list of `float`, and are dynamically extracted from `results` by `index_set` and `index`.\n    If `index_set = \"val\"`, `index = \"accuracy\"`, then `scores = 0.9`.\n    Attributes: IO:\n        project_root (str): The root directory for all experiments.\n            Defaults to `\"experiments\"`.\n    `project_root` is the root directory of all **Experiments**, and should be consistent across the **Project**.\n    `dir` is the directory of a certain **Run**.\n    There is no attributes/properties for **Group** and **Experiment**.\n    `checkpoint_dir_name` is relative to `dir`, and is passed to generate `checkpoint_dir`\n    (`checkpoint_dir = os.path.join(dir, checkpoint_dir_name)`).\n    In practice, `checkpoint_dir_name` is rarely called.\n    Attributes: logging:\n        log (bool): Whether to log the outputs.\n            Defaults to `True`.\n        tensorboard (bool): Whether to use `tensorboard`.\n            Defaults to `False`.\n        print_interval (int): Interval of printing logs.\n            Defaults to -1.\n        save_interval (int): Interval of saving intermediate checkpoints.\n            Defaults to -1, never save intermediate checkpoints.\n    Notes:\n        `RunnerState` is a `NestedDict`, so you can access its attributes by `state[\"name\"]` or `state.name`.\n    See Also:\n        [`RunnerBase`][danling.runner.runner_base.RunnerBase]: The runeer state that stores critical information.\n        [`BaseRunner`][danling.runner.BaseRunner]: The base runner class.\n    \"\"\"\n# pylint: disable=R0902, R0904\n# DO NOT set default value in class, as they won't be stored in `__dict__`.\nid: str\nname: str\nrun_id: str\nrun_name: str\nexperiment_id: str\nexperiment_name: str\nseed: int\ndeterministic: bool\niters: int\nsteps: int\nepochs: int\n# iter_begin: int  # Deprecated\n# step_begin: int  # Deprecated\n# epoch_begin: int  # Deprecated\niter_end: int\nstep_end: int\nepoch_end: int\nresults: List[NestedDict]\nindex_set: Optional[str]\nindex: str\nproject_root: str = \"experiments\"\ncheckpoint_dir_name: str = \"checkpoints\"\nlog: bool = True\ntensorboard: bool = False\nprint_interval: int = -1\nsave_interval: int = -1\ndef __init__(self, *args, **kwargs):\nself.run_name = defaults.DEFAULT_RUN_NAME\nself.experiment_id = defaults.DEFAULT_EXPERIMENT_ID\nself.experiment_name = defaults.DEFAULT_EXPERIMENT_NAME\nif Repo is not None:\ntry:\nself.experiment_id = Repo(search_parent_directories=True).head.object.hexsha\nexcept ImportError:\nwarn(\"GitPython is not installed, using default experiment id.\")\nexcept InvalidGitRepositoryError:\npath = os.path.dirname(os.path.abspath(sys.argv[0]))\nwarn(\"CWD is not under a git repo, fallback to top-level code environment.\")\ntry:\nself.experiment_id = Repo(path=path, search_parent_directories=True).head.object.hexsha\nexcept InvalidGitRepositoryError:\nwarn(\"Top-level code environment is not under a git repo, using default experiment id.\")\nelse:\nwarn(\"GitPython is not installed, using default experiment id.\")\nself.deterministic = False\nself.seed = randint(0, 2**32 - 1)\nself.iters = 0\nself.steps = 0\nself.epochs = 0\nself.results = []\nself.index_set = None\nself.index = \"loss\"\nsuper().__init__(*args, **kwargs)\nself.run_id = self.run_uuid.hex\ntime = datetime.now()\ntime_tuple = time.isocalendar()[1:] + (time.hour, time.minute, time.second, time.microsecond)\ntime_str = \"\".join(base62.encode(i) for i in time_tuple)\nself.id = f\"{time_str}{self.experiment_id:.5}{self.run_id:.4}\"  # pylint: disable=C0103\nself.name = f\"{self.experiment_name}-{self.run_name}\"\nself.setattr(\"ignored_keys_in_hash\", defaults.DEFAULT_IGNORED_KEYS_IN_HASH)\n@property\ndef experiment_uuid(self) -&gt; UUID:\nr\"\"\"\n        UUID of the experiment.\n        \"\"\"\nreturn UUID(bytes=bytes(self.experiment_id.ljust(16, \"x\")[:16], encoding=\"ascii\"))\n@property\ndef run_uuid(self) -&gt; UUID:\nr\"\"\"\n        UUID of the run.\n        \"\"\"\nreturn uuid5(self.experiment_uuid, str(hash(self)))\n@property\ndef uuid(self) -&gt; UUID:\nr\"\"\"\n        UUID of the state.\n        \"\"\"\nreturn uuid5(self.run_uuid, self.id)\ndef __hash__(self) -&gt; int:\nignored_keys_in_hash = self.getattr(\"ignored_keys_in_hash\", defaults.DEFAULT_IGNORED_KEYS_IN_HASH)\nstate = NestedDict({k: v for k, v in self.dict().items() if k not in ignored_keys_in_hash})\nreturn hash(state.yamls())\n</code></pre>"},{"location":"runner/runner_state/#danling.runner.runner_state.RunnerState.experiment_uuid","title":"<code>experiment_uuid: UUID</code>  <code>property</code>","text":"<p>UUID of the experiment.</p>"},{"location":"runner/runner_state/#danling.runner.runner_state.RunnerState.run_uuid","title":"<code>run_uuid: UUID</code>  <code>property</code>","text":"<p>UUID of the run.</p>"},{"location":"runner/runner_state/#danling.runner.runner_state.RunnerState.uuid","title":"<code>uuid: UUID</code>  <code>property</code>","text":"<p>UUID of the state.</p>"},{"location":"runner/torch_runner/","title":"TorchRunner","text":"<p>         Bases: <code>BaseRunner</code></p> <p>Set up everything for running a job.</p> <p>Attributes:</p> Name Type Description <code>accelerator</code> <code>Accelerator</code> <code>accelerate</code> <code>Mapping[str, Any]</code> <p>Defaults to <code>{}</code>. if is <code>None</code>, will not use <code>accelerate</code>.</p> Source code in <code>danling/runner/torch_runner.py</code> Python<pre><code>class TorchRunner(BaseRunner):\nr\"\"\"\n    Set up everything for running a job.\n    Attributes:\n        accelerator (Accelerator):\n        accelerate: Defaults to `{}`.\n            if is `None`, will not use `accelerate`.\n    \"\"\"\n# pylint: disable=R0902\naccelerator: Accelerator = None  # type: ignore\naccelerate: Mapping[str, Any]\ndef __init__(self, *args, **kwargs) -&gt; None:\nif \"accelerate\" not in self:\nself.accelerate = {}\nif len(args) == 1 and isinstance(args[0], dict):\nself.accelerate.update(args[0].pop(\"accelerate\", {}))  # type: ignore\nif \"accelerate\" in kwargs:\nself.accelerate.update(kwargs.pop(\"accelerate\"))  # type: ignore\nsuper().__init__(*args, **kwargs)\ndef init_distributed(self) -&gt; None:\nr\"\"\"\n        Set up distributed training.\n        Initialise process group and set up DDP variables.\n        \"\"\"\nif self.accelerate is None:\nself.accelerate = {}\nself.accelerator = Accelerator(**self.accelerate)\nif self.distributed:\nobject_list = [self.state.id]\ndist.broadcast_object_list(object_list)\nself.state.id = object_list[0]\n@on_main_process\ndef init_tensorboard(self, *args, **kwargs) -&gt; None:\nr\"\"\"\n        Set up Tensoraoard SummaryWriter.\n        \"\"\"\nfrom torch.utils.tensorboard.writer import SummaryWriter  # pylint: disable=C0415\nif \"log_dir\" not in kwargs:\nkwargs[\"log_dir\"] = self.dir\nself.writer = SummaryWriter(*args, **kwargs)\nself.writer.add_scalar = catch(OSError, verbose=False)(self.writer.add_scalar)  # type: ignore\ndef set_seed(self, seed: int = None, bias: Optional[int] = None) -&gt; None:  # type: ignore\nr\"\"\"\n        Set up random seed.\n        Args:\n            seed: Random seed to set.\n                Defaults to `self.state.seed` (`config.seed`).\n            bias: Make the seed different for each processes.\n                This avoids same data augmentation are applied on every processes.\n                Defaults to `self.rank`.\n                Set to `False` to disable this feature.\n        \"\"\"\nif seed is None:\nseed = self.state.seed\nif self.distributed:\nobject_list = [seed]\ndist.broadcast_object_list(object_list)\nseed = object_list[0]\nif bias is None:\nbias = self.rank\nif bias:\nseed += bias  # type: ignore\nself.state.seed = seed\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\nnp.random.seed(seed)\nrandom.seed(seed)\ndef set_deterministic(self) -&gt; None:\nr\"\"\"\n        Set up deterministic.\n        \"\"\"\ncudnn.benchmark = False\ncudnn.deterministic = True\nif torch.__version__ &gt;= \"1.8.0\":\ntorch.use_deterministic_algorithms(True)\ndef state_dict(self, cls: Callable = dict) -&gt; Mapping:\nr\"\"\"\n        Return dict of all attributes for checkpoint.\n        \"\"\"\nif self.model is None:\nraise ValueError(\"Model must be defined when calling state_dict\")\nmodel = self.accelerator.unwrap_model(self.model)\nreturn cls(\nrunner=self.state.dict(),\nmodel=model.state_dict(),\noptimizer=self.optimizer.state_dict() if self.optimizer else None,\nscheduler=self.scheduler.state_dict() if self.scheduler else None,\n)\ndef prepare(self, *args, device_placement: Optional[List[bool]] = None) -&gt; None:\nr\"\"\"\n        Prepare all objects passed in `args` for distributed training and mixed precision,\n        then return them in the same order.\n        \"\"\"\nreturn self.accelerator.prepare(*args, device_placement=device_placement)\ndef autocast(self):\nr\"\"\"\n        Context manager that enables autocasting for the forward pass (and maybe backward pass).\n        \"\"\"\nreturn self.accelerator.autocast()\ndef backward(self, loss) -&gt; None:\nr\"\"\"\n        Backward loss to compute gradients.\n        \"\"\"\nreturn self.accelerator.backward(loss)\ndef unwrap_model(self, model: Optional[nn.Module] = None) -&gt; nn.Module:\nr\"\"\"\n        Unwrap DDP model.\n        Args:\n            model (Optional[nn.Module]):\n                Defaults to `self.model`.\n        \"\"\"\nif model is not None:\nmodel = self.model  # type: ignore\nif self.accelerator is not None:\nreturn self.accelerator.unwrap_model(model)\nif self.distributed:\nreturn model.module  # type: ignore\nreturn model  # type: ignore\n@property\ndef batch_size(self) -&gt; int:\nr\"\"\"\n        Batch size.\n        Notes:\n            If `train` is in `dataloaders`, then `batch_size` is the batch size of `train`.\n            Otherwise, `batch_size` is the batch size of the first dataloader.\n        Returns:\n            (int):\n        \"\"\"\nif self.dataloaders:\nloader = self.dataloaders[\"train\"] if \"train\" in self.dataloaders else next(iter(self.dataloaders.values()))\nbatch_sampler = loader.sampler if isinstance(loader.sampler, BatchSampler) else loader.batch_sampler\nreturn batch_sampler.batch_size\nraise AttributeError(\"batch_size could not be inferred, since no dataloaedr found.\")\n@property\ndef accum_steps(self) -&gt; int:\nr\"\"\"\n        Gradient accumulation steps.\n        Returns:\n            (int):\n        \"\"\"\nreturn self.accelerator.gradient_accumulation_steps\n@property\ndef device(self) -&gt; torch.device:  # pylint: disable=E1101\nr\"\"\"\n        Device of runner.\n        \"\"\"\nreturn self.accelerator.device\n@property\ndef world_size(self) -&gt; int:\nr\"\"\"\n        Number of Processes.\n        \"\"\"\nreturn self.accelerator.num_processes\n@property\ndef rank(self) -&gt; int:\nr\"\"\"\n        Process index in all processes.\n        \"\"\"\nreturn self.accelerator.process_index\n@property\ndef local_rank(self) -&gt; int:\nr\"\"\"\n        Process index in local processes.\n        \"\"\"\nreturn self.accelerator.local_process_index\ndef gather(self, tensor) -&gt; torch.Tensor:\nr\"\"\"\n        Gather tensor.\n        \"\"\"\nreturn self.accelerator.gather(tensor)\ndef reduce(self, tensor, reduction: str = \"sum\") -&gt; torch.Tensor:\nr\"\"\"\n        Reduce tensor.\n        \"\"\"\nreturn self.accelerator.reduce(tensor, reduction=reduction)\ndef __getattr__(self, name: str) -&gt; Any:\ntry:\nreturn super().__getattr__(name)\nexcept AttributeError:\npass\nif self.accelerator is not None and hasattr(self.accelerator, name):\nreturn getattr(self.accelerator, name)\nraise super().__getattribute__(name)\n</code></pre>"},{"location":"runner/torch_runner/#danling.runner.torch_runner.TorchRunner.batch_size","title":"<code>batch_size: int</code>  <code>property</code>","text":"<p>Batch size.</p> Notes <p>If <code>train</code> is in <code>dataloaders</code>, then <code>batch_size</code> is the batch size of <code>train</code>. Otherwise, <code>batch_size</code> is the batch size of the first dataloader.</p> <p>Returns:</p> Type Description <code>int</code>"},{"location":"runner/torch_runner/#danling.runner.torch_runner.TorchRunner.accum_steps","title":"<code>accum_steps: int</code>  <code>property</code>","text":"<p>Gradient accumulation steps.</p> <p>Returns:</p> Type Description <code>int</code>"},{"location":"runner/torch_runner/#danling.runner.torch_runner.TorchRunner.device","title":"<code>device: torch.device</code>  <code>property</code>","text":"<p>Device of runner.</p>"},{"location":"runner/torch_runner/#danling.runner.torch_runner.TorchRunner.world_size","title":"<code>world_size: int</code>  <code>property</code>","text":"<p>Number of Processes.</p>"},{"location":"runner/torch_runner/#danling.runner.torch_runner.TorchRunner.rank","title":"<code>rank: int</code>  <code>property</code>","text":"<p>Process index in all processes.</p>"},{"location":"runner/torch_runner/#danling.runner.torch_runner.TorchRunner.local_rank","title":"<code>local_rank: int</code>  <code>property</code>","text":"<p>Process index in local processes.</p>"},{"location":"runner/torch_runner/#danling.runner.torch_runner.TorchRunner.init_distributed","title":"<code>init_distributed()</code>","text":"<p>Set up distributed training.</p> <p>Initialise process group and set up DDP variables.</p> Source code in <code>danling/runner/torch_runner.py</code> Python<pre><code>def init_distributed(self) -&gt; None:\nr\"\"\"\n    Set up distributed training.\n    Initialise process group and set up DDP variables.\n    \"\"\"\nif self.accelerate is None:\nself.accelerate = {}\nself.accelerator = Accelerator(**self.accelerate)\nif self.distributed:\nobject_list = [self.state.id]\ndist.broadcast_object_list(object_list)\nself.state.id = object_list[0]\n</code></pre>"},{"location":"runner/torch_runner/#danling.runner.torch_runner.TorchRunner.init_tensorboard","title":"<code>init_tensorboard(*args, **kwargs)</code>","text":"<p>Set up Tensoraoard SummaryWriter.</p> Source code in <code>danling/runner/torch_runner.py</code> Python<pre><code>@on_main_process\ndef init_tensorboard(self, *args, **kwargs) -&gt; None:\nr\"\"\"\n    Set up Tensoraoard SummaryWriter.\n    \"\"\"\nfrom torch.utils.tensorboard.writer import SummaryWriter  # pylint: disable=C0415\nif \"log_dir\" not in kwargs:\nkwargs[\"log_dir\"] = self.dir\nself.writer = SummaryWriter(*args, **kwargs)\nself.writer.add_scalar = catch(OSError, verbose=False)(self.writer.add_scalar)  # type: ignore\n</code></pre>"},{"location":"runner/torch_runner/#danling.runner.torch_runner.TorchRunner.set_seed","title":"<code>set_seed(seed=None, bias=None)</code>","text":"<p>Set up random seed.</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>int</code> <p>Random seed to set. Defaults to <code>self.state.seed</code> (<code>config.seed</code>).</p> <code>None</code> <code>bias</code> <code>Optional[int]</code> <p>Make the seed different for each processes.</p> <p>This avoids same data augmentation are applied on every processes.</p> <p>Defaults to <code>self.rank</code>.</p> <p>Set to <code>False</code> to disable this feature.</p> <code>None</code> Source code in <code>danling/runner/torch_runner.py</code> Python<pre><code>def set_seed(self, seed: int = None, bias: Optional[int] = None) -&gt; None:  # type: ignore\nr\"\"\"\n    Set up random seed.\n    Args:\n        seed: Random seed to set.\n            Defaults to `self.state.seed` (`config.seed`).\n        bias: Make the seed different for each processes.\n            This avoids same data augmentation are applied on every processes.\n            Defaults to `self.rank`.\n            Set to `False` to disable this feature.\n    \"\"\"\nif seed is None:\nseed = self.state.seed\nif self.distributed:\nobject_list = [seed]\ndist.broadcast_object_list(object_list)\nseed = object_list[0]\nif bias is None:\nbias = self.rank\nif bias:\nseed += bias  # type: ignore\nself.state.seed = seed\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\nnp.random.seed(seed)\nrandom.seed(seed)\n</code></pre>"},{"location":"runner/torch_runner/#danling.runner.torch_runner.TorchRunner.set_deterministic","title":"<code>set_deterministic()</code>","text":"<p>Set up deterministic.</p> Source code in <code>danling/runner/torch_runner.py</code> Python<pre><code>def set_deterministic(self) -&gt; None:\nr\"\"\"\n    Set up deterministic.\n    \"\"\"\ncudnn.benchmark = False\ncudnn.deterministic = True\nif torch.__version__ &gt;= \"1.8.0\":\ntorch.use_deterministic_algorithms(True)\n</code></pre>"},{"location":"runner/torch_runner/#danling.runner.torch_runner.TorchRunner.state_dict","title":"<code>state_dict(cls=dict)</code>","text":"<p>Return dict of all attributes for checkpoint.</p> Source code in <code>danling/runner/torch_runner.py</code> Python<pre><code>def state_dict(self, cls: Callable = dict) -&gt; Mapping:\nr\"\"\"\n    Return dict of all attributes for checkpoint.\n    \"\"\"\nif self.model is None:\nraise ValueError(\"Model must be defined when calling state_dict\")\nmodel = self.accelerator.unwrap_model(self.model)\nreturn cls(\nrunner=self.state.dict(),\nmodel=model.state_dict(),\noptimizer=self.optimizer.state_dict() if self.optimizer else None,\nscheduler=self.scheduler.state_dict() if self.scheduler else None,\n)\n</code></pre>"},{"location":"runner/torch_runner/#danling.runner.torch_runner.TorchRunner.prepare","title":"<code>prepare(*args, device_placement=None)</code>","text":"<p>Prepare all objects passed in <code>args</code> for distributed training and mixed precision, then return them in the same order.</p> Source code in <code>danling/runner/torch_runner.py</code> Python<pre><code>def prepare(self, *args, device_placement: Optional[List[bool]] = None) -&gt; None:\nr\"\"\"\n    Prepare all objects passed in `args` for distributed training and mixed precision,\n    then return them in the same order.\n    \"\"\"\nreturn self.accelerator.prepare(*args, device_placement=device_placement)\n</code></pre>"},{"location":"runner/torch_runner/#danling.runner.torch_runner.TorchRunner.autocast","title":"<code>autocast()</code>","text":"<p>Context manager that enables autocasting for the forward pass (and maybe backward pass).</p> Source code in <code>danling/runner/torch_runner.py</code> Python<pre><code>def autocast(self):\nr\"\"\"\n    Context manager that enables autocasting for the forward pass (and maybe backward pass).\n    \"\"\"\nreturn self.accelerator.autocast()\n</code></pre>"},{"location":"runner/torch_runner/#danling.runner.torch_runner.TorchRunner.backward","title":"<code>backward(loss)</code>","text":"<p>Backward loss to compute gradients.</p> Source code in <code>danling/runner/torch_runner.py</code> Python<pre><code>def backward(self, loss) -&gt; None:\nr\"\"\"\n    Backward loss to compute gradients.\n    \"\"\"\nreturn self.accelerator.backward(loss)\n</code></pre>"},{"location":"runner/torch_runner/#danling.runner.torch_runner.TorchRunner.unwrap_model","title":"<code>unwrap_model(model=None)</code>","text":"<p>Unwrap DDP model.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Optional[nn.Module]</code> <p>Defaults to <code>self.model</code>.</p> <code>None</code> Source code in <code>danling/runner/torch_runner.py</code> Python<pre><code>def unwrap_model(self, model: Optional[nn.Module] = None) -&gt; nn.Module:\nr\"\"\"\n    Unwrap DDP model.\n    Args:\n        model (Optional[nn.Module]):\n            Defaults to `self.model`.\n    \"\"\"\nif model is not None:\nmodel = self.model  # type: ignore\nif self.accelerator is not None:\nreturn self.accelerator.unwrap_model(model)\nif self.distributed:\nreturn model.module  # type: ignore\nreturn model  # type: ignore\n</code></pre>"},{"location":"runner/torch_runner/#danling.runner.torch_runner.TorchRunner.gather","title":"<code>gather(tensor)</code>","text":"<p>Gather tensor.</p> Source code in <code>danling/runner/torch_runner.py</code> Python<pre><code>def gather(self, tensor) -&gt; torch.Tensor:\nr\"\"\"\n    Gather tensor.\n    \"\"\"\nreturn self.accelerator.gather(tensor)\n</code></pre>"},{"location":"runner/torch_runner/#danling.runner.torch_runner.TorchRunner.reduce","title":"<code>reduce(tensor, reduction='sum')</code>","text":"<p>Reduce tensor.</p> Source code in <code>danling/runner/torch_runner.py</code> Python<pre><code>def reduce(self, tensor, reduction: str = \"sum\") -&gt; torch.Tensor:\nr\"\"\"\n    Reduce tensor.\n    \"\"\"\nreturn self.accelerator.reduce(tensor, reduction=reduction)\n</code></pre>"},{"location":"runner/utils/","title":"Utilities","text":""},{"location":"runner/utils/#danling.runner.utils.on_main_process","title":"<code>on_main_process(func)</code>","text":"<p>Decorator to run func only on main process.</p> Source code in <code>danling/runner/utils.py</code> Python<pre><code>def on_main_process(func):\n\"\"\"\n    Decorator to run func only on main process.\n    \"\"\"\n@wraps(func)\ndef wrapper(self, *args, **kwargs) -&gt; Optional[Any]:\nif self.is_main_process or not self.distributed:\nreturn func(self, *args, **kwargs)\nreturn None\nreturn wrapper\n</code></pre>"},{"location":"runner/utils/#danling.runner.utils.on_local_main_process","title":"<code>on_local_main_process(func)</code>","text":"<p>Decorator to run func only on local main process.</p> Source code in <code>danling/runner/utils.py</code> Python<pre><code>def on_local_main_process(func):\n\"\"\"\n    Decorator to run func only on local main process.\n    \"\"\"\n@wraps(func)\ndef wrapper(self, *args, **kwargs) -&gt; Optional[Any]:\nif self.is_local_main_process or not self.distributed:\nreturn func(self, *args, **kwargs)\nreturn None\nreturn wrapper\n</code></pre>"},{"location":"tensors/nested_tensor/","title":"NestedTensor","text":"<p>Wrap a sequence of tensors into a single tensor with a mask.</p> <p>In sequence to sequence tasks, elements of a batch are usually not of the same length. This made it tricky to use a single tensor to represent a batch of sequences.</p> <p><code>NestedTensor</code> allows to store a sequence of tensors of different lengths in a single object. It also provides a mask that can be used to retrieve the original sequence of tensors.</p> <p>Attributes:</p> Name Type Description <code>storage</code> <code>Sequence[Tensor]</code> <p>The sequence of tensors.</p> <code>batch_first</code> <code>bool</code> <p>Whether the first dimension of the tensors is the batch dimension.</p> <p>If <code>True</code>, the first dimension is the batch dimension, i.e., <code>B, N, *</code>.</p> <p>If <code>False</code>, the first dimension is the sequence dimension, i.e., <code>N, B, *</code></p> <code>padding_value</code> <code>SupportsFloat</code> <p>The value used to pad the tensors.</p> <p>Parameters:</p> Name Type Description Default <code>tensors</code> <code>Iterable[Tensor]</code> required <code>batch_first</code> <code>bool</code> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>tensors</code> is not a sequence.</p> <code>ValueError</code> <p>If <code>tensors</code> is empty.</p> Notes <p>We have rewritten the <code>__getattr__</code> function to support as much native tensor operations as possible. However, not all operations are tested.</p> <p>Please file an issue if you find any bugs.</p> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n&gt;&gt;&gt; nested_tensor.shape\ntorch.Size([2, 3])\n&gt;&gt;&gt; nested_tensor.device\ndevice(type='cpu')\n&gt;&gt;&gt; nested_tensor.dtype\ntorch.int64\n&gt;&gt;&gt; nested_tensor.tensor\ntensor([[1, 2, 3],\n[4, 5, 0]])\n&gt;&gt;&gt; nested_tensor.mask\ntensor([[ True,  True,  True],\n[ True,  True, False]])\n&gt;&gt;&gt; nested_tensor.to(torch.float).tensor\ntensor([[1., 2., 3.],\n[4., 5., 0.]])\n&gt;&gt;&gt; nested_tensor.half().tensor\ntensor([[1., 2., 3.],\n[4., 5., 0.]], dtype=torch.float16)\n</code></pre> Source code in <code>danling/tensors/nested_tensor.py</code> Python<pre><code>class NestedTensor:\nr\"\"\"\n    Wrap a sequence of tensors into a single tensor with a mask.\n    In sequence to sequence tasks, elements of a batch are usually not of the same length.\n    This made it tricky to use a single tensor to represent a batch of sequences.\n    `NestedTensor` allows to store a sequence of tensors of different lengths in a single object.\n    It also provides a mask that can be used to retrieve the original sequence of tensors.\n    Attributes:\n        storage: The sequence of tensors.\n        batch_first:  Whether the first dimension of the tensors is the batch dimension.\n            If `True`, the first dimension is the batch dimension, i.e., `B, N, *`.\n            If `False`, the first dimension is the sequence dimension, i.e., `N, B, *`\n        padding_value: The value used to pad the tensors.\n    Args:\n        tensors:\n        batch_first:\n    Raises:\n        ValueError: If `tensors` is not a sequence.\n        ValueError: If `tensors` is empty.\n    Notes:\n        We have rewritten the `__getattr__` function to support as much native tensor operations as possible.\n        However, not all operations are tested.\n        Please file an issue if you find any bugs.\n    Examples:\n    ```python\n    &gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n    &gt;&gt;&gt; nested_tensor.shape\n    torch.Size([2, 3])\n    &gt;&gt;&gt; nested_tensor.device\n    device(type='cpu')\n    &gt;&gt;&gt; nested_tensor.dtype\n    torch.int64\n    &gt;&gt;&gt; nested_tensor.tensor\n    tensor([[1, 2, 3],\n            [4, 5, 0]])\n    &gt;&gt;&gt; nested_tensor.mask\n    tensor([[ True,  True,  True],\n            [ True,  True, False]])\n    &gt;&gt;&gt; nested_tensor.to(torch.float).tensor\n    tensor([[1., 2., 3.],\n            [4., 5., 0.]])\n    &gt;&gt;&gt; nested_tensor.half().tensor\n    tensor([[1., 2., 3.],\n            [4., 5., 0.]], dtype=torch.float16)\n    ```\n    \"\"\"\n# pylint: disable=C0103\nstorage: Sequence[Tensor] = []\nbatch_first: bool = True\npadding_value: SupportsFloat = 0.0\nmask_value: bool = False\ndef __init__(\nself,\ntensors: Iterable[Tensor],\nbatch_first: bool = True,\npadding_value: SupportsFloat = 0.0,\nmask_value: bool = False,\n) -&gt; None:\nif not isinstance(tensors, Iterable):\nraise ValueError(f\"NestedTensor must be initialised with an Iterable, bug got {type(tensors)}.\")\ntensors = list(tensors)\nif len(tensors) == 0:\nraise ValueError(\"NestedTensor must be initialised with a non-empty Iterable.\")\nif not isinstance(tensors[0], Tensor):\ntensors = [torch.tensor(tensor) for tensor in tensors]  # pylint: disable=E1101\nself.storage = tensors\nself.batch_first = batch_first\nself.padding_value = padding_value\nself.mask_value = mask_value\n@property\ndef tensor(self) -&gt; Tensor:\nr\"\"\"\n        Return a single tensor by padding all the tensors.\n        Returns:\n            (torch.Tensor):\n        Examples:\n        ```python\n        &gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n        &gt;&gt;&gt; nested_tensor.tensor\n        tensor([[1, 2, 3],\n                [4, 5, 0]])\n        ```\n        \"\"\"\nreturn self._tensor(tuple(self.storage), self.batch_first, float(self.padding_value))\n@property\ndef mask(self) -&gt; Tensor:\nr\"\"\"\n        Padding mask of `tensor`.\n        Returns:\n            (torch.Tensor):\n        Examples:\n        ```python\n        &gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n        &gt;&gt;&gt; nested_tensor.mask\n        tensor([[ True,  True,  True],\n                [ True,  True, False]])\n        ```\n        \"\"\"\nreturn self._mask(tuple(self.storage), self.mask_value)\n@property\ndef device(self) -&gt; torch.device:  # pylint: disable=E1101\nr\"\"\"\n        Device of the NestedTensor.\n        Returns:\n            (torch.Tensor):\n        Examples:\n        ```python\n        &gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n        &gt;&gt;&gt; nested_tensor.device\n        device(type='cpu')\n        ```\n        \"\"\"\nreturn self._device(tuple(self.storage))\n@property\ndef shape(self) -&gt; torch.Size:  # pylint: disable=E1101\nr\"\"\"\n        Alias for `size`.\n        Returns:\n            (torch.Size):\n        Examples:\n        ```python\n        &gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n        &gt;&gt;&gt; nested_tensor.shape\n        torch.Size([2, 3])\n        &gt;&gt;&gt; nested_tensor.storage.append(torch.tensor([6, 7, 8, 9]))\n        &gt;&gt;&gt; nested_tensor.shape\n        torch.Size([3, 4])\n        ```\n        \"\"\"\nreturn self.size()\ndef size(self) -&gt; torch.Size:  # pylint: disable=E1101\nr\"\"\"\n        Shape of the NestedTensor.\n        Returns:\n            (torch.Size):\n        Examples:\n        ```python\n        &gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n        &gt;&gt;&gt; nested_tensor.size()\n        torch.Size([2, 3])\n        &gt;&gt;&gt; nested_tensor.storage[1] = torch.tensor([4, 5, 6, 7])\n        &gt;&gt;&gt; nested_tensor.size()\n        torch.Size([2, 4])\n        ```\n        \"\"\"\nreturn self._size(tuple(self.storage))\ndef where(self, condition, other) -&gt; NestedTensor:\nr\"\"\"\n        Return a NestedTensor of elements selected from either self or other, depending on condition.\n        Returns:\n            (NestedTensor):\n        Examples:\n        ```python\n        &gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n        &gt;&gt;&gt; nested_tensor.size()\n        torch.Size([2, 3])\n        &gt;&gt;&gt; nested_tensor.storage[1] = torch.tensor([4, 5, 6, 7])\n        &gt;&gt;&gt; nested_tensor.size()\n        torch.Size([2, 4])\n        ```\n        \"\"\"\nif isinstance(condition, NestedTensor) and isinstance(other, NestedTensor):\nreturn NestedTensor(\n[x.where(c, y) for x, c, y in zip(self.storage, condition.storage, other.storage)], **self._state()\n)\nif isinstance(condition, NestedTensor):\nreturn NestedTensor([x.where(c, other) for x, c in zip(self.storage, condition.storage)], **self._state())\nif isinstance(other, NestedTensor):\nreturn NestedTensor([x.where(condition, y) for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor(x.where(condition, other) for x in self.storage)\ndef __abs__(self):\nreturn NestedTensor([abs(value) for value in self.storage], **self._state())\ndef __add__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([x + y for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([value + other for value in self.storage], **self._state())\ndef __radd__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([y + x for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([other + value for value in self.storage], **self._state())\ndef __iadd__(self, other):\nif isinstance(other, NestedTensor):\nfor x, y in zip(self.storage, other.storage):\nx += y\nelse:\nfor value in self.storage:\nvalue += other\nreturn self\ndef __and__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([x &amp; y for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([value &amp; other for value in self.storage], **self._state())\ndef __rand__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([y &amp; x for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([other &amp; value for value in self.storage], **self._state())\ndef __iand__(self, other):\nif isinstance(other, NestedTensor):\nfor x, y in zip(self.storage, other.storage):\nx &amp;= y\nelse:\nfor value in self.storage:\nvalue &amp;= other\nreturn self\ndef __floordiv__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([x // y for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([value // other for value in self.storage], **self._state())\ndef __rfloordiv__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([y // x for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([other // value for value in self.storage], **self._state())\ndef __ifloordiv__(self, other):\nif isinstance(other, NestedTensor):\nfor x, y in zip(self.storage, other.storage):\nx //= y\nelse:\nfor value in self.storage:\nvalue //= other\nreturn self\ndef __mod__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([x % y for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([value % other for value in self.storage], **self._state())\ndef __rmod__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([y % x for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([other % value for value in self.storage], **self._state())\ndef __imod__(self, other):\nif isinstance(other, NestedTensor):\nfor x, y in zip(self.storage, other.storage):\nx %= y\nelse:\nfor value in self.storage:\nvalue %= other\nreturn self\ndef __mul__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([x * y for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([value * other for value in self.storage], **self._state())\ndef __rmul__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([y * x for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([other * value for value in self.storage], **self._state())\ndef __imul__(self, other):\nif isinstance(other, NestedTensor):\nfor x, y in zip(self.storage, other.storage):\nx *= y\nelse:\nfor value in self.storage:\nvalue *= other\nreturn self\ndef __matmul__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([x @ y for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([value @ other for value in self.storage], **self._state())\ndef __rmatmul__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([y @ x for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([other @ value for value in self.storage], **self._state())\ndef __imatmul__(self, other):\nif isinstance(other, NestedTensor):\nfor x, y in zip(self.storage, other.storage):\nx @= y\nelse:\nfor value in self.storage:\nvalue @= other\nreturn self\ndef __pow__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([x**y for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([value**other for value in self.storage], **self._state())\ndef __rpow__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([y**x for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([other**value for value in self.storage], **self._state())\ndef __ipow__(self, other):\nif isinstance(other, NestedTensor):\nfor x, y in zip(self.storage, other.storage):\nx *= y\nelse:\nfor value in self.storage:\nvalue *= other\nreturn self\ndef __truediv__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([x / y for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([value / other for value in self.storage], **self._state())\ndef __rtruediv__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([y / x for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([other / value for value in self.storage], **self._state())\ndef __itruediv__(self, other):\nif isinstance(other, NestedTensor):\nfor x, y in zip(self.storage, other.storage):\nx /= y\nelse:\nfor value in self.storage:\nvalue /= other\nreturn self\ndef __sub__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([x - y for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([value - other for value in self.storage], **self._state())\ndef __rsub__(self, other):\nif isinstance(other, NestedTensor):\nreturn NestedTensor([y - x for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor([other - value for value in self.storage], **self._state())\ndef __isub__(self, other):\nif isinstance(other, NestedTensor):\nfor x, y in zip(self.storage, other.storage):\nx -= y\nelse:\nfor value in self.storage:\nvalue -= other\nreturn self\ndef __getitem__(self, index) -&gt; Tuple[Tensor, Tensor]:\nret = self.storage[index]\nif isinstance(ret, Tensor):\nreturn ret, torch.ones_like(ret)  # pylint: disable=E1101\nreturn self.tensor, self.mask\ndef __getattr__(self, name) -&gt; Any:\nif not self.storage:\nraise ValueError(f\"Unable to get {name} from an empty {self.__class__.__name__}\")\nret = [getattr(i, name) for i in self.storage]\nelem = ret[0]\nif isinstance(elem, Tensor):\nreturn NestedTensor(ret, **self._state())\nif callable(elem):\nreturn NestedTensorFuncWrapper(ret, state=self._state())\nif elem.__hash__ is not None and len(set(ret)) == 1:\nreturn elem\nreturn ret\n@classmethod\ndef __torch_function__(cls, func, types, args=(), kwargs=None):\nif kwargs is None:\nkwargs = {}\nif func not in NestedTensorFunc or not all(issubclass(t, (torch.Tensor, NestedTensor)) for t in types):\nargs = [a.tensor() if hasattr(a, \"tensor\") else a for a in args]\nreturn func(*args, **kwargs)\nreturn NestedTensorFunc[func](*args, **kwargs)\ndef __len__(self) -&gt; int:\nreturn len(self.storage)\ndef __eq__(self, other) -&gt; Union[bool, Tensor, NestedTensor]:  # type: ignore[override]\nif isinstance(other, NestedTensor):\nreturn self.storage == other.storage\nif isinstance(other, Tensor):\nreturn self.tensor == other\nif isinstance(other, SupportsFloat):\nreturn NestedTensor([x == other for x in self.storage], **self._state())\nraise NotImplementedError(f\"Cannot compare {self.__class__.__name__} with {other.__class__.__name__}\")\ndef _state(self) -&gt; Mapping:\nreturn {k: v for k, v in self.__dict__.items() if k != \"storage\"}\ndef __state__(self) -&gt; Mapping:\nreturn self.__dict__\ndef __setstate__(self, state: Mapping) -&gt; None:\nself.__dict__.update(state)\ndef __repr__(self):\nreturn self.__class__.__name__ + repr(self.tensor)[len(self.tensor.__class__.__name__) :]  # noqa: E203\n@staticmethod\n@lru_cache(maxsize=None)\ndef _tensor(storage, batch_first, padding_value: float = 0) -&gt; Tensor:\nif storage[0].dim() == 0:\nreturn torch.stack(storage, dim=0)  # pylint: disable=E1101\nreturn pad_sequence(storage, batch_first=batch_first, padding_value=padding_value)\n@staticmethod\n@lru_cache(maxsize=None)\ndef _mask(storage, mask_value: bool = False) -&gt; Tensor:\n# pylint: disable=E1101\nif storage[0].dim() == 0:\nreturn torch.ones(len(storage), dtype=torch.bool)\nlens = torch.tensor([len(t) for t in storage], device=storage[0].device)\narange = torch.arange(max(lens), device=storage[0].device)[None, :]\nreturn arange &gt;= lens[:, None] if mask_value else arange &lt; lens[:, None]\n@staticmethod\n@lru_cache(maxsize=None)\ndef _device(storage) -&gt; torch.device:  # pylint: disable=E1101\nreturn storage[0].device\n@staticmethod\n@lru_cache(maxsize=None)\ndef _size(storage) -&gt; torch.Size:\n# pylint: disable=E1101\nif storage[0].dim() == 0:\nreturn torch.Size([len(storage)])\nreturn torch.Size([len(storage), max(t.shape[0] for t in storage), *storage[0].shape[1:]])\n</code></pre>"},{"location":"tensors/nested_tensor/#danling.tensors.nested_tensor.NestedTensor.tensor","title":"<code>tensor: Tensor</code>  <code>property</code>","text":"<p>Return a single tensor by padding all the tensors.</p> <p>Returns:</p> Type Description <code>torch.Tensor</code> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n&gt;&gt;&gt; nested_tensor.tensor\ntensor([[1, 2, 3],\n[4, 5, 0]])\n</code></pre>"},{"location":"tensors/nested_tensor/#danling.tensors.nested_tensor.NestedTensor.mask","title":"<code>mask: Tensor</code>  <code>property</code>","text":"<p>Padding mask of <code>tensor</code>.</p> <p>Returns:</p> Type Description <code>torch.Tensor</code> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n&gt;&gt;&gt; nested_tensor.mask\ntensor([[ True,  True,  True],\n[ True,  True, False]])\n</code></pre>"},{"location":"tensors/nested_tensor/#danling.tensors.nested_tensor.NestedTensor.device","title":"<code>device: torch.device</code>  <code>property</code>","text":"<p>Device of the NestedTensor.</p> <p>Returns:</p> Type Description <code>torch.Tensor</code> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n&gt;&gt;&gt; nested_tensor.device\ndevice(type='cpu')\n</code></pre>"},{"location":"tensors/nested_tensor/#danling.tensors.nested_tensor.NestedTensor.shape","title":"<code>shape: torch.Size</code>  <code>property</code>","text":"<p>Alias for <code>size</code>.</p> <p>Returns:</p> Type Description <code>torch.Size</code> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n&gt;&gt;&gt; nested_tensor.shape\ntorch.Size([2, 3])\n&gt;&gt;&gt; nested_tensor.storage.append(torch.tensor([6, 7, 8, 9]))\n&gt;&gt;&gt; nested_tensor.shape\ntorch.Size([3, 4])\n</code></pre>"},{"location":"tensors/nested_tensor/#danling.tensors.nested_tensor.NestedTensor.size","title":"<code>size()</code>","text":"<p>Shape of the NestedTensor.</p> <p>Returns:</p> Type Description <code>torch.Size</code> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n&gt;&gt;&gt; nested_tensor.size()\ntorch.Size([2, 3])\n&gt;&gt;&gt; nested_tensor.storage[1] = torch.tensor([4, 5, 6, 7])\n&gt;&gt;&gt; nested_tensor.size()\ntorch.Size([2, 4])\n</code></pre> Source code in <code>danling/tensors/nested_tensor.py</code> Python<pre><code>def size(self) -&gt; torch.Size:  # pylint: disable=E1101\nr\"\"\"\n    Shape of the NestedTensor.\n    Returns:\n        (torch.Size):\n    Examples:\n    ```python\n    &gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n    &gt;&gt;&gt; nested_tensor.size()\n    torch.Size([2, 3])\n    &gt;&gt;&gt; nested_tensor.storage[1] = torch.tensor([4, 5, 6, 7])\n    &gt;&gt;&gt; nested_tensor.size()\n    torch.Size([2, 4])\n    ```\n    \"\"\"\nreturn self._size(tuple(self.storage))\n</code></pre>"},{"location":"tensors/nested_tensor/#danling.tensors.nested_tensor.NestedTensor.where","title":"<code>where(condition, other)</code>","text":"<p>Return a NestedTensor of elements selected from either self or other, depending on condition.</p> <p>Returns:</p> Type Description <code>NestedTensor</code> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n&gt;&gt;&gt; nested_tensor.size()\ntorch.Size([2, 3])\n&gt;&gt;&gt; nested_tensor.storage[1] = torch.tensor([4, 5, 6, 7])\n&gt;&gt;&gt; nested_tensor.size()\ntorch.Size([2, 4])\n</code></pre> Source code in <code>danling/tensors/nested_tensor.py</code> Python<pre><code>def where(self, condition, other) -&gt; NestedTensor:\nr\"\"\"\n    Return a NestedTensor of elements selected from either self or other, depending on condition.\n    Returns:\n        (NestedTensor):\n    Examples:\n    ```python\n    &gt;&gt;&gt; nested_tensor = NestedTensor([torch.tensor([1, 2, 3]), torch.tensor([4, 5])])\n    &gt;&gt;&gt; nested_tensor.size()\n    torch.Size([2, 3])\n    &gt;&gt;&gt; nested_tensor.storage[1] = torch.tensor([4, 5, 6, 7])\n    &gt;&gt;&gt; nested_tensor.size()\n    torch.Size([2, 4])\n    ```\n    \"\"\"\nif isinstance(condition, NestedTensor) and isinstance(other, NestedTensor):\nreturn NestedTensor(\n[x.where(c, y) for x, c, y in zip(self.storage, condition.storage, other.storage)], **self._state()\n)\nif isinstance(condition, NestedTensor):\nreturn NestedTensor([x.where(c, other) for x, c in zip(self.storage, condition.storage)], **self._state())\nif isinstance(other, NestedTensor):\nreturn NestedTensor([x.where(condition, y) for x, y in zip(self.storage, other.storage)], **self._state())\nreturn NestedTensor(x.where(condition, other) for x in self.storage)\n</code></pre>"},{"location":"tensors/pn_tensor/","title":"PNTensor","text":"<p>         Bases: <code>Tensor</code></p> <p>Wrapper for tensors to be converted to <code>NestedTensor</code>.</p> <p><code>PNTensor</code> is a subclass of <code>torch.Tensor</code>. It implements two additional methods as <code>NestedTensor</code>: <code>tensor</code> and <code>mask</code>.</p> <p>Although it is possible to construct <code>NestedTensor</code> in dataset, the best practice is to do so in <code>collate_fn</code>. However, it is hard to tell if a batch of <code>Tensor</code> should be stacked or converted to <code>NestedTensor</code>.</p> <p><code>PNTensor</code> is introduced overcome this limitation.</p> <p>Convert tensors that will be converted to <code>NestedTensor</code> to a <code>PNTensor</code>, and all you need to do is to convert <code>PNTensor</code> to <code>NestedTensor</code> in <code>collate_fn</code>.</p> Source code in <code>danling/tensors/nested_tensor.py</code> Python<pre><code>class PNTensor(Tensor):\nr\"\"\"\n    Wrapper for tensors to be converted to `NestedTensor`.\n    `PNTensor` is a subclass of `torch.Tensor`.\n    It implements two additional methods as `NestedTensor`: `tensor` and `mask`.\n    Although it is possible to construct `NestedTensor` in dataset,\n    the best practice is to do so in `collate_fn`.\n    However, it is hard to tell if a batch of `Tensor` should be stacked or converted to `NestedTensor`.\n    `PNTensor` is introduced overcome this limitation.\n    Convert tensors that will be converted to `NestedTensor` to a `PNTensor`,\n    and all you need to do is to convert `PNTensor` to `NestedTensor` in `collate_fn`.\n    \"\"\"\n@property\ndef tensor(self) -&gt; Tensor:\nr\"\"\"\n        Identical to `self`.\n        Returns:\n            (torch.Tensor):\n        Examples:\n        ```python\n        &gt;&gt;&gt; tensor = torch.tensor([1, 2, 3])\n        &gt;&gt;&gt; pn_tensor = PNTensor(tensor)\n        &gt;&gt;&gt; (tensor == pn_tensor).all()\n        PNTensor(True)\n        &gt;&gt;&gt; (tensor == pn_tensor.tensor).all()\n        PNTensor(True)\n        ```\n        \"\"\"\nreturn self\n@property\ndef mask(self) -&gt; Tensor:\nr\"\"\"\n        Identical to `torch.ones_like(self)`.\n        Returns:\n            (torch.Tensor):\n        Examples:\n        ```python\n        &gt;&gt;&gt; tensor = torch.tensor([1, 2, 3])\n        &gt;&gt;&gt; pn_tensor = PNTensor(tensor)\n        &gt;&gt;&gt; (pn_tensor.mask == torch.ones_like(pn_tensor)).all()\n        PNTensor(True)\n        ```\n        \"\"\"\nreturn torch.ones_like(self)  # pylint: disable=E1101\n</code></pre>"},{"location":"tensors/pn_tensor/#danling.tensors.nested_tensor.PNTensor.tensor","title":"<code>tensor: Tensor</code>  <code>property</code>","text":"<p>Identical to <code>self</code>.</p> <p>Returns:</p> Type Description <code>torch.Tensor</code> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; tensor = torch.tensor([1, 2, 3])\n&gt;&gt;&gt; pn_tensor = PNTensor(tensor)\n&gt;&gt;&gt; (tensor == pn_tensor).all()\nPNTensor(True)\n&gt;&gt;&gt; (tensor == pn_tensor.tensor).all()\nPNTensor(True)\n</code></pre>"},{"location":"tensors/pn_tensor/#danling.tensors.nested_tensor.PNTensor.mask","title":"<code>mask: Tensor</code>  <code>property</code>","text":"<p>Identical to <code>torch.ones_like(self)</code>.</p> <p>Returns:</p> Type Description <code>torch.Tensor</code> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; tensor = torch.tensor([1, 2, 3])\n&gt;&gt;&gt; pn_tensor = PNTensor(tensor)\n&gt;&gt;&gt; (pn_tensor.mask == torch.ones_like(pn_tensor)).all()\nPNTensor(True)\n</code></pre>"},{"location":"tensors/torch_func_registry/","title":"TorchFuncRegistry","text":"<p>         Bases: <code>Registry</code></p> <p><code>TorchFuncRegistry</code> for extending PyTorch Tensor.</p> Source code in <code>danling/tensors/torch_func_registry.py</code> Python<pre><code>class TorchFuncRegistry(Registry):\n\"\"\"\n    `TorchFuncRegistry` for extending PyTorch Tensor.\n    \"\"\"\ndef implement(self, torch_function: Callable) -&gt; Callable:\nr\"\"\"\n        Implement an implementation for a torch function.\n        Args:\n            function: The torch function to implement.\n        Returns:\n            function: The registered function.\n        Raises:\n            ValueError: If the function with the same name already registered and `TorchFuncRegistry.override=False`.\n        Examples:\n        ```python\n        &gt;&gt;&gt; import torch\n        &gt;&gt;&gt; registry = TorchFuncRegistry(\"test\")\n        &gt;&gt;&gt; @registry.implement(torch.mean)  # pylint: disable=E1101\n        ... def mean(input):\n        ...     raise input.mean()\n        &gt;&gt;&gt; registry  # doctest: +ELLIPSIS\n        TorchFuncRegistry(\n          (&lt;built-in method mean of type object at ...&gt;): &lt;function mean at ...&gt;\n        )\n        ```\n        \"\"\"\nif torch_function in self and not self.override:\nraise ValueError(f\"Torch function {torch_function.__name__} already registered.\")\n@wraps(self.register)\ndef register(function):\nself.set(torch_function, function)\nreturn function\nreturn register\n</code></pre>"},{"location":"tensors/torch_func_registry/#danling.tensors.torch_func_registry.TorchFuncRegistry.implement","title":"<code>implement(torch_function)</code>","text":"<p>Implement an implementation for a torch function.</p> <p>Parameters:</p> Name Type Description Default <code>function</code> <p>The torch function to implement.</p> required <p>Returns:</p> Name Type Description <code>function</code> <code>Callable</code> <p>The registered function.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the function with the same name already registered and <code>TorchFuncRegistry.override=False</code>.</p> <p>Examples:</p> Python<pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; registry = TorchFuncRegistry(\"test\")\n&gt;&gt;&gt; @registry.implement(torch.mean)  # pylint: disable=E1101\n... def mean(input):\n...     raise input.mean()\n&gt;&gt;&gt; registry  # doctest: +ELLIPSIS\nTorchFuncRegistry(\n(&lt;built-in method mean of type object at ...&gt;): &lt;function mean at ...&gt;\n)\n</code></pre> Source code in <code>danling/tensors/torch_func_registry.py</code> Python<pre><code>def implement(self, torch_function: Callable) -&gt; Callable:\nr\"\"\"\n    Implement an implementation for a torch function.\n    Args:\n        function: The torch function to implement.\n    Returns:\n        function: The registered function.\n    Raises:\n        ValueError: If the function with the same name already registered and `TorchFuncRegistry.override=False`.\n    Examples:\n    ```python\n    &gt;&gt;&gt; import torch\n    &gt;&gt;&gt; registry = TorchFuncRegistry(\"test\")\n    &gt;&gt;&gt; @registry.implement(torch.mean)  # pylint: disable=E1101\n    ... def mean(input):\n    ...     raise input.mean()\n    &gt;&gt;&gt; registry  # doctest: +ELLIPSIS\n    TorchFuncRegistry(\n      (&lt;built-in method mean of type object at ...&gt;): &lt;function mean at ...&gt;\n    )\n    ```\n    \"\"\"\nif torch_function in self and not self.override:\nraise ValueError(f\"Torch function {torch_function.__name__} already registered.\")\n@wraps(self.register)\ndef register(function):\nself.set(torch_function, function)\nreturn function\nreturn register\n</code></pre>"},{"location":"utils/basex/","title":"basex","text":""},{"location":"utils/decorators/","title":"Decorator","text":""},{"location":"utils/decorators/#danling.utils.decorators.flexible_decorator","title":"<code>flexible_decorator(maybe_decorator=None)</code>","text":"<p>Decorator to allow bracket-less when no arguments are passed.</p> <p>Examples:</p> <p>For decorator defined as follows:</p> Python<pre><code>&gt;&gt;&gt; @flexible_decorator\n... def decorator(*args, **kwargs):\n...     def wrapper(func, *args, **kwargs):\n...         pass\n...     return wrapper\n</code></pre> <p>The following two are equivalent:</p> Python<pre><code>&gt;&gt;&gt; @decorator\n... def func(*args, **kwargs):\n...     pass\n</code></pre> Python<pre><code>&gt;&gt;&gt; @decorator()\n... def func(*args, **kwargs):\n...     pass\n</code></pre> Source code in <code>danling/utils/decorators.py</code> Python<pre><code>def flexible_decorator(maybe_decorator: Optional[Callable] = None):\n\"\"\"\n    Decorator to allow bracket-less when no arguments are passed.\n    Examples:\n    For decorator defined as follows:\n    ```python\n    &gt;&gt;&gt; @flexible_decorator\n    ... def decorator(*args, **kwargs):\n    ...     def wrapper(func, *args, **kwargs):\n    ...         pass\n    ...     return wrapper\n    ```\n    The following two are equivalent:\n    ```python\n    &gt;&gt;&gt; @decorator\n    ... def func(*args, **kwargs):\n    ...     pass\n    ```\n    ```python\n    &gt;&gt;&gt; @decorator()\n    ... def func(*args, **kwargs):\n    ...     pass\n    ```\n    \"\"\"\ndef decorator(func: Callable):\n@wraps(decorator)\ndef wrapper(*args, **kwargs):\nif len(args) == 1 and isfunction(args[0]):\nreturn func(**kwargs)(args[0])\nreturn func(*args, **kwargs)\nreturn wrapper\nif maybe_decorator is None:\nreturn decorator\nreturn decorator(maybe_decorator)\n</code></pre>"},{"location":"utils/decorators/#danling.utils.decorators.catch","title":"<code>catch(error=Exception, exclude=None, verbose=True, print_args=False)</code>","text":"<p>Decorator to catch <code>error</code> except for <code>exclude</code>. Detailed traceback will be printed to <code>stderr</code>.</p> <p><code>catch</code> is extremely useful for unfatal errors. For example, <code>Runner</code> saves checkpoint regularly, however, this might break running if the space is full. Decorating <code>save</code> method with <code>catch</code> will allow you to catch these errors and continue your running.</p> <p>Parameters:</p> Name Type Description Default <code>error</code> <code>Type[Exception]</code> <code>Exception</code> <code>exclude</code> <code>Optional[Type[Exception]]</code> <code>None</code> <code>print_args</code> <code>bool</code> <p>Whether to print the arguments passed to the function.</p> <code>False</code> Source code in <code>danling/utils/decorators.py</code> Python<pre><code>@flexible_decorator\ndef catch(\nerror: Type[Exception] = Exception,\nexclude: Optional[Type[Exception]] = None,\nverbose: bool = True,\nprint_args: bool = False,\n):\n\"\"\"\n    Decorator to catch `error` except for `exclude`.\n    Detailed traceback will be printed to `stderr`.\n    `catch` is extremely useful for unfatal errors.\n    For example, `Runner` saves checkpoint regularly, however, this might break running if the space is full.\n    Decorating `save` method with `catch` will allow you to catch these errors and continue your running.\n    Args:\n        error:\n        exclude:\n        print_args: Whether to print the arguments passed to the function.\n    \"\"\"\ndef decorator(\nfunc, error: Type[Exception] = Exception, exclude: Optional[Type[Exception]] = None, print_args: bool = False\n):\n@wraps(func)\ndef wrapper(*args, **kwargs):  # pylint: disable=R1710\ntry:\nreturn func(*args, **kwargs)\nexcept error as exc:  # pylint: disable=W0703\nif exclude is not None and isinstance(exc, exclude):\nraise exc\nif verbose:\nmessage = format_exc()\nmessage += f\"\\nencoutered when calling {func}\"\nif print_args:\nmessage += f\"with args {args} and kwargs {kwargs}\"\nprint(message, file=stderr, force=True)\nreturn wrapper\nreturn lambda func: decorator(func, error, exclude, print_args)\n</code></pre>"},{"location":"utils/decorators/#danling.utils.decorators.method_cache","title":"<code>method_cache(*cache_args, **lru_kwargs)</code>","text":"<p>Decorator to cache the result of an instance method.</p> <p><code>functools.lru_cache</code> uses a strong reference to the instance, which will make the instance immortal and break the garbage collection.</p> <p><code>method_cache</code> uses a weak reference to the instance and works fine.</p> <p>https://rednafi.github.io/reflections/dont-wrap-instance-methods-with-functoolslru_cache-decorator-in-python.html</p> Source code in <code>danling/utils/decorators.py</code> Python<pre><code>def method_cache(*cache_args, **lru_kwargs):\nr\"\"\"\n    Decorator to cache the result of an instance method.\n    `functools.lru_cache` uses a strong reference to the instance,\n    which will make the instance immortal and break the garbage collection.\n    `method_cache` uses a weak reference to the instance and works fine.\n    https://rednafi.github.io/reflections/dont-wrap-instance-methods-with-functoolslru_cache-decorator-in-python.html\n    \"\"\"\ndef decorator(func):\n@wraps(func)\ndef wrapper(self, *args, **kwargs):\nself_ref = ref(self)\n@wraps(func)\n@lru_cache(*cache_args, **lru_kwargs)\ndef cached_method(*args, **kwargs):\nreturn func(self_ref(), *args, **kwargs)\nsetattr(self, func.__name__, cached_method)\nreturn cached_method(*args, **kwargs)\nreturn wrapper\nreturn decorator\n</code></pre>"},{"location":"utils/decorators/#danling.utils.decorators.ensure_dir","title":"<code>ensure_dir(func)</code>","text":"<p>Decorator to ensure a directory property exists.</p> Source code in <code>danling/utils/decorators.py</code> Python<pre><code>def ensure_dir(func):\n\"\"\"\n    Decorator to ensure a directory property exists.\n    \"\"\"\n@wraps(func)\ndef wrapper(*args, **kwargs):\npath = abspath(func(*args, **kwargs))\nmakedirs(path, exist_ok=True)\nreturn path\nreturn wrapper\n</code></pre>"},{"location":"utils/io/","title":"IO","text":""},{"location":"utils/io/#danling.utils.io.save","title":"<code>save(obj, file, *args, **kwargs)</code>","text":"<p>Save any file with supported extensions.</p> Source code in <code>danling/utils/io.py</code> Python<pre><code>def save(obj: Any, file: PathStr, *args: List[Any], **kwargs: Dict[str, Any]) -&gt; File:  # pylint: disable=R0912\nr\"\"\"\n    Save any file with supported extensions.\n    \"\"\"\nextension = os.path.splitext(file)[-1].lower()[1:]  # type: ignore\nif extension in PYTORCH:\nif not TORCH_AVAILABLE:\nraise ImportError(f\"Trying to save {obj} to {file!r} but torch is not installed.\")\ntorch.save(obj, file, *args, **kwargs)  # type: ignore\nelif extension in NUMPY:\nif not NUMPY_AVAILABLE:\nraise ImportError(f\"Trying to save {obj} to {file!r} but numpy is not installed.\")\nnumpy.save(file, obj, *args, **kwargs)  # type: ignore\nelif extension in CSV:\nif isinstance(obj, pandas.DataFrame):\nobj.to_csv(file, *args, **kwargs)  # type: ignore\nelse:\nraise NotImplementedError(f\"Trying to save {obj} to {file!r} but is not supported\")\nelif extension in JSON:\nif isinstance(obj, FlatDict):\nobj.json(file)\nelse:\nwith open(file, \"w\") as fp:  # pylint: disable=W1514, C0103\njson.dump(obj, fp, *args, **kwargs)  # type: ignore\nelif extension in YAML:\nif isinstance(obj, FlatDict):\nobj.yaml(file)\nelse:\nwith open(file, \"w\") as fp:  # pylint: disable=W1514, C0103\nyaml.dump(obj, fp, *args, **kwargs)  # type: ignore\nelif extension in PICKLE:\nwith open(file, \"wb\") as fp:  # type: ignore # pylint: disable=C0103\npickle.dump(obj, fp, *args, **kwargs)  # type: ignore\nelse:\nraise ValueError(f\"Tying to save {obj} to {file!r} with unsupported extension={extension!r}\")\nreturn file\n</code></pre>"},{"location":"utils/io/#danling.utils.io.load","title":"<code>load(file, *args, **kwargs)</code>","text":"<p>Load any file with supported extensions.</p> Source code in <code>danling/utils/io.py</code> Python<pre><code>def load(file: PathStr, *args: List[Any], **kwargs: Dict[str, Any]) -&gt; Any:\nr\"\"\"\n    Load any file with supported extensions.\n    \"\"\"\nif not os.path.isfile(file):\nraise ValueError(f\"Trying to load {file!r} but it is not a file.\")\nextension = os.path.splitext(file)[-1].lower()[1:]  # type: ignore\nif extension in PYTORCH:\nif not TORCH_AVAILABLE:\nraise ImportError(f\"Trying to load {file!r} but torch is not installed.\")\nreturn torch.load(file, *args, **kwargs)  # type: ignore\nif extension in NUMPY:\nif not NUMPY_AVAILABLE:\nraise ImportError(f\"Trying to load {file!r} but numpy is not installed.\")\nreturn numpy.load(file, *args, **kwargs)  # type: ignore\nif extension in CSV:\nif not PANDAS_AVAILABLE:\nraise ImportError(f\"Trying to load {file!r} but pandas is not installed.\")\nreturn pandas.read_csv(file, *args, **kwargs)  # type: ignore\nif extension in JSON:\nwith open(file, \"r\") as fp:  # pylint: disable=W1514, C0103\nreturn json.load(fp, *args, **kwargs)  # type: ignore\nif extension in YAML:\nwith open(file, \"r\") as fp:  # pylint: disable=W1514, C0103\nreturn yaml.load(fp, *args, **kwargs)  # type: ignore\nif extension in PICKLE:\nwith open(file, \"rb\") as fp:  # type: ignore # pylint: disable=C0103\nreturn pickle.load(fp, *args, **kwargs)  # type: ignore\nraise ValueError(f\"Tying to load {file!r} with unsupported extension={extension!r}\")\n</code></pre>"},{"location":"utils/io/#danling.utils.io.is_json_serializable","title":"<code>is_json_serializable(obj)</code>","text":"<p>Check if <code>obj</code> is JSON serializable.</p> Source code in <code>danling/utils/io.py</code> Python<pre><code>def is_json_serializable(obj: Any) -&gt; bool:\nr\"\"\"\n    Check if `obj` is JSON serializable.\n    \"\"\"\ntry:\njson.dumps(obj)\nreturn True\nexcept (TypeError, OverflowError):\nreturn False\n</code></pre>"},{"location":"en/#introduction","title":"Introduction","text":"<p>DanLing (\u4e39\u7075) is a high-level library to help with running neural networks flexibly and transparently.</p> <p>DanLing is meant to be a scaffold for experienced researchers and engineers who know how to define a training loop, but are bored of writing the same boilerplate code, such as DDP, logging, checkpointing, etc., over and over again.</p> <p>Therefore, DanLing does not feature complex Runner designs with many pre-defined methods and complicated hooks. Instead, the Runner of DanLing just initialise the essential parts for you, and you can do whatever you want, however you want.</p> <p>Although many attributes and properties are pre-defined and are expected to be used in DanLing, you have full control over your code.</p> <p>DanLing also provides some utilities, such as [Registry][danling.Registry], [NestedTensor][danling.NestedTensor], [catch][danling.utils.catch], etc.</p>"},{"location":"en/package/#danling.runner.base_runner.BaseRunner.load_checkpoint","title":"<code>load_checkpoint(checkpoint=None, override_state=False, *args, **kwargs)</code>","text":"<p>Load info from checkpoint.</p> <p>Parameters:</p> Name Type Description Default <code>checkpoint</code> <code>Optional[Union[Mapping, str]]</code> <p>Checkpoint (or its path) to load. Defaults to <code>self.checkpoint_dir/latest.pth</code>.</p> <code>None</code> <code>override_state</code> <code>bool</code> <p>If True, override runner state with checkpoint state. Defaults to <code>False</code>.</p> <code>False</code> <code>*args</code> <p>Additional arguments to pass to <code>self.load</code>.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to <code>self.load</code>.</p> <code>{}</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If <code>checkpoint</code> does not exists.</p> See Also <p>[<code>from_checkpoint</code>][danling.BaseRunner.from_checkpoint]: Build runner from checkpoint. [<code>load_pretrained</code>][danling.BaseRunner.load_pretrained]: Load parameters from pretrained checkpoint.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>def load_checkpoint(  # pylint: disable=W1113\nself, checkpoint: Optional[Union[Mapping, str]] = None, override_state: bool = False, *args, **kwargs\n) -&gt; None:\n\"\"\"\n    Load info from checkpoint.\n    Args:\n        checkpoint: Checkpoint (or its path) to load.\n            Defaults to `self.checkpoint_dir/latest.pth`.\n        override_state: If True, override runner state with checkpoint state.\n            Defaults to `False`.\n        *args: Additional arguments to pass to `self.load`.\n        **kwargs: Additional keyword arguments to pass to `self.load`.\n    Raises:\n        FileNotFoundError: If `checkpoint` does not exists.\n    See Also:\n        [`from_checkpoint`][danling.BaseRunner.from_checkpoint]: Build runner from checkpoint.\n        [`load_pretrained`][danling.BaseRunner.load_pretrained]: Load parameters from pretrained checkpoint.\n    \"\"\"\nif checkpoint is None:\ncheckpoint = os.path.join(self.checkpoint_dir, \"latest.pth\")  # type: ignore\n# TODO: Support loading checkpoints in other format\nif isinstance(checkpoint, str):\nif not os.path.exists(checkpoint):\nraise FileNotFoundError(f\"checkpoint is set to {checkpoint} but does not exist.\")\nself.checkpoint = checkpoint  # pylint: disable=W0201\ncheckpoint: Mapping = self.load(checkpoint, *args, **kwargs)  # type: ignore\n# TODO: Wrap state_dict in a dataclass\nif override_state:\nself.__dict__.update(NestedDict(**checkpoint[\"runner\"]))  # type: ignore\nif self.model is not None and \"model\" in checkpoint:\nmodel = self.unwrap_model(self.model)\nmodel.load_state_dict(checkpoint[\"model\"])  # type: ignore\nif self.optimizer is not None and \"optimizer\" in checkpoint:\nself.optimizer.load_state_dict(checkpoint[\"optimizer\"])  # type: ignore\nif self.scheduler is not None and \"scheduler\" in checkpoint:\nself.scheduler.load_state_dict(checkpoint[\"scheduler\"])  # type: ignore\n</code></pre>"},{"location":"en/package/#danling.runner.base_runner.BaseRunner.load_pretrained","title":"<code>load_pretrained(checkpoint, *args, **kwargs)</code>","text":"<p>Load parameters from pretrained checkpoint.</p> <p>Parameters:</p> Name Type Description Default <code>checkpoint</code> <code>Union[Mapping, str]</code> <p>Pretrained checkpoint (or its path) to load.</p> required <code>*args</code> <p>Additional arguments to pass to <code>self.load</code>.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to <code>self.load</code>.</p> <code>{}</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If <code>checkpoint</code> does not exists.</p> See Also <p>[<code>load_checkpoint</code>][danling.BaseRunner.load_checkpoint]: Load info from checkpoint.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>def load_pretrained(self, checkpoint: Union[Mapping, str], *args, **kwargs) -&gt; None:\n\"\"\"\n    Load parameters from pretrained checkpoint.\n    Args:\n        checkpoint: Pretrained checkpoint (or its path) to load.\n        *args: Additional arguments to pass to `self.load`.\n        **kwargs: Additional keyword arguments to pass to `self.load`.\n    Raises:\n        FileNotFoundError: If `checkpoint` does not exists.\n    See Also:\n        [`load_checkpoint`][danling.BaseRunner.load_checkpoint]: Load info from checkpoint.\n    \"\"\"\n# TODO: Support loading checkpoints in other format\nif isinstance(checkpoint, str):\nif not os.path.exists(checkpoint):\nraise FileNotFoundError(f\"pretrained is set to {checkpoint} but does not exist.\")\ncheckpoint: Mapping = self.load(checkpoint, *args, **kwargs)  # type: ignore\nif \"model\" in checkpoint:\ncheckpoint = checkpoint[\"model\"]  # type: ignore\nif \"state_dict\" in checkpoint:\ncheckpoint = checkpoint[\"state_dict\"]  # type: ignore\nmodel = self.unwrap_model(self.model)\nmodel.load_state_dict(checkpoint)  # type: ignore\n</code></pre>"},{"location":"en/runner/#runnerstatedanlingrunnerrunner_staterunnerstate","title":"[<code>RunnerState</code>][danling.runner.runner_state.RunnerState]","text":"<p>[<code>RunnerState</code>][danling.runner.runner_state.RunnerState] stores the state of a run.</p> <p>All attributes stored in <code>RunnerState</code> will be saved in the checkpoint, and thus should be json serialisable. Except for <code>@property</code> of json serialisable attributes.</p>"},{"location":"en/runner/#runnerbasedanlingrunnerrunner_baserunnerbase","title":"[<code>RunnerBase</code>][danling.runner.runner_base.RunnerBase]","text":"<p>[<code>RunnerBase</code>][danling.runner.abstract_base_runner.RunnerBase] gives you a basic instinct on what attributes and properties are provided by the Runner.</p> <p>It works in an AbstractBaseClass manner and should neither be used directly nor be inherited from.</p>"},{"location":"en/runner/#baserunnerdanlingrunnerbaserunner","title":"[<code>BaseRunner</code>][danling.runner.BaseRunner]","text":"<p>[<code>BaseRunner</code>][danling.runner.BaseRunner] contains core methods of general basic functionality, such as <code>init_logging</code>, <code>append_result</code>, <code>print_result</code>.</p>"},{"location":"en/runner/#runnerdanlingrunnertorchrunner","title":"[<code>Runner</code>][danling.runner.TorchRunner]","text":"<p>[<code>Runner</code>][danling.runner.TorchRunner] should only contain platform-specific features. Currently, only [<code>TorchRunner</code>][danling.runner.TorchRunner] is supported.</p>"},{"location":"en/runner/base_runner/#danling.runner.base_runner.BaseRunner.load_checkpoint","title":"<code>load_checkpoint(checkpoint=None, override_state=False, *args, **kwargs)</code>","text":"<p>Load info from checkpoint.</p> <p>Parameters:</p> Name Type Description Default <code>checkpoint</code> <code>Optional[Union[Mapping, str]]</code> <p>Checkpoint (or its path) to load. Defaults to <code>self.checkpoint_dir/latest.pth</code>.</p> <code>None</code> <code>override_state</code> <code>bool</code> <p>If True, override runner state with checkpoint state. Defaults to <code>False</code>.</p> <code>False</code> <code>*args</code> <p>Additional arguments to pass to <code>self.load</code>.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to <code>self.load</code>.</p> <code>{}</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If <code>checkpoint</code> does not exists.</p> See Also <p>[<code>from_checkpoint</code>][danling.BaseRunner.from_checkpoint]: Build runner from checkpoint. [<code>load_pretrained</code>][danling.BaseRunner.load_pretrained]: Load parameters from pretrained checkpoint.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>def load_checkpoint(  # pylint: disable=W1113\nself, checkpoint: Optional[Union[Mapping, str]] = None, override_state: bool = False, *args, **kwargs\n) -&gt; None:\n\"\"\"\n    Load info from checkpoint.\n    Args:\n        checkpoint: Checkpoint (or its path) to load.\n            Defaults to `self.checkpoint_dir/latest.pth`.\n        override_state: If True, override runner state with checkpoint state.\n            Defaults to `False`.\n        *args: Additional arguments to pass to `self.load`.\n        **kwargs: Additional keyword arguments to pass to `self.load`.\n    Raises:\n        FileNotFoundError: If `checkpoint` does not exists.\n    See Also:\n        [`from_checkpoint`][danling.BaseRunner.from_checkpoint]: Build runner from checkpoint.\n        [`load_pretrained`][danling.BaseRunner.load_pretrained]: Load parameters from pretrained checkpoint.\n    \"\"\"\nif checkpoint is None:\ncheckpoint = os.path.join(self.checkpoint_dir, \"latest.pth\")  # type: ignore\n# TODO: Support loading checkpoints in other format\nif isinstance(checkpoint, str):\nif not os.path.exists(checkpoint):\nraise FileNotFoundError(f\"checkpoint is set to {checkpoint} but does not exist.\")\nself.checkpoint = checkpoint  # pylint: disable=W0201\ncheckpoint: Mapping = self.load(checkpoint, *args, **kwargs)  # type: ignore\n# TODO: Wrap state_dict in a dataclass\nif override_state:\nself.__dict__.update(NestedDict(**checkpoint[\"runner\"]))  # type: ignore\nif self.model is not None and \"model\" in checkpoint:\nmodel = self.unwrap_model(self.model)\nmodel.load_state_dict(checkpoint[\"model\"])  # type: ignore\nif self.optimizer is not None and \"optimizer\" in checkpoint:\nself.optimizer.load_state_dict(checkpoint[\"optimizer\"])  # type: ignore\nif self.scheduler is not None and \"scheduler\" in checkpoint:\nself.scheduler.load_state_dict(checkpoint[\"scheduler\"])  # type: ignore\n</code></pre>"},{"location":"en/runner/base_runner/#danling.runner.base_runner.BaseRunner.load_pretrained","title":"<code>load_pretrained(checkpoint, *args, **kwargs)</code>","text":"<p>Load parameters from pretrained checkpoint.</p> <p>Parameters:</p> Name Type Description Default <code>checkpoint</code> <code>Union[Mapping, str]</code> <p>Pretrained checkpoint (or its path) to load.</p> required <code>*args</code> <p>Additional arguments to pass to <code>self.load</code>.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to <code>self.load</code>.</p> <code>{}</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If <code>checkpoint</code> does not exists.</p> See Also <p>[<code>load_checkpoint</code>][danling.BaseRunner.load_checkpoint]: Load info from checkpoint.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>def load_pretrained(self, checkpoint: Union[Mapping, str], *args, **kwargs) -&gt; None:\n\"\"\"\n    Load parameters from pretrained checkpoint.\n    Args:\n        checkpoint: Pretrained checkpoint (or its path) to load.\n        *args: Additional arguments to pass to `self.load`.\n        **kwargs: Additional keyword arguments to pass to `self.load`.\n    Raises:\n        FileNotFoundError: If `checkpoint` does not exists.\n    See Also:\n        [`load_checkpoint`][danling.BaseRunner.load_checkpoint]: Load info from checkpoint.\n    \"\"\"\n# TODO: Support loading checkpoints in other format\nif isinstance(checkpoint, str):\nif not os.path.exists(checkpoint):\nraise FileNotFoundError(f\"pretrained is set to {checkpoint} but does not exist.\")\ncheckpoint: Mapping = self.load(checkpoint, *args, **kwargs)  # type: ignore\nif \"model\" in checkpoint:\ncheckpoint = checkpoint[\"model\"]  # type: ignore\nif \"state_dict\" in checkpoint:\ncheckpoint = checkpoint[\"state_dict\"]  # type: ignore\nmodel = self.unwrap_model(self.model)\nmodel.load_state_dict(checkpoint)  # type: ignore\n</code></pre>"},{"location":"en/runner/runner_base/","title":"RunnerBase","text":"<p>Base class for all runners.</p> <p><code>RunnerBase</code> is designed as a \u201cdataclass\u201d.</p> <p>It defines all basic attributes and relevant properties such as <code>scores</code>, <code>progress</code>, etc.</p> <p><code>RunnerBase</code> also defines basic IO operations such as <code>save</code>, <code>load</code>, <code>json</code>, <code>yaml</code>, etc.</p> <p>Model:</p> Name Type Description <code>model</code> <code>Callable</code> <code>criterion</code> <code>Callable</code> <code>optimizer</code> <code>Optional[Any]</code> <code>scheduler</code> <code>Optional[Any]</code> <p>Data:</p> Name Type Description <code>datasets</code> <code>FlatDict</code> <p>All datasets, should be in the form of <code>{subset: dataset}</code>.</p> <code>datasamplers</code> <code>FlatDict</code> <p>All datasamplers, should be in the form of <code>{subset: datasampler}</code>.</p> <code>dataloaders</code> <code>FlatDict</code> <p>All dataloaders, should be in the form of <code>{subset: dataloader}</code>.</p> <code>batch_size</code> <code>int, property</code> <p>Number of samples per batch in train dataloader or the first dataloader.</p> <code>batch_size_equivalent</code> <code>int, property</code> <p>Total batch_size (<code>batch_size * world_size * accum_steps</code>).</p> <p><code>datasets</code>, <code>datasamplers</code>, <code>dataloaders</code> should be a dict with the same keys. Their keys should be <code>split</code> (e.g. <code>train</code>, <code>val</code>, <code>test</code>).</p> <p>Progress:</p> Name Type Description <code>progress</code> <code>float, property</code> <p>Running Progress, in <code>range(0, 1)</code>.</p> <p>Results:</p> Name Type Description <code>latest_result</code> <code>NestedDict, property</code> <p>Most recent results, should be in the form of <code>{subset: {index: score}}</code>.</p> <code>best_result</code> <code>NestedDict, property</code> <p>Best recent results, should be in the form of <code>{subset: {index: score}}</code>.</p> <code>scores</code> <code>List[float], property</code> <p>All scores.</p> <code>latest_score</code> <code>float, property</code> <p>Most recent score.</p> <code>best_score</code> <code>float, property</code> <p>Best score.</p> <code>index_set</code> <code>Optional[str]</code> <p>The subset to calculate the core score. If is <code>None</code>, will use the last set of the result.</p> <code>index</code> <code>str</code> <p>The index to calculate the core score. Defaults to <code>\"loss\"</code>.</p> <code>is_best</code> <code>bool, property</code> <p>If <code>latest_score == best_score</code>.</p> <p>IO:</p> Name Type Description <code>dir</code> <code>str, property</code> <p>Directory of the run. Defaults to <code>os.path.join(self.project_root, f\"{self.name}-{self.id}\")</code>.</p> <code>checkpoint_dir</code> <code>str, property</code> <p>Directory of checkpoints.</p> <code>log_path</code> <code>str, property</code> <p>Path of log file.</p> <code>checkpoint_dir_name</code> <code>str</code> <p>The name of the directory under <code>runner.dir</code> to save checkpoints. Defaults to <code>\"checkpoints\"</code>.</p> <p>Parallel Training:</p> Name Type Description <code>world_size</code> <code>int, property</code> <p>Number of processes.</p> <code>rank</code> <code>int, property</code> <p>Process index of all processes.</p> <code>local_rank</code> <code>int, property</code> <p>Process index of local processes.</p> <code>distributed</code> <code>bool, property</code> <p>If runner is running in distributed mode.</p> <code>is_main_process</code> <code>bool, property</code> <p>If current process is the main process of all processes.</p> <code>is_local_main_process</code> <code>bool, property</code> <p>If current process is the main process of local processes.</p> <p>logging:</p> Name Type Description <code>logger</code> <code>Optional[logging.Logger]</code> <code>writer</code> <code>Optional[Any]</code> Notes <p>The <code>RunnerBase</code> class is not intended to be used directly, nor to be directly inherit from.</p> <p>This is because <code>RunnerBase</code> is designed as a \u201cdataclass\u201d, and is meant for demonstrating all attributes and properties only.</p> See Also <p>[<code>RunnerState</code>][danling.runner.runner_state.RunnerState]: The runeer base that stores runtime information. [<code>BaseRunner</code>][danling.runner.BaseRunner]: The base runner class.</p> Source code in <code>danling/runner/runner_base.py</code> Python<pre><code>class RunnerBase:\nr\"\"\"\n    Base class for all runners.\n    `RunnerBase` is designed as a \"dataclass\".\n    It defines all basic attributes and relevant properties such as `scores`, `progress`, etc.\n    `RunnerBase` also defines basic IO operations such as `save`, `load`, `json`, `yaml`, etc.\n    Attributes: Model:\n        model (Callable):\n        criterion (Callable):\n        optimizer:\n        scheduler:\n    Attributes: Data:\n        datasets (FlatDict): All datasets, should be in the form of ``{subset: dataset}``.\n        datasamplers (FlatDict): All datasamplers, should be in the form of ``{subset: datasampler}``.\n        dataloaders (FlatDict): All dataloaders, should be in the form of ``{subset: dataloader}``.\n        batch_size (int, property): Number of samples per batch in train dataloader or the first dataloader.\n        batch_size_equivalent (int, property): Total batch_size (`batch_size * world_size * accum_steps`).\n    `datasets`, `datasamplers`, `dataloaders` should be a dict with the same keys.\n    Their keys should be `split` (e.g. `train`, `val`, `test`).\n    Attributes: Progress:\n        progress (float, property): Running Progress, in `range(0, 1)`.\n    Attributes: Results:\n        latest_result (NestedDict, property): Most recent results,\n            should be in the form of ``{subset: {index: score}}``.\n        best_result (NestedDict, property): Best recent results, should be in the form of ``{subset: {index: score}}``.\n        scores (List[float], property): All scores.\n        latest_score (float, property): Most recent score.\n        best_score (float, property): Best score.\n        index_set (Optional[str]): The subset to calculate the core score.\n            If is `None`, will use the last set of the result.\n        index (str): The index to calculate the core score.\n            Defaults to `\"loss\"`.\n        is_best (bool, property): If `latest_score == best_score`.\n    Attributes: IO:\n        dir (str, property): Directory of the run.\n            Defaults to `os.path.join(self.project_root, f\"{self.name}-{self.id}\")`.\n        checkpoint_dir (str, property): Directory of checkpoints.\n        log_path (str, property):  Path of log file.\n        checkpoint_dir_name (str): The name of the directory under `runner.dir` to save checkpoints.\n            Defaults to `\"checkpoints\"`.\n    Attributes: Parallel Training:\n        world_size (int, property): Number of processes.\n        rank (int, property): Process index of all processes.\n        local_rank (int, property): Process index of local processes.\n        distributed (bool, property): If runner is running in distributed mode.\n        is_main_process (bool, property): If current process is the main process of all processes.\n        is_local_main_process (bool, property): If current process is the main process of local processes.\n    Attributes: logging:\n        logger:\n        writer:\n    Notes:\n        The `RunnerBase` class is not intended to be used directly, nor to be directly inherit from.\n        This is because `RunnerBase` is designed as a \"dataclass\",\n        and is meant for demonstrating all attributes and properties only.\n    See Also:\n        [`RunnerState`][danling.runner.runner_state.RunnerState]: The runeer base that stores runtime information.\n        [`BaseRunner`][danling.runner.BaseRunner]: The base runner class.\n    \"\"\"\n# pylint: disable=R0902, R0904\n# DO NOT set default value in class, as they won't be stored in `__dict__`.\nstate: RunnerState\nmodel: Optional[Callable] = None\ncriterion: Optional[Callable] = None\noptimizer: Optional[Any] = None\nscheduler: Optional[Any] = None\ndatasets: FlatDict\ndatasamplers: FlatDict\ndataloaders: FlatDict\nmeters: Optional[AverageMeters] = None\nlogger: Optional[logging.Logger] = None\nwriter: Optional[Any] = None\ndef __init__(self, *args, **kwargs):\nsuper().__init__()\nself.state = RunnerState(*args, **kwargs)\nself.meters = AverageMeters()\nself.datasets = FlatDict()\nself.datasamplers = FlatDict()\nself.dataloaders = FlatDict()\n@property\ndef batch_size(self) -&gt; int:\nr\"\"\"\n        Batch size.\n        Notes:\n            If `train` is in `dataloaders`, then `batch_size` is the batch size of `train`.\n            Otherwise, `batch_size` is the batch size of the first dataloader.\n        Returns:\n            (int):\n        \"\"\"\nif self.dataloaders:\nloader = self.dataloaders[\"train\"] if \"train\" in self.dataloaders else next(iter(self.dataloaders.values()))\nreturn loader.batch_size\nraise AttributeError(\"batch_size could not be inferred, since no dataloaedr found.\")\n@property\ndef batch_size_equivalent(self) -&gt; int:\nr\"\"\"\n        Actual batch size.\n        Returns:\n            (int): `batch_size` * `world_size` * `accum_steps`\n        \"\"\"\nreturn self.batch_size * self.world_size * getattr(self, \"accum_steps\", 1)\n@property\ndef accum_steps(self) -&gt; int:\nr\"\"\"\n        Accumulated steps.\n        Returns:\n            (int):\n        \"\"\"\nraise AttributeError(\"accum_steps is not defined.\")\n@property\ndef device(self) -&gt; Any:\nr\"\"\"\n        Device of runner.\n        \"\"\"\nraise NotImplementedError\n@property\ndef world_size(self) -&gt; int:\nr\"\"\"\n        Number of processes.\n        \"\"\"\nreturn 1\n@property\ndef rank(self) -&gt; int:\nr\"\"\"\n        Process index of all processes.\n        \"\"\"\nreturn 0\n@property\ndef local_rank(self) -&gt; int:\nr\"\"\"\n        Process index of local processes.\n        \"\"\"\nreturn 0\n@property\ndef distributed(self) -&gt; bool:\nr\"\"\"\n        If runner is running in distributed mode.\n        \"\"\"\nreturn self.world_size &gt; 1\n@property\ndef is_main_process(self) -&gt; bool:\nr\"\"\"\n        If current process is the main process of all processes.\n        \"\"\"\nreturn self.rank == 0\n@property\ndef is_local_main_process(self) -&gt; bool:\nr\"\"\"\n        If current process is the main process of local processes.\n        \"\"\"\nreturn self.local_rank == 0\n@catch\ndef save(  # pylint: disable=W1113\nself, obj: Any, file: PathStr, main_process_only: bool = True, *args, **kwargs\n) -&gt; File:\nr\"\"\"\n        Save any file with supported extensions.\n        `Runner.save` internally calls `dl.save`,\n        but with additional arguments to allow it save only on the main process.\n        Moreover, any error raised by `Runner.save` will be caught and logged.\n        \"\"\"\nif main_process_only and self.is_main_process or not main_process_only:\nreturn save(obj, file, *args, **kwargs)\nreturn file\n@staticmethod\ndef load(file: PathStr, *args, **kwargs) -&gt; Any:  # pylint: disable=C0103\nr\"\"\"\n        Load any file with supported extensions.\n        `Runner.load` is identical to `dl.save`.\n        \"\"\"\nreturn load(file, *args, **kwargs)\ndef dict(self, cls: Callable = dict) -&gt; Mapping:\nr\"\"\"\n        Convert state to Mapping.\n        Args:\n            cls: Target `clc to convert to.\n        \"\"\"\n# pylint: disable=C0103\nreturn self.state.dict(cls)\n@catch\ndef json(self, file: File, main_process_only: bool = True, *args, **kwargs) -&gt; None:  # pylint: disable=W1113\nr\"\"\"\n        Dump Runner State to json file.\n        \"\"\"\nif main_process_only and self.is_main_process or not main_process_only:\nreturn self.state.json(file, *args, **kwargs)\n@classmethod\ndef from_json(cls, file: File, *args, **kwargs) -&gt; RunnerBase:\nr\"\"\"\n        Construct Runner from json file.\n        This function calls `self.from_jsons()` to construct object from json string.\n        You may overwrite `from_jsons` in case something is not json serializable.\n        \"\"\"\nwith FlatDict.open(file) as fp:  # pylint: disable=C0103\nreturn cls.from_jsons(fp.read(), *args, **kwargs)\ndef jsons(self, *args, **kwargs) -&gt; str:\nr\"\"\"\n        Dump Runner State to json string.\n        \"\"\"\nreturn self.state.jsons(*args, **kwargs)\n@classmethod\ndef from_jsons(cls, string: str, *args, **kwargs) -&gt; RunnerBase:\nr\"\"\"\n        Construct Runner from json string.\n        \"\"\"\nreturn cls(Config.from_jsons(string, *args, **kwargs))\n@catch\ndef yaml(self, file: File, main_process_only: bool = True, *args, **kwargs) -&gt; None:  # pylint: disable=W1113\nr\"\"\"\n        Dump Runner State to yaml file.\n        \"\"\"\nif main_process_only and self.is_main_process or not main_process_only:\nreturn self.state.yaml(file, *args, **kwargs)\n@classmethod\ndef from_yaml(cls, file: File, *args, **kwargs) -&gt; RunnerBase:\nr\"\"\"\n        Construct Runner from yaml file.\n        This function calls `self.from_yamls()` to construct object from yaml string.\n        You may overwrite `from_yamls` in case something is not yaml serializable.\n        \"\"\"\nwith FlatDict.open(file) as fp:  # pylint: disable=C0103\nreturn cls.from_yamls(fp.read(), *args, **kwargs)\ndef yamls(self, *args, **kwargs) -&gt; str:\nr\"\"\"\n        Dump Runner State to yaml string.\n        \"\"\"\nreturn self.state.yamls(*args, **kwargs)\n@classmethod\ndef from_yamls(cls, string: str, *args, **kwargs) -&gt; RunnerBase:\nr\"\"\"\n        Construct Runner from yaml string.\n        \"\"\"\nreturn cls(Config.from_yamls(string, *args, **kwargs))\n@property\ndef progress(self) -&gt; float:\nr\"\"\"\n        Training Progress.\n        Returns:\n            (float):\n        Raises:\n            RuntimeError: If no terminal is defined.\n        \"\"\"\nif hasattr(self.state, \"iter_end\"):\nreturn self.state.iters / self.state.iter_end\nif hasattr(self.state, \"step_end\"):\nreturn self.state.steps / self.state.step_end\nif hasattr(self.state, \"epoch_end\"):\nreturn self.state.epochs / self.state.epoch_end\nraise RuntimeError(\"DanLing cannot determine progress since no terminal is defined.\")\n@property\ndef best_fn(self) -&gt; Callable:  # pylint: disable=C0103\nr\"\"\"\n        Function to determine the best score from a list of scores.\n        Subclass can override this method to accommodate needs, such as `min`.\n        Returns:\n            (callable): `max`\n        \"\"\"\nreturn max\n@property\ndef latest_result(self) -&gt; Optional[NestedDict]:\nr\"\"\"\n        Latest result.\n        \"\"\"\nreturn self.state.results[-1] if self.state.results else None\n@property\ndef best_result(self) -&gt; Optional[NestedDict]:\nr\"\"\"\n        Best result.\n        \"\"\"\nif not self.state.results:\nreturn None\nreturn self.state.results[-1 - self.scores[::-1].index(self.best_score)]  # type: ignore\n@property\ndef scores(self) -&gt; List[float]:\nr\"\"\"\n        All scores.\n        Scores are extracted from results by `index_set` and `runner.index`,\n        following `[r[index_set][self.state.index] for r in self.state.results]`.\n        By default, `index_set` points to `self.state.index_set` and is set to `val`,\n        if `self.state.index_set` is not set, it will be the last key of the last result.\n        Scores are considered as the index of the performance of the model.\n        It is useful to determine the best model and the best hyper-parameters.\n        \"\"\"\nif not self.state.results:\nreturn []\nindex_set = self.state.index_set or next(reversed(self.state.results[-1]))\nreturn [r[index_set][self.state.index] for r in self.state.results]\n@property\ndef latest_score(self) -&gt; Optional[float]:\nr\"\"\"\n        Latest score.\n        \"\"\"\nreturn self.scores[-1] if self.state.results else None\n@property\ndef best_score(self) -&gt; Optional[float]:\nr\"\"\"\n        Best score.\n        \"\"\"\nreturn self.best_fn(self.scores) if self.results else None\n@property\ndef is_best(self) -&gt; bool:\nr\"\"\"\n        If current epoch is the best epoch.\n        \"\"\"\ntry:\nreturn abs(self.latest_score - self.best_score) &lt; 1e-7  # type: ignore\nexcept TypeError:\nreturn True\n@property  # type: ignore\n@ensure_dir\ndef dir(self) -&gt; str:\nr\"\"\"\n        Directory of the run.\n        \"\"\"\nreturn os.path.join(self.project_root, f\"{self.name}-{self.id}\")\n@property\ndef log_path(self) -&gt; str:\nr\"\"\"\n        Path of log file.\n        \"\"\"\nreturn os.path.join(self.dir, \"run.log\")\n@property  # type: ignore\n@ensure_dir\ndef checkpoint_dir(self) -&gt; str:\nr\"\"\"\n        Directory of checkpoints.\n        \"\"\"\nreturn os.path.join(self.dir, self.checkpoint_dir_name)\ndef __getattr__(self, name) -&gt; Any:\nif \"state\" not in self:\nraise RuntimeError(\"Runner is not initialised yet.\")\nif name in self.state:\nreturn self.state[name]\nif name in dir(self.state):\nreturn getattr(self.state, name)\nraise super().__getattribute__(name)\ndef __setattr__(self, name, value) -&gt; None:\nif name in self.__dict__ and isinstance(self.__dict__[name], Variable):\nself.__dict__[name].set(value)\nelse:\nself.__dict__[name] = value\ndef __contains__(self, name) -&gt; bool:\nreturn name in self.__dict__\ndef __repr__(self):\nlines = []\nfor key, value in self.__dict__.items():\nvalue_str = repr(value)\nvalue_str = self._add_indent(value_str)\nlines.append(\"(\" + key + \"): \" + value_str)\nmain_str = self.__class__.__name__ + \"(\"\nif lines:\nmain_str += \"\\n  \" + \"\\n  \".join(lines) + \"\\n\"\nmain_str += \")\"\nreturn main_str\ndef _add_indent(self, text):\nlines = text.split(\"\\n\")\n# don't do anything for single-line stuff\nif len(lines) == 1:\nreturn text\nfirst = lines.pop(0)\n# add 2 spaces to each line but the first\nlines = [(2 * \" \") + line for line in lines]\nlines = \"\\n\".join(lines)\nlines = first + \"\\n\" + lines\nreturn lines\n</code></pre>"},{"location":"en/runner/runner_state/","title":"RunnerState","text":"<p>         Bases: <code>NestedDict</code></p> <p><code>RunnerState</code> is a <code>NestedDict</code> that contains all states of a <code>Runner</code>.</p> <p><code>RunnerState</code> is designed to store all critical information of a Run so that you can resume a run from a state and corresponding weights or even restart a run from a state.</p> <p><code>RunnerState</code> is also designed to be serialisable and hashable, so that you can save it to a file. <code>RunnerState</code> is saved in checkpoint together with weights by default.</p> <p>Since <code>RunnerState</code> is a <code>NestedDict</code>, you can access its attributes by <code>state[\"key\"]</code> or <code>state.key</code>.</p> <p>General:</p> Name Type Description <code>id</code> <code>str</code> <p><code>f\"{self.experiment_id:.4}{self.run_id:.4}{time_str}\"</code>.</p> <code>uuid</code> <code>UUID, property</code> <p><code>uuid5(self.run_id, self.id)</code>.</p> <code>name</code> <code>str</code> <p><code>f\"{self.experiment_name}-{self.run_name}\"</code>.</p> <code>run_id</code> <code>str</code> <p>hex of <code>self.run_uuid</code>.</p> <code>run_uuid</code> <code>UUID, property</code> <p><code>uuid5(self.experiment_id, config.jsons())</code>.</p> <code>run_name</code> <code>str</code> <p>Defaults to <code>\"DanLing\"</code>.</p> <code>experiment_id</code> <code>str</code> <p>git hash of the current HEAD. Defaults to <code>\"xxxxxxxxxxxxxxxx\"</code> if Runner not under a git repo or git/gitpython not installed.</p> <code>experiment_uuid</code> <code>UUID, property</code> <p>UUID of <code>self.experiment_id</code>. Defaults to <code>UUID('78787878-7878-7878-7878-787878787878')</code> if Runner not under a git repo or git/gitpython not installed.</p> <code>experiment_name</code> <code>str</code> <p>Defaults to <code>\"DanLing\"</code>.</p> <code>seed</code> <code>int</code> <p>Defaults to <code>randint(0, 2**32 - 1)</code>.</p> <code>deterministic</code> <code>bool</code> <p>Ensure deterministic operations. Defaults to <code>False</code>.</p> <p>Progress:</p> Name Type Description <code>iters</code> <code>int</code> <p>The number of data samples processed. equals to <code>steps</code> when <code>batch_size = 1</code>.</p> <code>steps</code> <code>int</code> <p>The number of <code>step</code> calls.</p> <code>epochs</code> <code>int</code> <p>The number of complete passes over the datasets.</p> <code>iter_end</code> <code>int</code> <p>End running iters. Note that <code>step_end</code> not initialised since this variable may not apply to some Runners.</p> <code>step_end</code> <code>int</code> <p>End running steps. Note that <code>step_end</code> not initialised since this variable may not apply to some Runners.</p> <code>epoch_end</code> <code>int</code> <p>End running epochs. Note that <code>epoch_end</code> not initialised since this variable may not apply to some Runners.</p> <p>In general you should only use one of <code>iter_end</code>, <code>step_end</code>, <code>epoch_end</code> to indicate the length of running.</p> <p>Results:</p> Name Type Description <code>results</code> <code>List[NestedDict]</code> <p>All results, should be in the form of <code>[{subset: {index: score}}]</code>.</p> <p><code>results</code> should be a list of <code>result</code>. <code>result</code> should be a dict with the same <code>split</code> as keys, like <code>dataloaders</code>. A typical <code>result</code> might look like this: Python<pre><code>{\n\"train\": {\n\"loss\": 0.1,\n\"accuracy\": 0.9,\n},\n\"val\": {\n\"loss\": 0.2,\n\"accuracy\": 0.8,\n},\n\"test\": {\n\"loss\": 0.3,\n\"accuracy\": 0.7,\n},\n}\n</code></pre></p> <p><code>scores</code> are usually a list of <code>float</code>, and are dynamically extracted from <code>results</code> by <code>index_set</code> and <code>index</code>. If <code>index_set = \"val\"</code>, <code>index = \"accuracy\"</code>, then <code>scores = 0.9</code>.</p> <p>IO:</p> Name Type Description <code>project_root</code> <code>str</code> <p>The root directory for all experiments. Defaults to <code>\"experiments\"</code>.</p> <p><code>project_root</code> is the root directory of all Experiments, and should be consistent across the Project.</p> <p><code>dir</code> is the directory of a certain Run.</p> <p>There is no attributes/properties for Group and Experiment.</p> <p><code>checkpoint_dir_name</code> is relative to <code>dir</code>, and is passed to generate <code>checkpoint_dir</code> (<code>checkpoint_dir = os.path.join(dir, checkpoint_dir_name)</code>). In practice, <code>checkpoint_dir_name</code> is rarely called.</p> <p>logging:</p> Name Type Description <code>log</code> <code>bool</code> <p>Whether to log the outputs. Defaults to <code>True</code>.</p> <code>tensorboard</code> <code>bool</code> <p>Whether to use <code>tensorboard</code>. Defaults to <code>False</code>.</p> <code>print_interval</code> <code>int</code> <p>Interval of printing logs. Defaults to -1.</p> <code>save_interval</code> <code>int</code> <p>Interval of saving intermediate checkpoints. Defaults to -1, never save intermediate checkpoints.</p> Notes <p><code>RunnerState</code> is a <code>NestedDict</code>, so you can access its attributes by <code>state[\"name\"]</code> or <code>state.name</code>.</p> See Also <p>[<code>RunnerBase</code>][danling.runner.runner_base.RunnerBase]: The runeer state that stores critical information. [<code>BaseRunner</code>][danling.runner.BaseRunner]: The base runner class.</p> Source code in <code>danling/runner/runner_state.py</code> Python<pre><code>class RunnerState(NestedDict):\nr\"\"\"\n    `RunnerState` is a `NestedDict` that contains all states of a `Runner`.\n    `RunnerState` is designed to store all critical information of a Run so that you can resume a run\n    from a state and corresponding weights or even restart a run from a state.\n    `RunnerState` is also designed to be serialisable and hashable, so that you can save it to a file.\n    `RunnerState` is saved in checkpoint together with weights by default.\n    Since `RunnerState` is a `NestedDict`, you can access its attributes by `state[\"key\"]` or `state.key`.\n    Attributes: General:\n        id (str): `f\"{self.experiment_id:.4}{self.run_id:.4}{time_str}\"`.\n        uuid (UUID, property): `uuid5(self.run_id, self.id)`.\n        name (str): `f\"{self.experiment_name}-{self.run_name}\"`.\n        run_id (str): hex of `self.run_uuid`.\n        run_uuid (UUID, property): `uuid5(self.experiment_id, config.jsons())`.\n        run_name (str): Defaults to `\"DanLing\"`.\n        experiment_id (str): git hash of the current HEAD.\n            Defaults to `\"xxxxxxxxxxxxxxxx\"` if Runner not under a git repo or git/gitpython not installed.\n        experiment_uuid (UUID, property): UUID of `self.experiment_id`.\n            Defaults to `UUID('78787878-7878-7878-7878-787878787878')`\n            if Runner not under a git repo or git/gitpython not installed.\n        experiment_name (str): Defaults to `\"DanLing\"`.\n        seed (int): Defaults to `randint(0, 2**32 - 1)`.\n        deterministic (bool): Ensure [deterministic](https://pytorch.org/docs/stable/notes/randomness.html) operations.\n            Defaults to `False`.\n    Attributes: Progress:\n        iters (int): The number of data samples processed.\n            equals to `steps` when `batch_size = 1`.\n        steps (int): The number of `step` calls.\n        epochs (int): The number of complete passes over the datasets.\n        iter_end (int): End running iters.\n            Note that `step_end` not initialised since this variable may not apply to some Runners.\n        step_end (int): End running steps.\n            Note that `step_end` not initialised since this variable may not apply to some Runners.\n        epoch_end (int): End running epochs.\n            Note that `epoch_end` not initialised since this variable may not apply to some Runners.\n    In general you should only use one of `iter_end`, `step_end`, `epoch_end` to indicate the length of running.\n    Attributes: Results:\n        results (List[NestedDict]): All results, should be in the form of ``[{subset: {index: score}}]``.\n    `results` should be a list of `result`.\n    `result` should be a dict with the same `split` as keys, like `dataloaders`.\n    A typical `result` might look like this:\n    ```python\n    {\n        \"train\": {\n            \"loss\": 0.1,\n            \"accuracy\": 0.9,\n        },\n        \"val\": {\n            \"loss\": 0.2,\n            \"accuracy\": 0.8,\n        },\n        \"test\": {\n            \"loss\": 0.3,\n            \"accuracy\": 0.7,\n        },\n    }\n    ```\n    `scores` are usually a list of `float`, and are dynamically extracted from `results` by `index_set` and `index`.\n    If `index_set = \"val\"`, `index = \"accuracy\"`, then `scores = 0.9`.\n    Attributes: IO:\n        project_root (str): The root directory for all experiments.\n            Defaults to `\"experiments\"`.\n    `project_root` is the root directory of all **Experiments**, and should be consistent across the **Project**.\n    `dir` is the directory of a certain **Run**.\n    There is no attributes/properties for **Group** and **Experiment**.\n    `checkpoint_dir_name` is relative to `dir`, and is passed to generate `checkpoint_dir`\n    (`checkpoint_dir = os.path.join(dir, checkpoint_dir_name)`).\n    In practice, `checkpoint_dir_name` is rarely called.\n    Attributes: logging:\n        log (bool): Whether to log the outputs.\n            Defaults to `True`.\n        tensorboard (bool): Whether to use `tensorboard`.\n            Defaults to `False`.\n        print_interval (int): Interval of printing logs.\n            Defaults to -1.\n        save_interval (int): Interval of saving intermediate checkpoints.\n            Defaults to -1, never save intermediate checkpoints.\n    Notes:\n        `RunnerState` is a `NestedDict`, so you can access its attributes by `state[\"name\"]` or `state.name`.\n    See Also:\n        [`RunnerBase`][danling.runner.runner_base.RunnerBase]: The runeer state that stores critical information.\n        [`BaseRunner`][danling.runner.BaseRunner]: The base runner class.\n    \"\"\"\n# pylint: disable=R0902, R0904\n# DO NOT set default value in class, as they won't be stored in `__dict__`.\nid: str\nname: str\nrun_id: str\nrun_name: str\nexperiment_id: str\nexperiment_name: str\nseed: int\ndeterministic: bool\niters: int\nsteps: int\nepochs: int\n# iter_begin: int  # Deprecated\n# step_begin: int  # Deprecated\n# epoch_begin: int  # Deprecated\niter_end: int\nstep_end: int\nepoch_end: int\nresults: List[NestedDict]\nindex_set: Optional[str]\nindex: str\nproject_root: str = \"experiments\"\ncheckpoint_dir_name: str = \"checkpoints\"\nlog: bool = True\ntensorboard: bool = False\nprint_interval: int = -1\nsave_interval: int = -1\ndef __init__(self, *args, **kwargs):\nself.run_name = defaults.DEFAULT_RUN_NAME\nself.experiment_id = defaults.DEFAULT_EXPERIMENT_ID\nself.experiment_name = defaults.DEFAULT_EXPERIMENT_NAME\nif Repo is not None:\ntry:\nself.experiment_id = Repo(search_parent_directories=True).head.object.hexsha\nexcept ImportError:\nwarn(\"GitPython is not installed, using default experiment id.\")\nexcept InvalidGitRepositoryError:\npath = os.path.dirname(os.path.abspath(sys.argv[0]))\nwarn(\"CWD is not under a git repo, fallback to top-level code environment.\")\ntry:\nself.experiment_id = Repo(path=path, search_parent_directories=True).head.object.hexsha\nexcept InvalidGitRepositoryError:\nwarn(\"Top-level code environment is not under a git repo, using default experiment id.\")\nelse:\nwarn(\"GitPython is not installed, using default experiment id.\")\nself.deterministic = False\nself.seed = randint(0, 2**32 - 1)\nself.iters = 0\nself.steps = 0\nself.epochs = 0\nself.results = []\nself.index_set = None\nself.index = \"loss\"\nsuper().__init__(*args, **kwargs)\nself.run_id = self.run_uuid.hex\ntime = datetime.now()\ntime_tuple = time.isocalendar()[1:] + (time.hour, time.minute, time.second, time.microsecond)\ntime_str = \"\".join(base62.encode(i) for i in time_tuple)\nself.id = f\"{time_str}{self.experiment_id:.5}{self.run_id:.4}\"  # pylint: disable=C0103\nself.name = f\"{self.experiment_name}-{self.run_name}\"\nself.setattr(\"ignored_keys_in_hash\", defaults.DEFAULT_IGNORED_KEYS_IN_HASH)\n@property\ndef experiment_uuid(self) -&gt; UUID:\nr\"\"\"\n        UUID of the experiment.\n        \"\"\"\nreturn UUID(bytes=bytes(self.experiment_id.ljust(16, \"x\")[:16], encoding=\"ascii\"))\n@property\ndef run_uuid(self) -&gt; UUID:\nr\"\"\"\n        UUID of the run.\n        \"\"\"\nreturn uuid5(self.experiment_uuid, str(hash(self)))\n@property\ndef uuid(self) -&gt; UUID:\nr\"\"\"\n        UUID of the state.\n        \"\"\"\nreturn uuid5(self.run_uuid, self.id)\ndef __hash__(self) -&gt; int:\nignored_keys_in_hash = self.getattr(\"ignored_keys_in_hash\", defaults.DEFAULT_IGNORED_KEYS_IN_HASH)\nstate = NestedDict({k: v for k, v in self.dict().items() if k not in ignored_keys_in_hash})\nreturn hash(state.yamls())\n</code></pre>"},{"location":"zh/#introduction","title":"Introduction","text":"<p>DanLing (\u4e39\u7075) is a high-level library to help with running neural networks flexibly and transparently.</p> <p>DanLing is meant to be a scaffold for experienced researchers and engineers who know how to define a training loop, but are bored of writing the same boilerplate code, such as DDP, logging, checkpointing, etc., over and over again.</p> <p>Therefore, DanLing does not feature complex Runner designs with many pre-defined methods and complicated hooks. Instead, the Runner of DanLing just initialise the essential parts for you, and you can do whatever you want, however you want.</p> <p>Although many attributes and properties are pre-defined and are expected to be used in DanLing, you have full control over your code.</p> <p>DanLing also provides some utilities, such as [Registry][danling.Registry], [NestedTensor][danling.NestedTensor], [catch][danling.utils.catch], etc.</p>"},{"location":"zh/package/#danling.runner.base_runner.BaseRunner.load_checkpoint","title":"<code>load_checkpoint(checkpoint=None, override_state=False, *args, **kwargs)</code>","text":"<p>Load info from checkpoint.</p> <p>Parameters:</p> Name Type Description Default <code>checkpoint</code> <code>Optional[Union[Mapping, str]]</code> <p>Checkpoint (or its path) to load. Defaults to <code>self.checkpoint_dir/latest.pth</code>.</p> <code>None</code> <code>override_state</code> <code>bool</code> <p>If True, override runner state with checkpoint state. Defaults to <code>False</code>.</p> <code>False</code> <code>*args</code> <p>Additional arguments to pass to <code>self.load</code>.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to <code>self.load</code>.</p> <code>{}</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If <code>checkpoint</code> does not exists.</p> See Also <p>[<code>from_checkpoint</code>][danling.BaseRunner.from_checkpoint]: Build runner from checkpoint. [<code>load_pretrained</code>][danling.BaseRunner.load_pretrained]: Load parameters from pretrained checkpoint.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>def load_checkpoint(  # pylint: disable=W1113\nself, checkpoint: Optional[Union[Mapping, str]] = None, override_state: bool = False, *args, **kwargs\n) -&gt; None:\n\"\"\"\n    Load info from checkpoint.\n    Args:\n        checkpoint: Checkpoint (or its path) to load.\n            Defaults to `self.checkpoint_dir/latest.pth`.\n        override_state: If True, override runner state with checkpoint state.\n            Defaults to `False`.\n        *args: Additional arguments to pass to `self.load`.\n        **kwargs: Additional keyword arguments to pass to `self.load`.\n    Raises:\n        FileNotFoundError: If `checkpoint` does not exists.\n    See Also:\n        [`from_checkpoint`][danling.BaseRunner.from_checkpoint]: Build runner from checkpoint.\n        [`load_pretrained`][danling.BaseRunner.load_pretrained]: Load parameters from pretrained checkpoint.\n    \"\"\"\nif checkpoint is None:\ncheckpoint = os.path.join(self.checkpoint_dir, \"latest.pth\")  # type: ignore\n# TODO: Support loading checkpoints in other format\nif isinstance(checkpoint, str):\nif not os.path.exists(checkpoint):\nraise FileNotFoundError(f\"checkpoint is set to {checkpoint} but does not exist.\")\nself.checkpoint = checkpoint  # pylint: disable=W0201\ncheckpoint: Mapping = self.load(checkpoint, *args, **kwargs)  # type: ignore\n# TODO: Wrap state_dict in a dataclass\nif override_state:\nself.__dict__.update(NestedDict(**checkpoint[\"runner\"]))  # type: ignore\nif self.model is not None and \"model\" in checkpoint:\nmodel = self.unwrap_model(self.model)\nmodel.load_state_dict(checkpoint[\"model\"])  # type: ignore\nif self.optimizer is not None and \"optimizer\" in checkpoint:\nself.optimizer.load_state_dict(checkpoint[\"optimizer\"])  # type: ignore\nif self.scheduler is not None and \"scheduler\" in checkpoint:\nself.scheduler.load_state_dict(checkpoint[\"scheduler\"])  # type: ignore\n</code></pre>"},{"location":"zh/package/#danling.runner.base_runner.BaseRunner.load_pretrained","title":"<code>load_pretrained(checkpoint, *args, **kwargs)</code>","text":"<p>Load parameters from pretrained checkpoint.</p> <p>Parameters:</p> Name Type Description Default <code>checkpoint</code> <code>Union[Mapping, str]</code> <p>Pretrained checkpoint (or its path) to load.</p> required <code>*args</code> <p>Additional arguments to pass to <code>self.load</code>.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to <code>self.load</code>.</p> <code>{}</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If <code>checkpoint</code> does not exists.</p> See Also <p>[<code>load_checkpoint</code>][danling.BaseRunner.load_checkpoint]: Load info from checkpoint.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>def load_pretrained(self, checkpoint: Union[Mapping, str], *args, **kwargs) -&gt; None:\n\"\"\"\n    Load parameters from pretrained checkpoint.\n    Args:\n        checkpoint: Pretrained checkpoint (or its path) to load.\n        *args: Additional arguments to pass to `self.load`.\n        **kwargs: Additional keyword arguments to pass to `self.load`.\n    Raises:\n        FileNotFoundError: If `checkpoint` does not exists.\n    See Also:\n        [`load_checkpoint`][danling.BaseRunner.load_checkpoint]: Load info from checkpoint.\n    \"\"\"\n# TODO: Support loading checkpoints in other format\nif isinstance(checkpoint, str):\nif not os.path.exists(checkpoint):\nraise FileNotFoundError(f\"pretrained is set to {checkpoint} but does not exist.\")\ncheckpoint: Mapping = self.load(checkpoint, *args, **kwargs)  # type: ignore\nif \"model\" in checkpoint:\ncheckpoint = checkpoint[\"model\"]  # type: ignore\nif \"state_dict\" in checkpoint:\ncheckpoint = checkpoint[\"state_dict\"]  # type: ignore\nmodel = self.unwrap_model(self.model)\nmodel.load_state_dict(checkpoint)  # type: ignore\n</code></pre>"},{"location":"zh/runner/#runnerstatedanlingrunnerrunner_staterunnerstate","title":"[<code>RunnerState</code>][danling.runner.runner_state.RunnerState]","text":"<p>[<code>RunnerState</code>][danling.runner.runner_state.RunnerState] stores the state of a run.</p> <p>All attributes stored in <code>RunnerState</code> will be saved in the checkpoint, and thus should be json serialisable. Except for <code>@property</code> of json serialisable attributes.</p>"},{"location":"zh/runner/#runnerbasedanlingrunnerrunner_baserunnerbase","title":"[<code>RunnerBase</code>][danling.runner.runner_base.RunnerBase]","text":"<p>[<code>RunnerBase</code>][danling.runner.abstract_base_runner.RunnerBase] gives you a basic instinct on what attributes and properties are provided by the Runner.</p> <p>It works in an AbstractBaseClass manner and should neither be used directly nor be inherited from.</p>"},{"location":"zh/runner/#baserunnerdanlingrunnerbaserunner","title":"[<code>BaseRunner</code>][danling.runner.BaseRunner]","text":"<p>[<code>BaseRunner</code>][danling.runner.BaseRunner] contains core methods of general basic functionality, such as <code>init_logging</code>, <code>append_result</code>, <code>print_result</code>.</p>"},{"location":"zh/runner/#runnerdanlingrunnertorchrunner","title":"[<code>Runner</code>][danling.runner.TorchRunner]","text":"<p>[<code>Runner</code>][danling.runner.TorchRunner] should only contain platform-specific features. Currently, only [<code>TorchRunner</code>][danling.runner.TorchRunner] is supported.</p>"},{"location":"zh/runner/base_runner/#danling.runner.base_runner.BaseRunner.load_checkpoint","title":"<code>load_checkpoint(checkpoint=None, override_state=False, *args, **kwargs)</code>","text":"<p>Load info from checkpoint.</p> <p>Parameters:</p> Name Type Description Default <code>checkpoint</code> <code>Optional[Union[Mapping, str]]</code> <p>Checkpoint (or its path) to load. Defaults to <code>self.checkpoint_dir/latest.pth</code>.</p> <code>None</code> <code>override_state</code> <code>bool</code> <p>If True, override runner state with checkpoint state. Defaults to <code>False</code>.</p> <code>False</code> <code>*args</code> <p>Additional arguments to pass to <code>self.load</code>.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to <code>self.load</code>.</p> <code>{}</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If <code>checkpoint</code> does not exists.</p> See Also <p>[<code>from_checkpoint</code>][danling.BaseRunner.from_checkpoint]: Build runner from checkpoint. [<code>load_pretrained</code>][danling.BaseRunner.load_pretrained]: Load parameters from pretrained checkpoint.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>def load_checkpoint(  # pylint: disable=W1113\nself, checkpoint: Optional[Union[Mapping, str]] = None, override_state: bool = False, *args, **kwargs\n) -&gt; None:\n\"\"\"\n    Load info from checkpoint.\n    Args:\n        checkpoint: Checkpoint (or its path) to load.\n            Defaults to `self.checkpoint_dir/latest.pth`.\n        override_state: If True, override runner state with checkpoint state.\n            Defaults to `False`.\n        *args: Additional arguments to pass to `self.load`.\n        **kwargs: Additional keyword arguments to pass to `self.load`.\n    Raises:\n        FileNotFoundError: If `checkpoint` does not exists.\n    See Also:\n        [`from_checkpoint`][danling.BaseRunner.from_checkpoint]: Build runner from checkpoint.\n        [`load_pretrained`][danling.BaseRunner.load_pretrained]: Load parameters from pretrained checkpoint.\n    \"\"\"\nif checkpoint is None:\ncheckpoint = os.path.join(self.checkpoint_dir, \"latest.pth\")  # type: ignore\n# TODO: Support loading checkpoints in other format\nif isinstance(checkpoint, str):\nif not os.path.exists(checkpoint):\nraise FileNotFoundError(f\"checkpoint is set to {checkpoint} but does not exist.\")\nself.checkpoint = checkpoint  # pylint: disable=W0201\ncheckpoint: Mapping = self.load(checkpoint, *args, **kwargs)  # type: ignore\n# TODO: Wrap state_dict in a dataclass\nif override_state:\nself.__dict__.update(NestedDict(**checkpoint[\"runner\"]))  # type: ignore\nif self.model is not None and \"model\" in checkpoint:\nmodel = self.unwrap_model(self.model)\nmodel.load_state_dict(checkpoint[\"model\"])  # type: ignore\nif self.optimizer is not None and \"optimizer\" in checkpoint:\nself.optimizer.load_state_dict(checkpoint[\"optimizer\"])  # type: ignore\nif self.scheduler is not None and \"scheduler\" in checkpoint:\nself.scheduler.load_state_dict(checkpoint[\"scheduler\"])  # type: ignore\n</code></pre>"},{"location":"zh/runner/base_runner/#danling.runner.base_runner.BaseRunner.load_pretrained","title":"<code>load_pretrained(checkpoint, *args, **kwargs)</code>","text":"<p>Load parameters from pretrained checkpoint.</p> <p>Parameters:</p> Name Type Description Default <code>checkpoint</code> <code>Union[Mapping, str]</code> <p>Pretrained checkpoint (or its path) to load.</p> required <code>*args</code> <p>Additional arguments to pass to <code>self.load</code>.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to <code>self.load</code>.</p> <code>{}</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If <code>checkpoint</code> does not exists.</p> See Also <p>[<code>load_checkpoint</code>][danling.BaseRunner.load_checkpoint]: Load info from checkpoint.</p> Source code in <code>danling/runner/base_runner.py</code> Python<pre><code>def load_pretrained(self, checkpoint: Union[Mapping, str], *args, **kwargs) -&gt; None:\n\"\"\"\n    Load parameters from pretrained checkpoint.\n    Args:\n        checkpoint: Pretrained checkpoint (or its path) to load.\n        *args: Additional arguments to pass to `self.load`.\n        **kwargs: Additional keyword arguments to pass to `self.load`.\n    Raises:\n        FileNotFoundError: If `checkpoint` does not exists.\n    See Also:\n        [`load_checkpoint`][danling.BaseRunner.load_checkpoint]: Load info from checkpoint.\n    \"\"\"\n# TODO: Support loading checkpoints in other format\nif isinstance(checkpoint, str):\nif not os.path.exists(checkpoint):\nraise FileNotFoundError(f\"pretrained is set to {checkpoint} but does not exist.\")\ncheckpoint: Mapping = self.load(checkpoint, *args, **kwargs)  # type: ignore\nif \"model\" in checkpoint:\ncheckpoint = checkpoint[\"model\"]  # type: ignore\nif \"state_dict\" in checkpoint:\ncheckpoint = checkpoint[\"state_dict\"]  # type: ignore\nmodel = self.unwrap_model(self.model)\nmodel.load_state_dict(checkpoint)  # type: ignore\n</code></pre>"},{"location":"zh/runner/runner_base/","title":"RunnerBase","text":"<p>Base class for all runners.</p> <p><code>RunnerBase</code> is designed as a \u201cdataclass\u201d.</p> <p>It defines all basic attributes and relevant properties such as <code>scores</code>, <code>progress</code>, etc.</p> <p><code>RunnerBase</code> also defines basic IO operations such as <code>save</code>, <code>load</code>, <code>json</code>, <code>yaml</code>, etc.</p> <p>Model:</p> Name Type Description <code>model</code> <code>Callable</code> <code>criterion</code> <code>Callable</code> <code>optimizer</code> <code>Optional[Any]</code> <code>scheduler</code> <code>Optional[Any]</code> <p>Data:</p> Name Type Description <code>datasets</code> <code>FlatDict</code> <p>All datasets, should be in the form of <code>{subset: dataset}</code>.</p> <code>datasamplers</code> <code>FlatDict</code> <p>All datasamplers, should be in the form of <code>{subset: datasampler}</code>.</p> <code>dataloaders</code> <code>FlatDict</code> <p>All dataloaders, should be in the form of <code>{subset: dataloader}</code>.</p> <code>batch_size</code> <code>int, property</code> <p>Number of samples per batch in train dataloader or the first dataloader.</p> <code>batch_size_equivalent</code> <code>int, property</code> <p>Total batch_size (<code>batch_size * world_size * accum_steps</code>).</p> <p><code>datasets</code>, <code>datasamplers</code>, <code>dataloaders</code> should be a dict with the same keys. Their keys should be <code>split</code> (e.g. <code>train</code>, <code>val</code>, <code>test</code>).</p> <p>Progress:</p> Name Type Description <code>progress</code> <code>float, property</code> <p>Running Progress, in <code>range(0, 1)</code>.</p> <p>Results:</p> Name Type Description <code>latest_result</code> <code>NestedDict, property</code> <p>Most recent results, should be in the form of <code>{subset: {index: score}}</code>.</p> <code>best_result</code> <code>NestedDict, property</code> <p>Best recent results, should be in the form of <code>{subset: {index: score}}</code>.</p> <code>scores</code> <code>List[float], property</code> <p>All scores.</p> <code>latest_score</code> <code>float, property</code> <p>Most recent score.</p> <code>best_score</code> <code>float, property</code> <p>Best score.</p> <code>index_set</code> <code>Optional[str]</code> <p>The subset to calculate the core score. If is <code>None</code>, will use the last set of the result.</p> <code>index</code> <code>str</code> <p>The index to calculate the core score. Defaults to <code>\"loss\"</code>.</p> <code>is_best</code> <code>bool, property</code> <p>If <code>latest_score == best_score</code>.</p> <p>IO:</p> Name Type Description <code>dir</code> <code>str, property</code> <p>Directory of the run. Defaults to <code>os.path.join(self.project_root, f\"{self.name}-{self.id}\")</code>.</p> <code>checkpoint_dir</code> <code>str, property</code> <p>Directory of checkpoints.</p> <code>log_path</code> <code>str, property</code> <p>Path of log file.</p> <code>checkpoint_dir_name</code> <code>str</code> <p>The name of the directory under <code>runner.dir</code> to save checkpoints. Defaults to <code>\"checkpoints\"</code>.</p> <p>Parallel Training:</p> Name Type Description <code>world_size</code> <code>int, property</code> <p>Number of processes.</p> <code>rank</code> <code>int, property</code> <p>Process index of all processes.</p> <code>local_rank</code> <code>int, property</code> <p>Process index of local processes.</p> <code>distributed</code> <code>bool, property</code> <p>If runner is running in distributed mode.</p> <code>is_main_process</code> <code>bool, property</code> <p>If current process is the main process of all processes.</p> <code>is_local_main_process</code> <code>bool, property</code> <p>If current process is the main process of local processes.</p> <p>logging:</p> Name Type Description <code>logger</code> <code>Optional[logging.Logger]</code> <code>writer</code> <code>Optional[Any]</code> Notes <p>The <code>RunnerBase</code> class is not intended to be used directly, nor to be directly inherit from.</p> <p>This is because <code>RunnerBase</code> is designed as a \u201cdataclass\u201d, and is meant for demonstrating all attributes and properties only.</p> See Also <p>[<code>RunnerState</code>][danling.runner.runner_state.RunnerState]: The runeer base that stores runtime information. [<code>BaseRunner</code>][danling.runner.BaseRunner]: The base runner class.</p> Source code in <code>danling/runner/runner_base.py</code> Python<pre><code>class RunnerBase:\nr\"\"\"\n    Base class for all runners.\n    `RunnerBase` is designed as a \"dataclass\".\n    It defines all basic attributes and relevant properties such as `scores`, `progress`, etc.\n    `RunnerBase` also defines basic IO operations such as `save`, `load`, `json`, `yaml`, etc.\n    Attributes: Model:\n        model (Callable):\n        criterion (Callable):\n        optimizer:\n        scheduler:\n    Attributes: Data:\n        datasets (FlatDict): All datasets, should be in the form of ``{subset: dataset}``.\n        datasamplers (FlatDict): All datasamplers, should be in the form of ``{subset: datasampler}``.\n        dataloaders (FlatDict): All dataloaders, should be in the form of ``{subset: dataloader}``.\n        batch_size (int, property): Number of samples per batch in train dataloader or the first dataloader.\n        batch_size_equivalent (int, property): Total batch_size (`batch_size * world_size * accum_steps`).\n    `datasets`, `datasamplers`, `dataloaders` should be a dict with the same keys.\n    Their keys should be `split` (e.g. `train`, `val`, `test`).\n    Attributes: Progress:\n        progress (float, property): Running Progress, in `range(0, 1)`.\n    Attributes: Results:\n        latest_result (NestedDict, property): Most recent results,\n            should be in the form of ``{subset: {index: score}}``.\n        best_result (NestedDict, property): Best recent results, should be in the form of ``{subset: {index: score}}``.\n        scores (List[float], property): All scores.\n        latest_score (float, property): Most recent score.\n        best_score (float, property): Best score.\n        index_set (Optional[str]): The subset to calculate the core score.\n            If is `None`, will use the last set of the result.\n        index (str): The index to calculate the core score.\n            Defaults to `\"loss\"`.\n        is_best (bool, property): If `latest_score == best_score`.\n    Attributes: IO:\n        dir (str, property): Directory of the run.\n            Defaults to `os.path.join(self.project_root, f\"{self.name}-{self.id}\")`.\n        checkpoint_dir (str, property): Directory of checkpoints.\n        log_path (str, property):  Path of log file.\n        checkpoint_dir_name (str): The name of the directory under `runner.dir` to save checkpoints.\n            Defaults to `\"checkpoints\"`.\n    Attributes: Parallel Training:\n        world_size (int, property): Number of processes.\n        rank (int, property): Process index of all processes.\n        local_rank (int, property): Process index of local processes.\n        distributed (bool, property): If runner is running in distributed mode.\n        is_main_process (bool, property): If current process is the main process of all processes.\n        is_local_main_process (bool, property): If current process is the main process of local processes.\n    Attributes: logging:\n        logger:\n        writer:\n    Notes:\n        The `RunnerBase` class is not intended to be used directly, nor to be directly inherit from.\n        This is because `RunnerBase` is designed as a \"dataclass\",\n        and is meant for demonstrating all attributes and properties only.\n    See Also:\n        [`RunnerState`][danling.runner.runner_state.RunnerState]: The runeer base that stores runtime information.\n        [`BaseRunner`][danling.runner.BaseRunner]: The base runner class.\n    \"\"\"\n# pylint: disable=R0902, R0904\n# DO NOT set default value in class, as they won't be stored in `__dict__`.\nstate: RunnerState\nmodel: Optional[Callable] = None\ncriterion: Optional[Callable] = None\noptimizer: Optional[Any] = None\nscheduler: Optional[Any] = None\ndatasets: FlatDict\ndatasamplers: FlatDict\ndataloaders: FlatDict\nmeters: Optional[AverageMeters] = None\nlogger: Optional[logging.Logger] = None\nwriter: Optional[Any] = None\ndef __init__(self, *args, **kwargs):\nsuper().__init__()\nself.state = RunnerState(*args, **kwargs)\nself.meters = AverageMeters()\nself.datasets = FlatDict()\nself.datasamplers = FlatDict()\nself.dataloaders = FlatDict()\n@property\ndef batch_size(self) -&gt; int:\nr\"\"\"\n        Batch size.\n        Notes:\n            If `train` is in `dataloaders`, then `batch_size` is the batch size of `train`.\n            Otherwise, `batch_size` is the batch size of the first dataloader.\n        Returns:\n            (int):\n        \"\"\"\nif self.dataloaders:\nloader = self.dataloaders[\"train\"] if \"train\" in self.dataloaders else next(iter(self.dataloaders.values()))\nreturn loader.batch_size\nraise AttributeError(\"batch_size could not be inferred, since no dataloaedr found.\")\n@property\ndef batch_size_equivalent(self) -&gt; int:\nr\"\"\"\n        Actual batch size.\n        Returns:\n            (int): `batch_size` * `world_size` * `accum_steps`\n        \"\"\"\nreturn self.batch_size * self.world_size * getattr(self, \"accum_steps\", 1)\n@property\ndef accum_steps(self) -&gt; int:\nr\"\"\"\n        Accumulated steps.\n        Returns:\n            (int):\n        \"\"\"\nraise AttributeError(\"accum_steps is not defined.\")\n@property\ndef device(self) -&gt; Any:\nr\"\"\"\n        Device of runner.\n        \"\"\"\nraise NotImplementedError\n@property\ndef world_size(self) -&gt; int:\nr\"\"\"\n        Number of processes.\n        \"\"\"\nreturn 1\n@property\ndef rank(self) -&gt; int:\nr\"\"\"\n        Process index of all processes.\n        \"\"\"\nreturn 0\n@property\ndef local_rank(self) -&gt; int:\nr\"\"\"\n        Process index of local processes.\n        \"\"\"\nreturn 0\n@property\ndef distributed(self) -&gt; bool:\nr\"\"\"\n        If runner is running in distributed mode.\n        \"\"\"\nreturn self.world_size &gt; 1\n@property\ndef is_main_process(self) -&gt; bool:\nr\"\"\"\n        If current process is the main process of all processes.\n        \"\"\"\nreturn self.rank == 0\n@property\ndef is_local_main_process(self) -&gt; bool:\nr\"\"\"\n        If current process is the main process of local processes.\n        \"\"\"\nreturn self.local_rank == 0\n@catch\ndef save(  # pylint: disable=W1113\nself, obj: Any, file: PathStr, main_process_only: bool = True, *args, **kwargs\n) -&gt; File:\nr\"\"\"\n        Save any file with supported extensions.\n        `Runner.save` internally calls `dl.save`,\n        but with additional arguments to allow it save only on the main process.\n        Moreover, any error raised by `Runner.save` will be caught and logged.\n        \"\"\"\nif main_process_only and self.is_main_process or not main_process_only:\nreturn save(obj, file, *args, **kwargs)\nreturn file\n@staticmethod\ndef load(file: PathStr, *args, **kwargs) -&gt; Any:  # pylint: disable=C0103\nr\"\"\"\n        Load any file with supported extensions.\n        `Runner.load` is identical to `dl.save`.\n        \"\"\"\nreturn load(file, *args, **kwargs)\ndef dict(self, cls: Callable = dict) -&gt; Mapping:\nr\"\"\"\n        Convert state to Mapping.\n        Args:\n            cls: Target `clc to convert to.\n        \"\"\"\n# pylint: disable=C0103\nreturn self.state.dict(cls)\n@catch\ndef json(self, file: File, main_process_only: bool = True, *args, **kwargs) -&gt; None:  # pylint: disable=W1113\nr\"\"\"\n        Dump Runner State to json file.\n        \"\"\"\nif main_process_only and self.is_main_process or not main_process_only:\nreturn self.state.json(file, *args, **kwargs)\n@classmethod\ndef from_json(cls, file: File, *args, **kwargs) -&gt; RunnerBase:\nr\"\"\"\n        Construct Runner from json file.\n        This function calls `self.from_jsons()` to construct object from json string.\n        You may overwrite `from_jsons` in case something is not json serializable.\n        \"\"\"\nwith FlatDict.open(file) as fp:  # pylint: disable=C0103\nreturn cls.from_jsons(fp.read(), *args, **kwargs)\ndef jsons(self, *args, **kwargs) -&gt; str:\nr\"\"\"\n        Dump Runner State to json string.\n        \"\"\"\nreturn self.state.jsons(*args, **kwargs)\n@classmethod\ndef from_jsons(cls, string: str, *args, **kwargs) -&gt; RunnerBase:\nr\"\"\"\n        Construct Runner from json string.\n        \"\"\"\nreturn cls(Config.from_jsons(string, *args, **kwargs))\n@catch\ndef yaml(self, file: File, main_process_only: bool = True, *args, **kwargs) -&gt; None:  # pylint: disable=W1113\nr\"\"\"\n        Dump Runner State to yaml file.\n        \"\"\"\nif main_process_only and self.is_main_process or not main_process_only:\nreturn self.state.yaml(file, *args, **kwargs)\n@classmethod\ndef from_yaml(cls, file: File, *args, **kwargs) -&gt; RunnerBase:\nr\"\"\"\n        Construct Runner from yaml file.\n        This function calls `self.from_yamls()` to construct object from yaml string.\n        You may overwrite `from_yamls` in case something is not yaml serializable.\n        \"\"\"\nwith FlatDict.open(file) as fp:  # pylint: disable=C0103\nreturn cls.from_yamls(fp.read(), *args, **kwargs)\ndef yamls(self, *args, **kwargs) -&gt; str:\nr\"\"\"\n        Dump Runner State to yaml string.\n        \"\"\"\nreturn self.state.yamls(*args, **kwargs)\n@classmethod\ndef from_yamls(cls, string: str, *args, **kwargs) -&gt; RunnerBase:\nr\"\"\"\n        Construct Runner from yaml string.\n        \"\"\"\nreturn cls(Config.from_yamls(string, *args, **kwargs))\n@property\ndef progress(self) -&gt; float:\nr\"\"\"\n        Training Progress.\n        Returns:\n            (float):\n        Raises:\n            RuntimeError: If no terminal is defined.\n        \"\"\"\nif hasattr(self.state, \"iter_end\"):\nreturn self.state.iters / self.state.iter_end\nif hasattr(self.state, \"step_end\"):\nreturn self.state.steps / self.state.step_end\nif hasattr(self.state, \"epoch_end\"):\nreturn self.state.epochs / self.state.epoch_end\nraise RuntimeError(\"DanLing cannot determine progress since no terminal is defined.\")\n@property\ndef best_fn(self) -&gt; Callable:  # pylint: disable=C0103\nr\"\"\"\n        Function to determine the best score from a list of scores.\n        Subclass can override this method to accommodate needs, such as `min`.\n        Returns:\n            (callable): `max`\n        \"\"\"\nreturn max\n@property\ndef latest_result(self) -&gt; Optional[NestedDict]:\nr\"\"\"\n        Latest result.\n        \"\"\"\nreturn self.state.results[-1] if self.state.results else None\n@property\ndef best_result(self) -&gt; Optional[NestedDict]:\nr\"\"\"\n        Best result.\n        \"\"\"\nif not self.state.results:\nreturn None\nreturn self.state.results[-1 - self.scores[::-1].index(self.best_score)]  # type: ignore\n@property\ndef scores(self) -&gt; List[float]:\nr\"\"\"\n        All scores.\n        Scores are extracted from results by `index_set` and `runner.index`,\n        following `[r[index_set][self.state.index] for r in self.state.results]`.\n        By default, `index_set` points to `self.state.index_set` and is set to `val`,\n        if `self.state.index_set` is not set, it will be the last key of the last result.\n        Scores are considered as the index of the performance of the model.\n        It is useful to determine the best model and the best hyper-parameters.\n        \"\"\"\nif not self.state.results:\nreturn []\nindex_set = self.state.index_set or next(reversed(self.state.results[-1]))\nreturn [r[index_set][self.state.index] for r in self.state.results]\n@property\ndef latest_score(self) -&gt; Optional[float]:\nr\"\"\"\n        Latest score.\n        \"\"\"\nreturn self.scores[-1] if self.state.results else None\n@property\ndef best_score(self) -&gt; Optional[float]:\nr\"\"\"\n        Best score.\n        \"\"\"\nreturn self.best_fn(self.scores) if self.results else None\n@property\ndef is_best(self) -&gt; bool:\nr\"\"\"\n        If current epoch is the best epoch.\n        \"\"\"\ntry:\nreturn abs(self.latest_score - self.best_score) &lt; 1e-7  # type: ignore\nexcept TypeError:\nreturn True\n@property  # type: ignore\n@ensure_dir\ndef dir(self) -&gt; str:\nr\"\"\"\n        Directory of the run.\n        \"\"\"\nreturn os.path.join(self.project_root, f\"{self.name}-{self.id}\")\n@property\ndef log_path(self) -&gt; str:\nr\"\"\"\n        Path of log file.\n        \"\"\"\nreturn os.path.join(self.dir, \"run.log\")\n@property  # type: ignore\n@ensure_dir\ndef checkpoint_dir(self) -&gt; str:\nr\"\"\"\n        Directory of checkpoints.\n        \"\"\"\nreturn os.path.join(self.dir, self.checkpoint_dir_name)\ndef __getattr__(self, name) -&gt; Any:\nif \"state\" not in self:\nraise RuntimeError(\"Runner is not initialised yet.\")\nif name in self.state:\nreturn self.state[name]\nif name in dir(self.state):\nreturn getattr(self.state, name)\nraise super().__getattribute__(name)\ndef __setattr__(self, name, value) -&gt; None:\nif name in self.__dict__ and isinstance(self.__dict__[name], Variable):\nself.__dict__[name].set(value)\nelse:\nself.__dict__[name] = value\ndef __contains__(self, name) -&gt; bool:\nreturn name in self.__dict__\ndef __repr__(self):\nlines = []\nfor key, value in self.__dict__.items():\nvalue_str = repr(value)\nvalue_str = self._add_indent(value_str)\nlines.append(\"(\" + key + \"): \" + value_str)\nmain_str = self.__class__.__name__ + \"(\"\nif lines:\nmain_str += \"\\n  \" + \"\\n  \".join(lines) + \"\\n\"\nmain_str += \")\"\nreturn main_str\ndef _add_indent(self, text):\nlines = text.split(\"\\n\")\n# don't do anything for single-line stuff\nif len(lines) == 1:\nreturn text\nfirst = lines.pop(0)\n# add 2 spaces to each line but the first\nlines = [(2 * \" \") + line for line in lines]\nlines = \"\\n\".join(lines)\nlines = first + \"\\n\" + lines\nreturn lines\n</code></pre>"},{"location":"zh/runner/runner_state/","title":"RunnerState","text":"<p>         Bases: <code>NestedDict</code></p> <p><code>RunnerState</code> is a <code>NestedDict</code> that contains all states of a <code>Runner</code>.</p> <p><code>RunnerState</code> is designed to store all critical information of a Run so that you can resume a run from a state and corresponding weights or even restart a run from a state.</p> <p><code>RunnerState</code> is also designed to be serialisable and hashable, so that you can save it to a file. <code>RunnerState</code> is saved in checkpoint together with weights by default.</p> <p>Since <code>RunnerState</code> is a <code>NestedDict</code>, you can access its attributes by <code>state[\"key\"]</code> or <code>state.key</code>.</p> <p>General:</p> Name Type Description <code>id</code> <code>str</code> <p><code>f\"{self.experiment_id:.4}{self.run_id:.4}{time_str}\"</code>.</p> <code>uuid</code> <code>UUID, property</code> <p><code>uuid5(self.run_id, self.id)</code>.</p> <code>name</code> <code>str</code> <p><code>f\"{self.experiment_name}-{self.run_name}\"</code>.</p> <code>run_id</code> <code>str</code> <p>hex of <code>self.run_uuid</code>.</p> <code>run_uuid</code> <code>UUID, property</code> <p><code>uuid5(self.experiment_id, config.jsons())</code>.</p> <code>run_name</code> <code>str</code> <p>Defaults to <code>\"DanLing\"</code>.</p> <code>experiment_id</code> <code>str</code> <p>git hash of the current HEAD. Defaults to <code>\"xxxxxxxxxxxxxxxx\"</code> if Runner not under a git repo or git/gitpython not installed.</p> <code>experiment_uuid</code> <code>UUID, property</code> <p>UUID of <code>self.experiment_id</code>. Defaults to <code>UUID('78787878-7878-7878-7878-787878787878')</code> if Runner not under a git repo or git/gitpython not installed.</p> <code>experiment_name</code> <code>str</code> <p>Defaults to <code>\"DanLing\"</code>.</p> <code>seed</code> <code>int</code> <p>Defaults to <code>randint(0, 2**32 - 1)</code>.</p> <code>deterministic</code> <code>bool</code> <p>Ensure deterministic operations. Defaults to <code>False</code>.</p> <p>Progress:</p> Name Type Description <code>iters</code> <code>int</code> <p>The number of data samples processed. equals to <code>steps</code> when <code>batch_size = 1</code>.</p> <code>steps</code> <code>int</code> <p>The number of <code>step</code> calls.</p> <code>epochs</code> <code>int</code> <p>The number of complete passes over the datasets.</p> <code>iter_end</code> <code>int</code> <p>End running iters. Note that <code>step_end</code> not initialised since this variable may not apply to some Runners.</p> <code>step_end</code> <code>int</code> <p>End running steps. Note that <code>step_end</code> not initialised since this variable may not apply to some Runners.</p> <code>epoch_end</code> <code>int</code> <p>End running epochs. Note that <code>epoch_end</code> not initialised since this variable may not apply to some Runners.</p> <p>In general you should only use one of <code>iter_end</code>, <code>step_end</code>, <code>epoch_end</code> to indicate the length of running.</p> <p>Results:</p> Name Type Description <code>results</code> <code>List[NestedDict]</code> <p>All results, should be in the form of <code>[{subset: {index: score}}]</code>.</p> <p><code>results</code> should be a list of <code>result</code>. <code>result</code> should be a dict with the same <code>split</code> as keys, like <code>dataloaders</code>. A typical <code>result</code> might look like this: Python<pre><code>{\n\"train\": {\n\"loss\": 0.1,\n\"accuracy\": 0.9,\n},\n\"val\": {\n\"loss\": 0.2,\n\"accuracy\": 0.8,\n},\n\"test\": {\n\"loss\": 0.3,\n\"accuracy\": 0.7,\n},\n}\n</code></pre></p> <p><code>scores</code> are usually a list of <code>float</code>, and are dynamically extracted from <code>results</code> by <code>index_set</code> and <code>index</code>. If <code>index_set = \"val\"</code>, <code>index = \"accuracy\"</code>, then <code>scores = 0.9</code>.</p> <p>IO:</p> Name Type Description <code>project_root</code> <code>str</code> <p>The root directory for all experiments. Defaults to <code>\"experiments\"</code>.</p> <p><code>project_root</code> is the root directory of all Experiments, and should be consistent across the Project.</p> <p><code>dir</code> is the directory of a certain Run.</p> <p>There is no attributes/properties for Group and Experiment.</p> <p><code>checkpoint_dir_name</code> is relative to <code>dir</code>, and is passed to generate <code>checkpoint_dir</code> (<code>checkpoint_dir = os.path.join(dir, checkpoint_dir_name)</code>). In practice, <code>checkpoint_dir_name</code> is rarely called.</p> <p>logging:</p> Name Type Description <code>log</code> <code>bool</code> <p>Whether to log the outputs. Defaults to <code>True</code>.</p> <code>tensorboard</code> <code>bool</code> <p>Whether to use <code>tensorboard</code>. Defaults to <code>False</code>.</p> <code>print_interval</code> <code>int</code> <p>Interval of printing logs. Defaults to -1.</p> <code>save_interval</code> <code>int</code> <p>Interval of saving intermediate checkpoints. Defaults to -1, never save intermediate checkpoints.</p> Notes <p><code>RunnerState</code> is a <code>NestedDict</code>, so you can access its attributes by <code>state[\"name\"]</code> or <code>state.name</code>.</p> See Also <p>[<code>RunnerBase</code>][danling.runner.runner_base.RunnerBase]: The runeer state that stores critical information. [<code>BaseRunner</code>][danling.runner.BaseRunner]: The base runner class.</p> Source code in <code>danling/runner/runner_state.py</code> Python<pre><code>class RunnerState(NestedDict):\nr\"\"\"\n    `RunnerState` is a `NestedDict` that contains all states of a `Runner`.\n    `RunnerState` is designed to store all critical information of a Run so that you can resume a run\n    from a state and corresponding weights or even restart a run from a state.\n    `RunnerState` is also designed to be serialisable and hashable, so that you can save it to a file.\n    `RunnerState` is saved in checkpoint together with weights by default.\n    Since `RunnerState` is a `NestedDict`, you can access its attributes by `state[\"key\"]` or `state.key`.\n    Attributes: General:\n        id (str): `f\"{self.experiment_id:.4}{self.run_id:.4}{time_str}\"`.\n        uuid (UUID, property): `uuid5(self.run_id, self.id)`.\n        name (str): `f\"{self.experiment_name}-{self.run_name}\"`.\n        run_id (str): hex of `self.run_uuid`.\n        run_uuid (UUID, property): `uuid5(self.experiment_id, config.jsons())`.\n        run_name (str): Defaults to `\"DanLing\"`.\n        experiment_id (str): git hash of the current HEAD.\n            Defaults to `\"xxxxxxxxxxxxxxxx\"` if Runner not under a git repo or git/gitpython not installed.\n        experiment_uuid (UUID, property): UUID of `self.experiment_id`.\n            Defaults to `UUID('78787878-7878-7878-7878-787878787878')`\n            if Runner not under a git repo or git/gitpython not installed.\n        experiment_name (str): Defaults to `\"DanLing\"`.\n        seed (int): Defaults to `randint(0, 2**32 - 1)`.\n        deterministic (bool): Ensure [deterministic](https://pytorch.org/docs/stable/notes/randomness.html) operations.\n            Defaults to `False`.\n    Attributes: Progress:\n        iters (int): The number of data samples processed.\n            equals to `steps` when `batch_size = 1`.\n        steps (int): The number of `step` calls.\n        epochs (int): The number of complete passes over the datasets.\n        iter_end (int): End running iters.\n            Note that `step_end` not initialised since this variable may not apply to some Runners.\n        step_end (int): End running steps.\n            Note that `step_end` not initialised since this variable may not apply to some Runners.\n        epoch_end (int): End running epochs.\n            Note that `epoch_end` not initialised since this variable may not apply to some Runners.\n    In general you should only use one of `iter_end`, `step_end`, `epoch_end` to indicate the length of running.\n    Attributes: Results:\n        results (List[NestedDict]): All results, should be in the form of ``[{subset: {index: score}}]``.\n    `results` should be a list of `result`.\n    `result` should be a dict with the same `split` as keys, like `dataloaders`.\n    A typical `result` might look like this:\n    ```python\n    {\n        \"train\": {\n            \"loss\": 0.1,\n            \"accuracy\": 0.9,\n        },\n        \"val\": {\n            \"loss\": 0.2,\n            \"accuracy\": 0.8,\n        },\n        \"test\": {\n            \"loss\": 0.3,\n            \"accuracy\": 0.7,\n        },\n    }\n    ```\n    `scores` are usually a list of `float`, and are dynamically extracted from `results` by `index_set` and `index`.\n    If `index_set = \"val\"`, `index = \"accuracy\"`, then `scores = 0.9`.\n    Attributes: IO:\n        project_root (str): The root directory for all experiments.\n            Defaults to `\"experiments\"`.\n    `project_root` is the root directory of all **Experiments**, and should be consistent across the **Project**.\n    `dir` is the directory of a certain **Run**.\n    There is no attributes/properties for **Group** and **Experiment**.\n    `checkpoint_dir_name` is relative to `dir`, and is passed to generate `checkpoint_dir`\n    (`checkpoint_dir = os.path.join(dir, checkpoint_dir_name)`).\n    In practice, `checkpoint_dir_name` is rarely called.\n    Attributes: logging:\n        log (bool): Whether to log the outputs.\n            Defaults to `True`.\n        tensorboard (bool): Whether to use `tensorboard`.\n            Defaults to `False`.\n        print_interval (int): Interval of printing logs.\n            Defaults to -1.\n        save_interval (int): Interval of saving intermediate checkpoints.\n            Defaults to -1, never save intermediate checkpoints.\n    Notes:\n        `RunnerState` is a `NestedDict`, so you can access its attributes by `state[\"name\"]` or `state.name`.\n    See Also:\n        [`RunnerBase`][danling.runner.runner_base.RunnerBase]: The runeer state that stores critical information.\n        [`BaseRunner`][danling.runner.BaseRunner]: The base runner class.\n    \"\"\"\n# pylint: disable=R0902, R0904\n# DO NOT set default value in class, as they won't be stored in `__dict__`.\nid: str\nname: str\nrun_id: str\nrun_name: str\nexperiment_id: str\nexperiment_name: str\nseed: int\ndeterministic: bool\niters: int\nsteps: int\nepochs: int\n# iter_begin: int  # Deprecated\n# step_begin: int  # Deprecated\n# epoch_begin: int  # Deprecated\niter_end: int\nstep_end: int\nepoch_end: int\nresults: List[NestedDict]\nindex_set: Optional[str]\nindex: str\nproject_root: str = \"experiments\"\ncheckpoint_dir_name: str = \"checkpoints\"\nlog: bool = True\ntensorboard: bool = False\nprint_interval: int = -1\nsave_interval: int = -1\ndef __init__(self, *args, **kwargs):\nself.run_name = defaults.DEFAULT_RUN_NAME\nself.experiment_id = defaults.DEFAULT_EXPERIMENT_ID\nself.experiment_name = defaults.DEFAULT_EXPERIMENT_NAME\nif Repo is not None:\ntry:\nself.experiment_id = Repo(search_parent_directories=True).head.object.hexsha\nexcept ImportError:\nwarn(\"GitPython is not installed, using default experiment id.\")\nexcept InvalidGitRepositoryError:\npath = os.path.dirname(os.path.abspath(sys.argv[0]))\nwarn(\"CWD is not under a git repo, fallback to top-level code environment.\")\ntry:\nself.experiment_id = Repo(path=path, search_parent_directories=True).head.object.hexsha\nexcept InvalidGitRepositoryError:\nwarn(\"Top-level code environment is not under a git repo, using default experiment id.\")\nelse:\nwarn(\"GitPython is not installed, using default experiment id.\")\nself.deterministic = False\nself.seed = randint(0, 2**32 - 1)\nself.iters = 0\nself.steps = 0\nself.epochs = 0\nself.results = []\nself.index_set = None\nself.index = \"loss\"\nsuper().__init__(*args, **kwargs)\nself.run_id = self.run_uuid.hex\ntime = datetime.now()\ntime_tuple = time.isocalendar()[1:] + (time.hour, time.minute, time.second, time.microsecond)\ntime_str = \"\".join(base62.encode(i) for i in time_tuple)\nself.id = f\"{time_str}{self.experiment_id:.5}{self.run_id:.4}\"  # pylint: disable=C0103\nself.name = f\"{self.experiment_name}-{self.run_name}\"\nself.setattr(\"ignored_keys_in_hash\", defaults.DEFAULT_IGNORED_KEYS_IN_HASH)\n@property\ndef experiment_uuid(self) -&gt; UUID:\nr\"\"\"\n        UUID of the experiment.\n        \"\"\"\nreturn UUID(bytes=bytes(self.experiment_id.ljust(16, \"x\")[:16], encoding=\"ascii\"))\n@property\ndef run_uuid(self) -&gt; UUID:\nr\"\"\"\n        UUID of the run.\n        \"\"\"\nreturn uuid5(self.experiment_uuid, str(hash(self)))\n@property\ndef uuid(self) -&gt; UUID:\nr\"\"\"\n        UUID of the state.\n        \"\"\"\nreturn uuid5(self.run_uuid, self.id)\ndef __hash__(self) -&gt; int:\nignored_keys_in_hash = self.getattr(\"ignored_keys_in_hash\", defaults.DEFAULT_IGNORED_KEYS_IN_HASH)\nstate = NestedDict({k: v for k, v in self.dict().items() if k not in ignored_keys_in_hash})\nreturn hash(state.yamls())\n</code></pre>"}]}